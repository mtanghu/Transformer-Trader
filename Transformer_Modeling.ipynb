{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from transformers import PreTrainedModel\n",
    "from trader_models import SRUTrader, SRUConfig, SGConvConfig, SGConvTrader\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import logging\n",
    "logging.disable(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(preds):\n",
    "    soft_profit, soft_trade = preds.predictions\n",
    "    abs_trade = np.abs(soft_trade)\n",
    "    abs_trade = abs_trade.astype('float64') # half precision will cause the sum to overflow on next line\n",
    "    trades = abs_trade.sum()\n",
    "    \n",
    "    day_profits = soft_profit.sum(axis = (1, 2))\n",
    "    \n",
    "    metrics = {\n",
    "        'day profit': day_profits.mean(),\n",
    "        'day sharpe': day_profits.mean() / day_profits.std(),\n",
    "        'trade %': trades * 100 / soft_profit.size,\n",
    "        \n",
    "        'full trade %': (abs_trade >= .7).mean() * 100,\n",
    "        'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
    "        'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
    "                          / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
    "        \n",
    "        'medium trade %': ((abs_trade < .7) & (abs_trade >= .4)).mean() * 100,\n",
    "        'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
    "        'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
    "                            / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),       \n",
    "        \n",
    "        'small trade %': ((abs_trade < .4) & (abs_trade >= .2)).mean() * 100,\n",
    "        'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
    "        'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
    "                            / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),        \n",
    "    }\n",
    "    \n",
    "    # round the metrics\n",
    "    metrics = {k: np.format_float_positional(v, precision = 4) for k, v in metrics.items()}\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fx = Dataset.load_from_disk('data/firstrate_days.ds')\n",
    "\n",
    "# # make splits\n",
    "# split = fx.train_test_split(.003, shuffle = False)\n",
    "# valid_test = split['test'].train_test_split(.3, shuffle = False)\n",
    "# fx = DatasetDict({\n",
    "#     'train': split['train'],\n",
    "#     'validation': valid_test['train'],\n",
    "#     'test': valid_test['test']\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fx = Dataset.load_from_disk('data/fx_days.ds')\n",
    "\n",
    "# make splits\n",
    "split = fx.train_test_split(.003, shuffle = False)\n",
    "valid_test = split['test'].train_test_split(.3, shuffle = False)\n",
    "fx = DatasetDict({\n",
    "    'train': split['train'],\n",
    "    'validation': valid_test['train'],\n",
    "    'test': valid_test['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ohlcv', 'labels', 'future'],\n",
       "        num_rows: 35213\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['ohlcv', 'labels', 'future'],\n",
       "        num_rows: 74\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ohlcv', 'labels', 'future'],\n",
       "        num_rows: 32\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    logging_strategy = \"steps\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    logging_steps = 200,\n",
    "    eval_steps = 200,\n",
    "    save_steps = 10000,\n",
    "    report_to = \"none\",\n",
    "    learning_rate = 1e-4,\n",
    "    weight_decay = .01,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    warmup_ratio = .05,\n",
    "    num_train_epochs = 1,\n",
    "    per_device_train_batch_size = 2,\n",
    "    per_device_eval_batch_size = 2,\n",
    "    max_grad_norm = 1,\n",
    "    fp16 = True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = SRUConfig(\n",
    "    n_embd = 320, n_head = 5 * 4, hidden_dropout_prob = 0\n",
    ")\n",
    "\n",
    "model = SRUTrader(config)\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = fx['train'],\n",
    "    eval_dataset = fx['validation'],\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='17607' max='17607' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [17607/17607 1:32:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.258100</td>\n",
       "      <td>2.193474</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.1659</td>\n",
       "      <td>6.5116</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>54.5455</td>\n",
       "      <td>0.6186</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>16.0494</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>2.2643</td>\n",
       "      <td>39.3212</td>\n",
       "      <td>1.0759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.201800</td>\n",
       "      <td>2.185424</td>\n",
       "      <td>-0.0262</td>\n",
       "      <td>-0.0771</td>\n",
       "      <td>8.3077</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>0.7036</td>\n",
       "      <td>1.2364</td>\n",
       "      <td>5.4984</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>5.7961</td>\n",
       "      <td>47.1297</td>\n",
       "      <td>1.0493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.197600</td>\n",
       "      <td>2.188328</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>7.0410</td>\n",
       "      <td>0.3534</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.669</td>\n",
       "      <td>1.0052</td>\n",
       "      <td>4.471</td>\n",
       "      <td>1.0310</td>\n",
       "      <td>1.5475</td>\n",
       "      <td>43.7976</td>\n",
       "      <td>1.1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.200600</td>\n",
       "      <td>2.195617</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.1689</td>\n",
       "      <td>14.1673</td>\n",
       "      <td>0.2401</td>\n",
       "      <td>0.5645</td>\n",
       "      <td>0.1081</td>\n",
       "      <td>0.2044</td>\n",
       "      <td>4.7959</td>\n",
       "      <td>1.0865</td>\n",
       "      <td>20.0892</td>\n",
       "      <td>52.0297</td>\n",
       "      <td>1.0338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.189900</td>\n",
       "      <td>2.176386</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.1973</td>\n",
       "      <td>6.1384</td>\n",
       "      <td>0.8275</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2601</td>\n",
       "      <td>2.0048</td>\n",
       "      <td>1.5603</td>\n",
       "      <td>0.6841</td>\n",
       "      <td>44.0634</td>\n",
       "      <td>1.0551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.171200</td>\n",
       "      <td>2.175950</td>\n",
       "      <td>-0.0379</td>\n",
       "      <td>-0.1197</td>\n",
       "      <td>9.1543</td>\n",
       "      <td>1.0965</td>\n",
       "      <td>0.1141</td>\n",
       "      <td>0.5855</td>\n",
       "      <td>0.1939</td>\n",
       "      <td>6.5054</td>\n",
       "      <td>1.1612</td>\n",
       "      <td>5.2620</td>\n",
       "      <td>47.3655</td>\n",
       "      <td>0.9768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.178900</td>\n",
       "      <td>2.174093</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>0.2667</td>\n",
       "      <td>6.5266</td>\n",
       "      <td>1.2283</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.1671</td>\n",
       "      <td>3.8677</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>0.5219</td>\n",
       "      <td>46.3337</td>\n",
       "      <td>0.9322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.172600</td>\n",
       "      <td>2.178842</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>8.4848</td>\n",
       "      <td>1.4084</td>\n",
       "      <td>0.6293</td>\n",
       "      <td>2.8776</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>11.8203</td>\n",
       "      <td>0.808</td>\n",
       "      <td>1.8730</td>\n",
       "      <td>55.8481</td>\n",
       "      <td>1.0201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.169400</td>\n",
       "      <td>2.166808</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.1579</td>\n",
       "      <td>7.9401</td>\n",
       "      <td>1.4970</td>\n",
       "      <td>0.3065</td>\n",
       "      <td>1.0143</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>17.8645</td>\n",
       "      <td>0.845</td>\n",
       "      <td>1.9651</td>\n",
       "      <td>52.8706</td>\n",
       "      <td>0.9855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.178600</td>\n",
       "      <td>2.168239</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>0.3022</td>\n",
       "      <td>7.1867</td>\n",
       "      <td>1.3680</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.078</td>\n",
       "      <td>1.4706</td>\n",
       "      <td>0.4641</td>\n",
       "      <td>0.4402</td>\n",
       "      <td>49.6447</td>\n",
       "      <td>0.9459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.173900</td>\n",
       "      <td>2.168594</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>7.1143</td>\n",
       "      <td>1.4281</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>5.8236</td>\n",
       "      <td>1.0565</td>\n",
       "      <td>1.1477</td>\n",
       "      <td>49.305</td>\n",
       "      <td>0.9603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.167300</td>\n",
       "      <td>2.166894</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>7.2211</td>\n",
       "      <td>1.4034</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>4.4269</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>6.6274</td>\n",
       "      <td>0.363</td>\n",
       "      <td>0.9367</td>\n",
       "      <td>52.989</td>\n",
       "      <td>0.8242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.162600</td>\n",
       "      <td>2.165585</td>\n",
       "      <td>-0.0028</td>\n",
       "      <td>-0.0194</td>\n",
       "      <td>7.6866</td>\n",
       "      <td>1.4189</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>15.1592</td>\n",
       "      <td>0.8161</td>\n",
       "      <td>1.389</td>\n",
       "      <td>59.455</td>\n",
       "      <td>1.0322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.174000</td>\n",
       "      <td>2.173063</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.3349</td>\n",
       "      <td>7.8765</td>\n",
       "      <td>1.3531</td>\n",
       "      <td>0.1772</td>\n",
       "      <td>0.4237</td>\n",
       "      <td>0.1368</td>\n",
       "      <td>20.0457</td>\n",
       "      <td>0.8891</td>\n",
       "      <td>2.3965</td>\n",
       "      <td>56.4635</td>\n",
       "      <td>0.9908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.160400</td>\n",
       "      <td>2.161273</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.3176</td>\n",
       "      <td>6.0398</td>\n",
       "      <td>1.5248</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>69.697</td>\n",
       "      <td>0.7153</td>\n",
       "      <td>0.4726</td>\n",
       "      <td>71.2930</td>\n",
       "      <td>0.7725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.156600</td>\n",
       "      <td>2.162318</td>\n",
       "      <td>0.0146</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>8.4365</td>\n",
       "      <td>1.4443</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>14.0030</td>\n",
       "      <td>0.7056</td>\n",
       "      <td>3.3953</td>\n",
       "      <td>54.9198</td>\n",
       "      <td>0.9455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.154700</td>\n",
       "      <td>2.155738</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.2664</td>\n",
       "      <td>6.0801</td>\n",
       "      <td>1.4924</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>17.0616</td>\n",
       "      <td>0.4782</td>\n",
       "      <td>0.4845</td>\n",
       "      <td>54.4222</td>\n",
       "      <td>0.8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.157900</td>\n",
       "      <td>2.164895</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>6.3210</td>\n",
       "      <td>1.5580</td>\n",
       "      <td>0.9570</td>\n",
       "      <td>0.3524</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>31.8919</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>0.5882</td>\n",
       "      <td>60.9289</td>\n",
       "      <td>0.8836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.164100</td>\n",
       "      <td>2.168918</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.2026</td>\n",
       "      <td>6.4112</td>\n",
       "      <td>1.4412</td>\n",
       "      <td>0.1881</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1916</td>\n",
       "      <td>68.7704</td>\n",
       "      <td>1.0857</td>\n",
       "      <td>1.1144</td>\n",
       "      <td>62.2942</td>\n",
       "      <td>1.0159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.152500</td>\n",
       "      <td>2.157144</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>7.0729</td>\n",
       "      <td>1.2501</td>\n",
       "      <td>0.3336</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2868</td>\n",
       "      <td>32.4246</td>\n",
       "      <td>0.9106</td>\n",
       "      <td>1.1995</td>\n",
       "      <td>57.5365</td>\n",
       "      <td>0.8396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.158500</td>\n",
       "      <td>2.164286</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>7.7944</td>\n",
       "      <td>1.4908</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0414</td>\n",
       "      <td>25.6927</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>1.1480</td>\n",
       "      <td>58.6649</td>\n",
       "      <td>0.9711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>2.165200</td>\n",
       "      <td>2.157478</td>\n",
       "      <td>-0.0008</td>\n",
       "      <td>-0.0069</td>\n",
       "      <td>7.1904</td>\n",
       "      <td>1.4305</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>56.0201</td>\n",
       "      <td>0.4909</td>\n",
       "      <td>0.964</td>\n",
       "      <td>61.3196</td>\n",
       "      <td>0.8488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>2.168200</td>\n",
       "      <td>2.159525</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.2646</td>\n",
       "      <td>6.5210</td>\n",
       "      <td>1.2726</td>\n",
       "      <td>1.0488</td>\n",
       "      <td>1.9213</td>\n",
       "      <td>0.3895</td>\n",
       "      <td>59.1432</td>\n",
       "      <td>1.5444</td>\n",
       "      <td>2.8657</td>\n",
       "      <td>55.6708</td>\n",
       "      <td>1.0873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>2.155400</td>\n",
       "      <td>2.155054</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.3306</td>\n",
       "      <td>6.6562</td>\n",
       "      <td>1.4993</td>\n",
       "      <td>0.16</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>70.7015</td>\n",
       "      <td>1.6834</td>\n",
       "      <td>1.1927</td>\n",
       "      <td>63.0705</td>\n",
       "      <td>0.9645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.158800</td>\n",
       "      <td>2.153423</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.1049</td>\n",
       "      <td>5.7181</td>\n",
       "      <td>1.5593</td>\n",
       "      <td>0.6687</td>\n",
       "      <td>0.8835</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>55.5409</td>\n",
       "      <td>1.5456</td>\n",
       "      <td>0.6542</td>\n",
       "      <td>63.6914</td>\n",
       "      <td>0.9247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>2.156800</td>\n",
       "      <td>2.154065</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>6.3023</td>\n",
       "      <td>1.4664</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0547</td>\n",
       "      <td>30.6667</td>\n",
       "      <td>0.5685</td>\n",
       "      <td>1.2283</td>\n",
       "      <td>58.1409</td>\n",
       "      <td>1.0085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>2.150300</td>\n",
       "      <td>2.156849</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>6.2839</td>\n",
       "      <td>1.4409</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.4701</td>\n",
       "      <td>67.6353</td>\n",
       "      <td>1.6847</td>\n",
       "      <td>1.5294</td>\n",
       "      <td>60.0832</td>\n",
       "      <td>1.0477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>2.154700</td>\n",
       "      <td>2.155280</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>7.0692</td>\n",
       "      <td>1.4046</td>\n",
       "      <td>0.6533</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.4341</td>\n",
       "      <td>69.6613</td>\n",
       "      <td>1.9264</td>\n",
       "      <td>1.7448</td>\n",
       "      <td>59.6606</td>\n",
       "      <td>0.9904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>2.162700</td>\n",
       "      <td>2.161391</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.2635</td>\n",
       "      <td>6.8198</td>\n",
       "      <td>1.5325</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>4.9773</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>70.6306</td>\n",
       "      <td>1.4529</td>\n",
       "      <td>1.9931</td>\n",
       "      <td>59.2781</td>\n",
       "      <td>1.0193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.155500</td>\n",
       "      <td>2.148758</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1953</td>\n",
       "      <td>6.4081</td>\n",
       "      <td>1.5303</td>\n",
       "      <td>0.2249</td>\n",
       "      <td>2.5231</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>77.4219</td>\n",
       "      <td>0.8158</td>\n",
       "      <td>0.7197</td>\n",
       "      <td>65.1695</td>\n",
       "      <td>0.8444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>2.161000</td>\n",
       "      <td>2.152900</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.1449</td>\n",
       "      <td>6.4111</td>\n",
       "      <td>1.2792</td>\n",
       "      <td>1.3368</td>\n",
       "      <td>25.2339</td>\n",
       "      <td>0.3465</td>\n",
       "      <td>76.0457</td>\n",
       "      <td>1.3177</td>\n",
       "      <td>1.5004</td>\n",
       "      <td>59.5455</td>\n",
       "      <td>1.0522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>2.160600</td>\n",
       "      <td>2.152036</td>\n",
       "      <td>0.0190</td>\n",
       "      <td>0.2091</td>\n",
       "      <td>7.4904</td>\n",
       "      <td>1.5357</td>\n",
       "      <td>5.2553</td>\n",
       "      <td>2.5214</td>\n",
       "      <td>0.8152</td>\n",
       "      <td>66.9992</td>\n",
       "      <td>1.1786</td>\n",
       "      <td>2.1572</td>\n",
       "      <td>59.4161</td>\n",
       "      <td>1.0654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>2.163400</td>\n",
       "      <td>2.158494</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>6.6922</td>\n",
       "      <td>1.4566</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1142</td>\n",
       "      <td>56.0731</td>\n",
       "      <td>1.6607</td>\n",
       "      <td>0.8919</td>\n",
       "      <td>62.2983</td>\n",
       "      <td>1.1445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6800</td>\n",
       "      <td>2.158300</td>\n",
       "      <td>2.148762</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.1317</td>\n",
       "      <td>6.5135</td>\n",
       "      <td>1.5407</td>\n",
       "      <td>1.9085</td>\n",
       "      <td>2.2138</td>\n",
       "      <td>0.3686</td>\n",
       "      <td>78.0764</td>\n",
       "      <td>1.3484</td>\n",
       "      <td>1.0248</td>\n",
       "      <td>59.8291</td>\n",
       "      <td>0.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.157400</td>\n",
       "      <td>2.153477</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.2623</td>\n",
       "      <td>6.9574</td>\n",
       "      <td>1.5156</td>\n",
       "      <td>1.3072</td>\n",
       "      <td>1.7441</td>\n",
       "      <td>0.5820</td>\n",
       "      <td>60.8384</td>\n",
       "      <td>1.8006</td>\n",
       "      <td>2.6888</td>\n",
       "      <td>56.3889</td>\n",
       "      <td>1.0719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7200</td>\n",
       "      <td>2.166500</td>\n",
       "      <td>2.150899</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.2730</td>\n",
       "      <td>7.2125</td>\n",
       "      <td>1.5381</td>\n",
       "      <td>0.9491</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.4102</td>\n",
       "      <td>73.9451</td>\n",
       "      <td>1.7437</td>\n",
       "      <td>2.8618</td>\n",
       "      <td>58.1688</td>\n",
       "      <td>0.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7400</td>\n",
       "      <td>2.148300</td>\n",
       "      <td>2.157434</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.2294</td>\n",
       "      <td>7.8234</td>\n",
       "      <td>1.5311</td>\n",
       "      <td>0.2996</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>60.4986</td>\n",
       "      <td>1.8341</td>\n",
       "      <td>3.4062</td>\n",
       "      <td>56.9657</td>\n",
       "      <td>1.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7600</td>\n",
       "      <td>2.155900</td>\n",
       "      <td>2.146233</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.3423</td>\n",
       "      <td>6.4008</td>\n",
       "      <td>1.5584</td>\n",
       "      <td>2.3016</td>\n",
       "      <td>3.1445</td>\n",
       "      <td>0.3753</td>\n",
       "      <td>76.3268</td>\n",
       "      <td>1.8952</td>\n",
       "      <td>1.3877</td>\n",
       "      <td>58.6971</td>\n",
       "      <td>1.0224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7800</td>\n",
       "      <td>2.151200</td>\n",
       "      <td>2.153939</td>\n",
       "      <td>0.0188</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>6.4911</td>\n",
       "      <td>1.0323</td>\n",
       "      <td>6.3636</td>\n",
       "      <td>2.1686</td>\n",
       "      <td>0.9028</td>\n",
       "      <td>61.5385</td>\n",
       "      <td>1.5466</td>\n",
       "      <td>2.8165</td>\n",
       "      <td>53.1635</td>\n",
       "      <td>0.9379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.155800</td>\n",
       "      <td>2.147918</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.2626</td>\n",
       "      <td>8.2944</td>\n",
       "      <td>1.6386</td>\n",
       "      <td>6.5479</td>\n",
       "      <td>2.2182</td>\n",
       "      <td>1.3602</td>\n",
       "      <td>68.4707</td>\n",
       "      <td>1.5302</td>\n",
       "      <td>4.2105</td>\n",
       "      <td>57.6696</td>\n",
       "      <td>1.0336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8200</td>\n",
       "      <td>2.154000</td>\n",
       "      <td>2.145423</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.3446</td>\n",
       "      <td>7.1622</td>\n",
       "      <td>1.5699</td>\n",
       "      <td>2.8560</td>\n",
       "      <td>13.9385</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>78.6004</td>\n",
       "      <td>2.0587</td>\n",
       "      <td>2.4301</td>\n",
       "      <td>60.478</td>\n",
       "      <td>1.0799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8400</td>\n",
       "      <td>2.151000</td>\n",
       "      <td>2.144441</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>7.9844</td>\n",
       "      <td>1.562</td>\n",
       "      <td>3.9386</td>\n",
       "      <td>2.8702</td>\n",
       "      <td>0.868</td>\n",
       "      <td>68.5848</td>\n",
       "      <td>1.5688</td>\n",
       "      <td>3.1515</td>\n",
       "      <td>59.0656</td>\n",
       "      <td>0.9683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8600</td>\n",
       "      <td>2.156100</td>\n",
       "      <td>2.146774</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.3117</td>\n",
       "      <td>7.6073</td>\n",
       "      <td>1.6141</td>\n",
       "      <td>4.4574</td>\n",
       "      <td>2.592</td>\n",
       "      <td>0.7457</td>\n",
       "      <td>71.7142</td>\n",
       "      <td>1.4912</td>\n",
       "      <td>3.0898</td>\n",
       "      <td>59.9791</td>\n",
       "      <td>1.0430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8800</td>\n",
       "      <td>2.156600</td>\n",
       "      <td>2.146513</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.3910</td>\n",
       "      <td>7.8695</td>\n",
       "      <td>1.6314</td>\n",
       "      <td>6.8388</td>\n",
       "      <td>2.3592</td>\n",
       "      <td>0.8207</td>\n",
       "      <td>73.269</td>\n",
       "      <td>1.5578</td>\n",
       "      <td>2.6523</td>\n",
       "      <td>58.6154</td>\n",
       "      <td>0.9924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.156000</td>\n",
       "      <td>2.147305</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.2632</td>\n",
       "      <td>8.3439</td>\n",
       "      <td>1.5744</td>\n",
       "      <td>3.0532</td>\n",
       "      <td>4.4017</td>\n",
       "      <td>1.04</td>\n",
       "      <td>71.0748</td>\n",
       "      <td>1.8945</td>\n",
       "      <td>4.1396</td>\n",
       "      <td>56.3728</td>\n",
       "      <td>0.9718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9200</td>\n",
       "      <td>2.153300</td>\n",
       "      <td>2.147873</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.332</td>\n",
       "      <td>7.3796</td>\n",
       "      <td>1.5117</td>\n",
       "      <td>2.221</td>\n",
       "      <td>3.9465</td>\n",
       "      <td>1.0410</td>\n",
       "      <td>62.8706</td>\n",
       "      <td>1.908</td>\n",
       "      <td>2.8614</td>\n",
       "      <td>60.1414</td>\n",
       "      <td>1.1309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9400</td>\n",
       "      <td>2.155700</td>\n",
       "      <td>2.147157</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.2097</td>\n",
       "      <td>7.5872</td>\n",
       "      <td>1.5898</td>\n",
       "      <td>1.7905</td>\n",
       "      <td>2.5841</td>\n",
       "      <td>1.1619</td>\n",
       "      <td>60.1903</td>\n",
       "      <td>1.5908</td>\n",
       "      <td>2.9755</td>\n",
       "      <td>56.1922</td>\n",
       "      <td>1.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9600</td>\n",
       "      <td>2.141400</td>\n",
       "      <td>2.147503</td>\n",
       "      <td>0.023</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>6.9706</td>\n",
       "      <td>1.6540</td>\n",
       "      <td>8.5671</td>\n",
       "      <td>2.4855</td>\n",
       "      <td>0.8328</td>\n",
       "      <td>67.2593</td>\n",
       "      <td>1.6145</td>\n",
       "      <td>1.8626</td>\n",
       "      <td>61.4902</td>\n",
       "      <td>1.0401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9800</td>\n",
       "      <td>2.148000</td>\n",
       "      <td>2.146118</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.1931</td>\n",
       "      <td>7.309</td>\n",
       "      <td>1.5688</td>\n",
       "      <td>1.7281</td>\n",
       "      <td>2.0738</td>\n",
       "      <td>0.4763</td>\n",
       "      <td>76.1821</td>\n",
       "      <td>2.0980</td>\n",
       "      <td>2.4747</td>\n",
       "      <td>61.4166</td>\n",
       "      <td>1.0784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.142200</td>\n",
       "      <td>2.143672</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.3547</td>\n",
       "      <td>7.8561</td>\n",
       "      <td>1.5304</td>\n",
       "      <td>1.2128</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0047</td>\n",
       "      <td>63.5703</td>\n",
       "      <td>1.7325</td>\n",
       "      <td>3.2380</td>\n",
       "      <td>57.5353</td>\n",
       "      <td>1.0649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10200</td>\n",
       "      <td>2.148200</td>\n",
       "      <td>2.146308</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.3582</td>\n",
       "      <td>7.3671</td>\n",
       "      <td>1.6333</td>\n",
       "      <td>5.5541</td>\n",
       "      <td>1.6700</td>\n",
       "      <td>1.3086</td>\n",
       "      <td>65.4741</td>\n",
       "      <td>1.6354</td>\n",
       "      <td>3.2051</td>\n",
       "      <td>58.9596</td>\n",
       "      <td>1.112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10400</td>\n",
       "      <td>2.158100</td>\n",
       "      <td>2.150397</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.2137</td>\n",
       "      <td>8.1187</td>\n",
       "      <td>1.4962</td>\n",
       "      <td>2.6901</td>\n",
       "      <td>3.0305</td>\n",
       "      <td>0.5695</td>\n",
       "      <td>72.7206</td>\n",
       "      <td>1.8294</td>\n",
       "      <td>3.0853</td>\n",
       "      <td>61.4147</td>\n",
       "      <td>1.0406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10600</td>\n",
       "      <td>2.137000</td>\n",
       "      <td>2.145027</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.3472</td>\n",
       "      <td>7.5871</td>\n",
       "      <td>1.5546</td>\n",
       "      <td>3.4543</td>\n",
       "      <td>5.1522</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>70.7130</td>\n",
       "      <td>1.8648</td>\n",
       "      <td>3.1218</td>\n",
       "      <td>60.6934</td>\n",
       "      <td>1.0754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10800</td>\n",
       "      <td>2.146500</td>\n",
       "      <td>2.144060</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.317</td>\n",
       "      <td>7.1856</td>\n",
       "      <td>1.5383</td>\n",
       "      <td>1.5726</td>\n",
       "      <td>2.915</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>72.0794</td>\n",
       "      <td>2.3017</td>\n",
       "      <td>2.5828</td>\n",
       "      <td>61.5866</td>\n",
       "      <td>1.1163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.145900</td>\n",
       "      <td>2.143353</td>\n",
       "      <td>0.0342</td>\n",
       "      <td>0.3249</td>\n",
       "      <td>8.2540</td>\n",
       "      <td>1.6161</td>\n",
       "      <td>4.7358</td>\n",
       "      <td>3.0788</td>\n",
       "      <td>1.1476</td>\n",
       "      <td>71.5155</td>\n",
       "      <td>1.7535</td>\n",
       "      <td>3.2642</td>\n",
       "      <td>60.3003</td>\n",
       "      <td>1.0844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11200</td>\n",
       "      <td>2.148600</td>\n",
       "      <td>2.143173</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.3780</td>\n",
       "      <td>7.4306</td>\n",
       "      <td>1.6263</td>\n",
       "      <td>4.8791</td>\n",
       "      <td>3.9458</td>\n",
       "      <td>1.5102</td>\n",
       "      <td>67.6793</td>\n",
       "      <td>1.6628</td>\n",
       "      <td>3.249</td>\n",
       "      <td>58.4133</td>\n",
       "      <td>1.1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11400</td>\n",
       "      <td>2.138200</td>\n",
       "      <td>2.145531</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.3052</td>\n",
       "      <td>7.5629</td>\n",
       "      <td>1.5493</td>\n",
       "      <td>1.0230</td>\n",
       "      <td>13.1635</td>\n",
       "      <td>1.0456</td>\n",
       "      <td>65.8755</td>\n",
       "      <td>1.9176</td>\n",
       "      <td>2.9486</td>\n",
       "      <td>56.8003</td>\n",
       "      <td>1.1194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11600</td>\n",
       "      <td>2.140600</td>\n",
       "      <td>2.142831</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.3717</td>\n",
       "      <td>7.5825</td>\n",
       "      <td>1.5681</td>\n",
       "      <td>6.4034</td>\n",
       "      <td>2.7428</td>\n",
       "      <td>1.6678</td>\n",
       "      <td>63.845</td>\n",
       "      <td>1.5677</td>\n",
       "      <td>3.1245</td>\n",
       "      <td>57.5705</td>\n",
       "      <td>1.093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11800</td>\n",
       "      <td>2.135800</td>\n",
       "      <td>2.143304</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.3551</td>\n",
       "      <td>7.3019</td>\n",
       "      <td>1.6879</td>\n",
       "      <td>7.9009</td>\n",
       "      <td>2.49</td>\n",
       "      <td>1.1057</td>\n",
       "      <td>69.0306</td>\n",
       "      <td>1.5789</td>\n",
       "      <td>2.6432</td>\n",
       "      <td>60.0260</td>\n",
       "      <td>1.0948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.142600</td>\n",
       "      <td>2.142907</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.3076</td>\n",
       "      <td>7.0554</td>\n",
       "      <td>1.6027</td>\n",
       "      <td>3.6042</td>\n",
       "      <td>5.1066</td>\n",
       "      <td>0.656</td>\n",
       "      <td>72.6753</td>\n",
       "      <td>2.0568</td>\n",
       "      <td>2.1266</td>\n",
       "      <td>61.3337</td>\n",
       "      <td>1.1063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12200</td>\n",
       "      <td>2.157000</td>\n",
       "      <td>2.144372</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.3691</td>\n",
       "      <td>7.3214</td>\n",
       "      <td>1.6140</td>\n",
       "      <td>3.2496</td>\n",
       "      <td>4.1370</td>\n",
       "      <td>1.1371</td>\n",
       "      <td>68.2898</td>\n",
       "      <td>1.7437</td>\n",
       "      <td>2.6732</td>\n",
       "      <td>59.2971</td>\n",
       "      <td>1.1162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12400</td>\n",
       "      <td>2.149300</td>\n",
       "      <td>2.142735</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.3432</td>\n",
       "      <td>7.4894</td>\n",
       "      <td>1.5847</td>\n",
       "      <td>3.2373</td>\n",
       "      <td>4.4513</td>\n",
       "      <td>1.1897</td>\n",
       "      <td>65.6266</td>\n",
       "      <td>1.7562</td>\n",
       "      <td>3.0245</td>\n",
       "      <td>58.6224</td>\n",
       "      <td>0.984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12600</td>\n",
       "      <td>2.139800</td>\n",
       "      <td>2.141714</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.3980</td>\n",
       "      <td>7.2203</td>\n",
       "      <td>1.5934</td>\n",
       "      <td>3.0103</td>\n",
       "      <td>4.4477</td>\n",
       "      <td>1.0454</td>\n",
       "      <td>69.5392</td>\n",
       "      <td>1.9552</td>\n",
       "      <td>2.5383</td>\n",
       "      <td>59.7379</td>\n",
       "      <td>1.0802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12800</td>\n",
       "      <td>2.141000</td>\n",
       "      <td>2.145739</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>8.4455</td>\n",
       "      <td>1.6950</td>\n",
       "      <td>7.1174</td>\n",
       "      <td>3.8709</td>\n",
       "      <td>1.8623</td>\n",
       "      <td>63.9586</td>\n",
       "      <td>1.6026</td>\n",
       "      <td>3.5369</td>\n",
       "      <td>55.855</td>\n",
       "      <td>0.9548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.147000</td>\n",
       "      <td>2.142242</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.4175</td>\n",
       "      <td>7.3111</td>\n",
       "      <td>1.5962</td>\n",
       "      <td>3.1421</td>\n",
       "      <td>3.8847</td>\n",
       "      <td>1.1039</td>\n",
       "      <td>72.079</td>\n",
       "      <td>1.9008</td>\n",
       "      <td>3.0746</td>\n",
       "      <td>60.1316</td>\n",
       "      <td>1.0747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13200</td>\n",
       "      <td>2.154000</td>\n",
       "      <td>2.142662</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.3467</td>\n",
       "      <td>7.4425</td>\n",
       "      <td>1.5918</td>\n",
       "      <td>3.3604</td>\n",
       "      <td>4.2140</td>\n",
       "      <td>0.6387</td>\n",
       "      <td>74.6286</td>\n",
       "      <td>2.2064</td>\n",
       "      <td>2.4400</td>\n",
       "      <td>61.9632</td>\n",
       "      <td>1.0489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13400</td>\n",
       "      <td>2.138400</td>\n",
       "      <td>2.142683</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.4008</td>\n",
       "      <td>7.9243</td>\n",
       "      <td>1.6669</td>\n",
       "      <td>5.3297</td>\n",
       "      <td>4.0504</td>\n",
       "      <td>1.4134</td>\n",
       "      <td>67.5175</td>\n",
       "      <td>1.7012</td>\n",
       "      <td>2.9343</td>\n",
       "      <td>59.6319</td>\n",
       "      <td>1.0067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13600</td>\n",
       "      <td>2.142400</td>\n",
       "      <td>2.142258</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.4068</td>\n",
       "      <td>8.1791</td>\n",
       "      <td>1.6955</td>\n",
       "      <td>8.8063</td>\n",
       "      <td>2.9647</td>\n",
       "      <td>1.3933</td>\n",
       "      <td>68.3281</td>\n",
       "      <td>1.5646</td>\n",
       "      <td>2.958</td>\n",
       "      <td>58.6400</td>\n",
       "      <td>1.0784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13800</td>\n",
       "      <td>2.140800</td>\n",
       "      <td>2.142128</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.4355</td>\n",
       "      <td>8.0423</td>\n",
       "      <td>1.7289</td>\n",
       "      <td>9.0525</td>\n",
       "      <td>3.6056</td>\n",
       "      <td>1.7397</td>\n",
       "      <td>68.0712</td>\n",
       "      <td>1.5831</td>\n",
       "      <td>2.9437</td>\n",
       "      <td>58.4358</td>\n",
       "      <td>1.0575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.149800</td>\n",
       "      <td>2.141038</td>\n",
       "      <td>0.0360</td>\n",
       "      <td>0.4006</td>\n",
       "      <td>7.8189</td>\n",
       "      <td>1.6087</td>\n",
       "      <td>4.6539</td>\n",
       "      <td>4.0799</td>\n",
       "      <td>1.2924</td>\n",
       "      <td>70.1815</td>\n",
       "      <td>1.9679</td>\n",
       "      <td>2.8729</td>\n",
       "      <td>59.9884</td>\n",
       "      <td>1.0497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14200</td>\n",
       "      <td>2.142400</td>\n",
       "      <td>2.142112</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.4213</td>\n",
       "      <td>8.3847</td>\n",
       "      <td>1.7354</td>\n",
       "      <td>8.7184</td>\n",
       "      <td>3.4698</td>\n",
       "      <td>1.7731</td>\n",
       "      <td>66.2393</td>\n",
       "      <td>1.5657</td>\n",
       "      <td>3.307</td>\n",
       "      <td>58.5433</td>\n",
       "      <td>0.9487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14400</td>\n",
       "      <td>2.144100</td>\n",
       "      <td>2.141794</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.4236</td>\n",
       "      <td>8.1132</td>\n",
       "      <td>1.6487</td>\n",
       "      <td>5.1733</td>\n",
       "      <td>3.4301</td>\n",
       "      <td>1.4777</td>\n",
       "      <td>66.6949</td>\n",
       "      <td>1.7343</td>\n",
       "      <td>2.9997</td>\n",
       "      <td>58.7563</td>\n",
       "      <td>0.9966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14600</td>\n",
       "      <td>2.138600</td>\n",
       "      <td>2.141118</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.4146</td>\n",
       "      <td>7.6343</td>\n",
       "      <td>1.6449</td>\n",
       "      <td>5.1601</td>\n",
       "      <td>3.4622</td>\n",
       "      <td>1.2103</td>\n",
       "      <td>69.3461</td>\n",
       "      <td>1.8836</td>\n",
       "      <td>2.6701</td>\n",
       "      <td>61.2294</td>\n",
       "      <td>1.0439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14800</td>\n",
       "      <td>2.145700</td>\n",
       "      <td>2.141512</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>7.7869</td>\n",
       "      <td>1.5935</td>\n",
       "      <td>3.0559</td>\n",
       "      <td>3.3452</td>\n",
       "      <td>1.206</td>\n",
       "      <td>69.4968</td>\n",
       "      <td>1.8493</td>\n",
       "      <td>2.8362</td>\n",
       "      <td>61.0110</td>\n",
       "      <td>1.0508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.143100</td>\n",
       "      <td>2.140025</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.4188</td>\n",
       "      <td>7.6415</td>\n",
       "      <td>1.6037</td>\n",
       "      <td>3.1469</td>\n",
       "      <td>3.3404</td>\n",
       "      <td>1.1219</td>\n",
       "      <td>70.2575</td>\n",
       "      <td>1.9346</td>\n",
       "      <td>2.6838</td>\n",
       "      <td>61.3039</td>\n",
       "      <td>1.0721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15200</td>\n",
       "      <td>2.142300</td>\n",
       "      <td>2.141422</td>\n",
       "      <td>0.0377</td>\n",
       "      <td>0.3973</td>\n",
       "      <td>8.0188</td>\n",
       "      <td>1.6672</td>\n",
       "      <td>6.1542</td>\n",
       "      <td>2.7708</td>\n",
       "      <td>1.403</td>\n",
       "      <td>66.1538</td>\n",
       "      <td>1.8103</td>\n",
       "      <td>2.8285</td>\n",
       "      <td>58.4163</td>\n",
       "      <td>1.0366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15400</td>\n",
       "      <td>2.137600</td>\n",
       "      <td>2.141228</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.3864</td>\n",
       "      <td>7.9493</td>\n",
       "      <td>1.6308</td>\n",
       "      <td>5.0064</td>\n",
       "      <td>3.7033</td>\n",
       "      <td>1.3491</td>\n",
       "      <td>69.6707</td>\n",
       "      <td>1.8358</td>\n",
       "      <td>2.8895</td>\n",
       "      <td>60.6366</td>\n",
       "      <td>1.0463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15600</td>\n",
       "      <td>2.144200</td>\n",
       "      <td>2.140743</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.3746</td>\n",
       "      <td>7.8091</td>\n",
       "      <td>1.6421</td>\n",
       "      <td>5.1943</td>\n",
       "      <td>3.5814</td>\n",
       "      <td>1.3852</td>\n",
       "      <td>68.9725</td>\n",
       "      <td>1.8492</td>\n",
       "      <td>2.6955</td>\n",
       "      <td>59.9358</td>\n",
       "      <td>1.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15800</td>\n",
       "      <td>2.140000</td>\n",
       "      <td>2.139804</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.3631</td>\n",
       "      <td>7.7545</td>\n",
       "      <td>1.6710</td>\n",
       "      <td>6.0901</td>\n",
       "      <td>3.424</td>\n",
       "      <td>1.4545</td>\n",
       "      <td>69.0300</td>\n",
       "      <td>1.7881</td>\n",
       "      <td>2.7382</td>\n",
       "      <td>60.2285</td>\n",
       "      <td>1.0902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.140300</td>\n",
       "      <td>2.140530</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.3805</td>\n",
       "      <td>8.0063</td>\n",
       "      <td>1.7088</td>\n",
       "      <td>8.1279</td>\n",
       "      <td>3.4955</td>\n",
       "      <td>1.6002</td>\n",
       "      <td>68.0263</td>\n",
       "      <td>1.7094</td>\n",
       "      <td>2.8771</td>\n",
       "      <td>59.8920</td>\n",
       "      <td>1.0869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16200</td>\n",
       "      <td>2.146800</td>\n",
       "      <td>2.140435</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.3552</td>\n",
       "      <td>8.1341</td>\n",
       "      <td>1.6975</td>\n",
       "      <td>7.3649</td>\n",
       "      <td>3.4256</td>\n",
       "      <td>1.5914</td>\n",
       "      <td>68.2545</td>\n",
       "      <td>1.7162</td>\n",
       "      <td>3.0203</td>\n",
       "      <td>59.9772</td>\n",
       "      <td>1.055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16400</td>\n",
       "      <td>2.146500</td>\n",
       "      <td>2.140776</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.3551</td>\n",
       "      <td>8.1183</td>\n",
       "      <td>1.6972</td>\n",
       "      <td>7.4399</td>\n",
       "      <td>3.5080</td>\n",
       "      <td>1.6012</td>\n",
       "      <td>68.1297</td>\n",
       "      <td>1.7159</td>\n",
       "      <td>3.0194</td>\n",
       "      <td>59.7956</td>\n",
       "      <td>1.0476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16600</td>\n",
       "      <td>2.144600</td>\n",
       "      <td>2.140687</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.3634</td>\n",
       "      <td>8.0082</td>\n",
       "      <td>1.6749</td>\n",
       "      <td>6.3936</td>\n",
       "      <td>3.3216</td>\n",
       "      <td>1.5437</td>\n",
       "      <td>68.1797</td>\n",
       "      <td>1.7444</td>\n",
       "      <td>2.9726</td>\n",
       "      <td>59.7867</td>\n",
       "      <td>1.0396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16800</td>\n",
       "      <td>2.139400</td>\n",
       "      <td>2.140603</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.365</td>\n",
       "      <td>7.9815</td>\n",
       "      <td>1.6796</td>\n",
       "      <td>6.4254</td>\n",
       "      <td>3.3909</td>\n",
       "      <td>1.5403</td>\n",
       "      <td>68.3117</td>\n",
       "      <td>1.7434</td>\n",
       "      <td>2.9716</td>\n",
       "      <td>59.8337</td>\n",
       "      <td>1.0356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.153400</td>\n",
       "      <td>2.140650</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.3503</td>\n",
       "      <td>8.0184</td>\n",
       "      <td>1.6822</td>\n",
       "      <td>6.4588</td>\n",
       "      <td>3.4005</td>\n",
       "      <td>1.5408</td>\n",
       "      <td>68.2750</td>\n",
       "      <td>1.7375</td>\n",
       "      <td>2.9676</td>\n",
       "      <td>59.7786</td>\n",
       "      <td>1.0407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17200</td>\n",
       "      <td>2.145300</td>\n",
       "      <td>2.140464</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.354</td>\n",
       "      <td>7.9992</td>\n",
       "      <td>1.6859</td>\n",
       "      <td>6.55</td>\n",
       "      <td>3.3774</td>\n",
       "      <td>1.5435</td>\n",
       "      <td>68.1078</td>\n",
       "      <td>1.7368</td>\n",
       "      <td>2.9584</td>\n",
       "      <td>59.7843</td>\n",
       "      <td>1.0427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17400</td>\n",
       "      <td>2.138800</td>\n",
       "      <td>2.140434</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.3544</td>\n",
       "      <td>7.9880</td>\n",
       "      <td>1.6839</td>\n",
       "      <td>6.4462</td>\n",
       "      <td>3.3933</td>\n",
       "      <td>1.5358</td>\n",
       "      <td>68.1105</td>\n",
       "      <td>1.7363</td>\n",
       "      <td>2.9512</td>\n",
       "      <td>59.8099</td>\n",
       "      <td>1.0461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17600</td>\n",
       "      <td>2.136400</td>\n",
       "      <td>2.140435</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.3538</td>\n",
       "      <td>7.9864</td>\n",
       "      <td>1.6836</td>\n",
       "      <td>6.4536</td>\n",
       "      <td>3.3834</td>\n",
       "      <td>1.535</td>\n",
       "      <td>68.0932</td>\n",
       "      <td>1.7352</td>\n",
       "      <td>2.9498</td>\n",
       "      <td>59.795</td>\n",
       "      <td>1.0448</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=17607, training_loss=2.155581929556805, metrics={'train_runtime': 5580.8579, 'train_samples_per_second': 6.31, 'train_steps_per_second': 3.155, 'total_flos': 0.0, 'train_loss': 2.155581929556805, 'epoch': 1.0})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OANDA finnhub, only from 2009 and only top 10 majors, no volume (to be similar to firstrate) only close and close diff\n",
    "\n",
    "# sru lr of 1e-4, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, NO rotary embed, norm or resid on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 2.12296199798584,\n",
       " 'eval_day profit': '0.045',\n",
       " 'eval_day sharpe': '0.4100',\n",
       " 'eval_trade %': '7.7770',\n",
       " 'eval_full trade %': '1.8586',\n",
       " 'eval_full trade accuracy': '2.4261',\n",
       " 'eval_full trade g/l': '2.2313',\n",
       " 'eval_medium trade %': '0.9469',\n",
       " 'eval_medium trade accuracy': '70.1299',\n",
       " 'eval_medium trade g/l': '1.9277',\n",
       " 'eval_small trade %': '2.7433',\n",
       " 'eval_small trade accuracy': '62.3275',\n",
       " 'eval_small trade g/l': '1.1338',\n",
       " 'eval_runtime': 2.6188,\n",
       " 'eval_samples_per_second': 12.219,\n",
       " 'eval_steps_per_second': 6.11,\n",
       " 'epoch': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(fx['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('srupp.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# quick prediction test to ensure model isn't cheating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRUTrader.from_pretrained('srupp.model', config = config).cuda().eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([ 8.,  5.,  5.,  5.,  6.,  8.,  7., 11., 11.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([4., 2., 1., 3., 3., 2., 4., 5., 6.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor([15., 13., 12., 12., 11., 10.,  9., 10.,  9.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([1., -0., -0., 1., 2., 1., 1., 2., 4.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for day in range(4):\n",
    "    # cut data short so no backwards flow of info\n",
    "    test_day = torch.tensor(fx['validation']['ohlcv'][day][:]).unsqueeze(0).cuda()\n",
    "    test_futures = torch.tensor(fx['validation']['future'][day][:]).unsqueeze(0).cuda()\n",
    "    after = torch.tensor(fx['validation']['ohlcv'][day][2*60:3*60])\n",
    "    with torch.no_grad():\n",
    "        # no access to futures\n",
    "        pred = model(test_day)[0][2*60]\n",
    "    torch.cuda.empty_cache()\n",
    "#     if (pred.abs() >= .9).any():\n",
    "    if True:\n",
    "        print(day)\n",
    "        print((pred.cpu() * 100).round())\n",
    "        \n",
    "        plt.plot(after.select(dim = 1, index = -1))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor([ 8.,  5.,  5.,  5.,  6.,  8.,  7., 11., 11.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "tensor([4., 2., 1., 3., 3., 2., 4., 5., 6.])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA7/ElEQVR4nO3dd3hb13n48e/BIgiSAPcmRWpSw9awIlvesuTEkWPLSZM2aeI6cX7NaJzVpqnTpk2apq3rJulKMxw7jppmNHGGFDtxLEveli1rULIGtUiJe+8JEji/P3ABcQBcIAiCeD/Po4fAxb3AuSJ433vWe5TWGiGEEPHLFO0CCCGEiC4JBEIIEeckEAghRJyTQCCEEHFOAoEQQsQ5S7QLMBuZmZm6pKQk2sUQQoiYcuTIkVatddb47TEZCEpKSjh8+HC0iyGEEDFFKXU52HZpGhJCiDgngUAIIeKcBAIhhIhzEgiEECLOSSAQQog4J4FACCHinAQCIYSIc3EVCPafaeJbz1+IdjGEEGJBiatA8PKFVv77gAQCIYQYLa4CQa7TTp/bQ+/QSLSLIoQQC0ZcBYIcpx2Axq7BKJdECCEWjrgMBE3dEgiEEMIvrECglEpXSu1TSp03fqaF2O+SUupNpVS5UurwTI+fK7kuqREIIcR44dYIHgT2a61XAPuN56Fs01pv0FpvnuXxYctxJgDQ1COBQAgh/MINBLuA3cbj3cA983z8jDhsFlLsFpqkRiCEEAHhBoIcrXUDgPEzO8R+GnhGKXVEKfWRWRyPUuojSqnDSqnDLS0tsy5wrtNOo/QRCCFEwJQL0yilngVyg7z0NzP4nBu01vVKqWxgn1KqQmv94gyOR2v9CPAIwObNm/VMjh0t12WnqXtotocLIcSiM2Ug0FrvCPWaUqpJKZWntW5QSuUBzSHeo9742ayU+hWwBXgRmNbxcyk7xc6F5tZIf4wQQsSMcJuG9gL3GY/vA/aM30EplaSUSvE/Bt4KnJzu8XMt15VAc88QHu+sKxVCCLGohBsIHgJuV0qdB243nqOUyldK/dbYJwd4WSl1HDgEPKW1fnqy4yMp12nH49W09UrzkBBCQJiL12ut24DtQbbXAzuNx5XA+pkcH0nZgUllQ4HHQggRz+JqZjH4agTAmJFDXmkmEkLEsfgLBK6xgeD/3qhmyz89S8/gcDSLJYQQURN3gSAjyYZJQbMRCH5/qonWXjdPn2yc8Xu5R7x8/ZmzNHQNzHUxhRBi3sRdILCYTWSlJNDYNciIx8uhqnYA9h6vn/F7PXminv86cIEnDtfOdTGFEGLexF0ggCuzi0/Wd9M7NMKK7GReudBK8wxyEGmteezlKgCO1XRGqKRCCBF5cRkIcpx2mruHeK2yDYB/uGcdXg1PHm+Y9nu8VtnOqfpu0pNsHKvuQGvpcBZCxKa4DQSN3YMcvNjGiuxkrluawdp8J3vK66b9Ho+9XEl6ko1P3bacjv5hqlr7IlhiIYSInLgMBLkuO10Dwxyqaue6pRkA3LOhgOO1XdO6oFe29LK/opkPXFvM1mWZAByr7oxkkYUQImLiMhD4VyobGPawdZkvENy1Ph+l4DchOo2buge5499f5OaHn+Pd3zmI1WTiA1uXsCI7mZQEC0erO+at/EIIMZfCmlkcq/wL1ACBGkGuy05pRhJnm3qCHnP0cgcVjT3sWJ1Nit3KtaXpZKf4AsqG4lSOSo1ACBGj4jIQ+GcXl+WmkJ5ku7LdZaehM/icgNoO3/avv2cDLod1zGsbi9P45oHz9A2NkJQQl/+lQogYFp9NQ8bsYn9twC/PlRhyPePajn5S7JYJQQBgU3EqXg3HazvnvKxCCBFpcRkInHYr//HeDXz81mVjtue57DSFSFFd0zFAYZoj6PttLEoDpMNYCBGb4jIQAOzaUBDoNPbLdflSVLf0TExRXdvRT1FaYtD3cjmsLMtK4uhl6TAWQsSeuA0EweSn+gLD+NxBWmtq2kPXCAA2FadRXtMpE8uEEDFHAsEouU7fHX/DuH6C9j43A8MeCkPUCADW5jtp63MHrU0IIcRCJoFglDyXv0YwNhD4RwwVpYeuEazKdQJQ0Rh8+KkQQixUEghGSXVYsVtNNI5rGqrp6AeYtEZQlpsCQEVjd+QKKIQQESCBYBSlFHmuROpD1AgmCwRpSTZynAlSIxBCxBwJBOPkOu0T5hLUtPeT6rCSYp84h2C0VblOzkogEELEGAkE4+SlTgwEtR0DFE0yYshvdW4K55t7GfF4I1U8IYSYcxIIxslz+VJUj55UVtvRP2mzkN+q3BTcI14utUlKaiFE7JBAME6uKxGPV9Pa6xsGqrX21QgmGTHkt8roMD7TIM1DQojYIYFgnPxxQ0hbeocYGvFOq0awPDsZs0lJP4EQIqZIIBgn1x8IjCykNe1TjxjyS7CYWZqZJENIhRAxRQLBOPmusbOLa405BNPpLAZf85AMIRVCxBIJBOOkOqwkWEw0dvsDga9GUDCNGgHA6jwntR0D9AwOR6yMQggxlyQQjOObVGan3mgaqu3oJzPZhsM2vQVnVuX4OozPhVjpTAghFhpZTiuI0QvUVLb0UTDNZiGAsjxfIPiHJ89QkJpIfqqdv965GqVURMoqhBDhkhpBEHkuOw1dg/zPwUu8XtXOTcszp31sQWoiO1bn0Ds0wtHqDr73UhVVrTKvQAixcEmNIIhcl536rgG+tPcUO1Zn85kdK6Z9rFKKR+/bDMDp+m52/udLnKzvZmlWcqSKK4QQYZEaQRB5qYloDesLU/mv923CYp7df9OKnGRsFhMn67rmuIRCCDF3pEYQxK0rs/jDzYX81R1lJNrMs34fq9nE6twUCQRCiAVNagRBFKU7ePjd68lITgj7vdYWuDhZ1yVLWAohFiwJBBG2Lt9F9+BIYIayEEIsNBIIIuyqAhcAJ+uleUgIsTBJIIiwlbnJWM2KN6WfQAixQIUVCJRS6UqpfUqp88bPtBD7XVJKvamUKldKHR61/ctKqTpje7lSamc45VmIEixmVuZIh7EQYuEKt0bwILBfa70C2G88D2Wb1nqD1nrzuO3/ZmzfoLX+bZjlWZDW5UuHsRBi4Qo3EOwCdhuPdwP3hPl+i9K6Aicd/cPUj1sCUyxOQyMeCfoipoQbCHK01g0Axs/sEPtp4Bml1BGl1EfGvfaAUuqEUur7oZqWAJRSH1FKHVZKHW5paQmz2PNrnb/DWJqHFr3mnkE2fmUfz5+Lre+oiG9TBgKl1LNKqZNB/u2awefcoLXeBLwd+IRS6mZj+7eBZcAGoAH4eqg30Fo/orXerLXenJWVNYOPjr7VeU7MJiWBIA68UdVBv9vDJckvJWLIlDOLtdY7Qr2mlGpSSuVprRuUUnlAc4j3qDd+NiulfgVsAV7UWjeNeq/vAU/O9ARigd1qZk2ek4MX28Zs7+ofRpnAabdGqWSxp7ajnxynHess035E2tHqDgB6BkeiXBIhpi/cv6a9wH3G4/uAPeN3UEolKaVS/I+BtwInjed5o3Z9p3/7YrStLJuj1R2097kD2+79/us8+IsTUSxVbHn2dBM3P/wc/3PwcrSLEpI/EPQOSSAQsSPcQPAQcLtS6jxwu/EcpVS+Uso/AigHeFkpdRw4BDyltX7aeO1hY1jpCWAb8Nkwy7NgbS/LxqvhhXO+StPZxh5O1HZR1ykdyNNxrLqDB35yFK+Go5c75v3zL7f18YkfH2Vw2BNyn6ERD6fqfOtVywp1IpaElXROa90GbA+yvR7YaTyuBNaHOP7ecD4/llxV4CIzOYH9Z5p558ZCfl1eB0D3gFwwpnKptY8P7z5Mdoqd/FR7VGZpH6ho5qkTDfzpTUvZUJQadJ+Tdd24PV4AuqVpSMSQhdnQugiZTIptq7J48VwL7hEve8vrAQkE0/HdFysZHPaw+/4t3LQii8tt/XTN8/+bP1dUQ2fonFHHjGahfJedXgkEIoZIIJhH21dn0z04wiMvXqSuc4CC1ES6B4dlzPkUmroHKc1MojQzKTAU99Q81wpqO/oBaJhkLsix6k4K0xIpzUqSpiERUyQQzKMbV2RhNSv+c/8FEq1m3rWpgGGPZnDYG+2iLWitvUNkGinB1+U7AQJt8fOlpsOoEXSFrhEcre5gY3EaKQlWGTUkYooEgnmUnGDh2tIM3B4vt6/JIddlB6Bb7h4n1dozREayDYCM5ATyXfZ5T+I3VY2goWuAhq5BNhWnkmy3yKghEVMkEMyz28p8k693bcjHleibPzDf7d2xRGtNa5+brFGLBK0tcM1rh3HXwHDgDr8xRCA4erkTgE3FaaTYLVIjEDFFAsE8e9+WYr7+nvVsW5UdmEgmHcah9QyN4B7xBpqGwDcCq6q1b97uumvafbWBJJs5ZI3gaHUHCRYTq/OcpNit9A6N4PFK34+IDRII5lmizcwfXFOIyaRwGjWCeGgaGhz2zOrC2NozBEBmii2wbV2BE63hdP389BPUGv0Dm5ak0dQ9GPQ8zjR0U5bnxGYxkZLgG5Xd55ZagYgNEgiiyGn3XTC6Bxb/BeOt//Yi33ruwoyPazNmYmckXakRzHcSP3//wJaSdEa8mrbeoQn7VLX2sSwzCYAU4/cqzUMiVkggiCJnnPQRDLg9VLf388IsMnIGagSjmoayU+xkpyTMYyAYIDnBQlmeb8TS+HTi/e4RGrp8Q1wBko1AIHMJRKyQQBBF8dJH0GrcQZ+o68I9MrOhsv5jRzcNga+fYL46jGs7+ilMSyTPGOXVOG4I6aVWX42hNMtfI/D9XmUugYgVEgiiyGYxkWg1L/o+gmbjrt494uV0w8za9Vt73SgF6Y6xgWBdgYsLzb109Uf+/66mfYDCNEcgEIzvML7U5ks5XSpNQyJGSSCIMmeiZdH3EbT0XGlT96dhmK7W3iHSHDYs49JO37wyE6+GF89Pv7npf1+7zH88e35Gn6+1DtQI0pNs2CymCYGgylh7oCTDCARGZ3GPzCUQMUICQZQ57dZFXyNoMZp3HDYzR6s7Z3Ssb1axbcL2DUVppDmsHKgIugRGUN998SLffO48nf3uqXc2dPYP0+f2UJTuQClFnss+IRBUtvSR67STZAQAaRoSsUYCQZS5Eq2LvrO4pWcIpeCmFZkzTiHd1use01HsZzYpbl2VzfNnm6c1LLW2o5+a9gGGPZrfvtk47c+vMUYMFaYlApDrtE9IPFfV2ktJpiPwXJqGRKyRQBBlzsQ4qBH0DJHusPGWknTqOgdo7p7+GgytvUNkBAkE4Jul3dE/THnN1MHltcp2wDdk158CfDr8cwj8gSA/NTFo01BpZnLgucNmxqRk1JCIHRIIosxpj48+gqyUBDYWpwHMqHmotdcdtGkI4OaVWZhNiv1npm4eOnixjTSHlQ/fuJRDVe3UB0kn/eSJ+glByj+ruDDNd8ef67LT1D2I16iFdPa76egfZqnRUQyglCI5wSJNQyJmSCCIsnioEbT2+gLBugInNrNp2h3Gg8MeeodGgjYNga9ZbfOStCn7CbTWvFbZxnVLM7hnYz4Ae4/Xj9nnubPNPPDjY/zjb8+M2V7bMYDTbgnkhcp32Rnx6sCwVn9HcemoQAC+fgJpGhKxQgJBlDntVroHhgN3mItRS88QWckJJFjMrMl3Btb1nUpgDkGIGgH41nioaOyhbpIFY2raB6jrHGDrsgyWZCSxsTiVXx+70jw0NOLhK785DcBTJxrGpJqu7einKP1K+3+uy9dE5G8eCgSCrPGBwCKjhkTMkEAQZa5EK169ePPSaK1pMWoE4MvOeaK2i2HP1BPLWnt9o3tC1QjgSjbXA2eaQu5zsLIVgK1LMwC4Z0MBFY09vHLBt/2xl6uoau3jq/esw6s1u1+9HCj75fb+QP8AMGEuQVVrH2aToijtSrAAIxAs8pqeWDwkEESZM9HIN7RImxG6B33ZQ/2BYENxKkMjXs429kx5bLD0EuMty0pmeXYyPz9SO2altwG3h6ER30LzBy+2kZlsY3m2r0P3rvX55DrtvP/R1/nkT47xzQMXuH1NDh+4bgl3rMvlx69fpm9ohG+/cJHKlj62lGYE3vdKIPDVGipb+yhMS8RmGfun5M9AKkQskEAQZYs9zYR/Mpk/EFw1g6Um2/r86SVCBwKlFB+8voQTtV0cNoamDo14uOubL3PTvzzHzw7X8FplO9cuzUApBUB6ko1n/+IWPrFtGb8/1ciIV/O3d64B4MM3ltI9OMIDPz7Kw0+f5a71+Xzo+pLA5/knlfnXJahq6ZvQPwAYncUSCERskEAQZYFU1Is9EBh39UvSHaQkWKa1wpi/aSgjKXQfAcAfbCok1WHl0ZcqAXj0pSouNPeS6rDy+SdO0Ng9GGgW8ktOsPCXbyvj+c/dyp5P3EBxhq9pZ1NxGhuKUnnubAtbl2bwtfdcjcmkAsf5J5Udq+mkd2iES23BA4EsTiNiiQSCKFvsq5T5ZxX7awQmk2JNvpOT01hzuKVniJQEC3aredL9Em1m/nhLMc+cbuL1yja+eeACb12Tw+8/czP/+b6N3L4mhzvW5QY9Nj81kdVGVlHwXei/eOdq7tmQz3fuvYYEy8TPfufGAg5VtXPzw8/R7/aMGTrql2K3yjwCETMkEERZoGlokV40WoK0819V4OJMQzcjU3QYt/W5J20WGu2+60uwmBQffPwNvFrzt+9Yg1KKu9fn870/2TxpP8N4m0vS+ff3bgwE6fE+s2Mlv/j49SwxahFr8l0T9kmxW3B7vAwOe6b9uUJEiwSCKAt0Fi/WGkHPEFazGnNRXVfgYmjEy4WW3kmPbe0JnmcomBynnXdcnc/AsIeP3rJszJDPSLhmSRq//Pj1vPT5bVyzJG3C65JmQsQSS7QLEO+SE/yjhhZnIPAljUsY085+ZYWxbspynaEOpbV3iGVZySFfH++zO1biSrTy8VuWzb7AM6CUChlw/IGgd2gk0CwmxEIlNYIos5hNJCdYFm8fQc/QhAthaWYSDpt5yhXGfE1D06sRABRnOPjy3WtJtE3epzAfkhMkA6mIHRIIFgBXonXR5hvyzyoezWxSrM13ThoIRjxeOvqDZx6NBSmyXKWIIRIIFoAUu2XaTUO/P9U4JgXCQjd6VvFoa/NdnG7oDplCur3PjdaEzDy60F1p8pNAIBY+CQQLgDPROq3O4pr2fj76wyN894XKeShV+DxeTVuIQLCuwEW/20NV68QOY601Dz1dAUBZbkrEyxkJTlmcRsQQCQQLgG+VsqnvHP0ZMysaZ7bub7S097nxaoIGgqtGdRiP94195/jl0To+u2MlbylJj3g5I2F0Z7EQC50EggXANY0agdaaPcaCKmcbe8bk1Vmoxs8qHm1ZVhJ2q4nyms4x23/8ejX/deAC79tSxKe2L5+PYkZEsgwfFTFEAsEC4FvAfvJAcKahh3NNvazMSaajf5jmUQvCL1T+WcXBJoVZzCZuWZnFj16/HMgC+uzpJr746ze5rSybf9i1LpAbKBZZzSbsVpM0DYmYIIFgAXDarfQMjUy69u6e8josJsVnd6wEoGIa2TujbbIaAcDD717P0sxkPvbDI/zfG9U88JOjXFXg4pt/vBGLOfa/mpKBVMSK2P9rWwT8iedCDTX0ejV7j9dz88osti7zJU+raFj4/QSt4/IMjedKtPL4h95CUoKFv/rFm+Q47Tz2wbfgsC2OeY4pCRYZNSRiggSCBcBptCeHmlR26FI7DV2D7NqQT6rDRo4zYVr5/KOttWcIu9VEUkLoC3t+aiK779/Czqty+cGHtsTsvIFgRmcgvdjSy4Bb8g6JhUkCwQLgz8MTai7B/jNN2Cwmbl+TA0BZrjMmmoba+qY3IWxVbgrfev81QdM5xzJfBtJhnj3dxO3feIHvvngx2kUSIqiwAoFSKl0ptU8pdd74OTH7lm+/VKXUE0qpCqXUGaXU1pkcv9j5m4Y++sMj7PjGC3z1ydNjXr/c1s+SdEegyaQsN4ULzb2B5R6/tOckvzhSO7+Fnoa2PveUawksZskJFipb+3jgJ0fxajhU1R7tIgkRVLg1ggeB/VrrFcB+43kw/wE8rbUuA9YDZ2Z4/KJ2daGLP9pcxIaiVLxezc/HXdRrOwbGrJu7KjcFt8fLpdY+TtR2svvgZX5zon6+iz2ltt6hmJ0ZPBdS7BY6+4fJTrFz51V5HK/pDDogYMTj5aXzLVEooRA+4QaCXcBu4/Fu4J7xOyilnMDNwGMAWmu31rpzusfHA4fNwr+8+2r++/2beO+WIroGhunqv9JMVNPRPybLpT9j55nGHh57uQrwBYuFpq3XTXoc1whKMpPITE5g9/1b2LEmmz63J2jfzi+P1nHvY4e40Lzwm/vE4hRuIMjRWjcAGD+zg+yzFGgBHldKHVNKPaqUSprB8QAopT6ilDqslDrc0rJ4756K033/NZfb+wBfB3LP4MiYGsGy7CTMJsULZ1t46kQDNrOJ2o7+BTXJTGtNe5+bjGmuJ7AY/dmty3jlwW2UZiaxqdjX6nmspmPCfi8b8yiauhf+3BCxOE0ZCJRSzyqlTgb5t2uan2EBNgHf1lpvBPqYRROQ1voRrfVmrfXmrKysmR4eM/yrXl1u6wd8+YUAitKu1AgSLGaWZibxi6O1eLXmT7YuYXDYG1jjdyHoGRrB7fGSmRS/TUNKqcBSl8XpDjKSbBy93DlmH601ByvbAF9KDiGiYcpAoLXeobVeF+TfHqBJKZUHYPxsDvIWtUCt1vp14/kT+AID0zw+rhQbTUDVRgDwN/kUpo1dAKXMWGf3jnW5XGcszF7b0T9fxZxSuxGU4rlpaDSlFBuL0zhWPbZGUNnaF5h4J4FAREu4TUN7gfuMx/cBe8bvoLVuBGqUUquMTdsB/7CYKY+PN0kJFjKTE6hu8wcC38/RTUMAq/N8WTk/fGNpoP+gZgH1E7T1+S5u8dw0NN7G4lQqW/voGHXBP3ixLfC4TQKBiJJwp3A+BPxMKfVhoBp4D4BSKh94VGu909jvk8CPlFI2oBL40GTHx7slGY5AH0FtxwDJCRZSHWMXUn//tUsoy03hmiXpgTQGC6lG4G+mWkwTxMLl7ycor+lkW5mvO+xgZRt5LjsDw54xAUKI+RRWINBat+G7wx+/vR7YOep5ObB5usfHuyXpDl4z2o1rO/opTEuckIDNlWjltjLfBLPkBAtpDmvIkUNtvUOkJ9nmNYmbv5lDmoauWF/kwmxSHK3uYFtZNlprXq9s4+YVWZTXds5r01Bnv5tUx8L43Wit6egflu9KFMnM4gWoOMNBQ/cgQyMeatoHJvQPBFOU7gh0LI92oraTt/zjs/zRI6/xZu3kawTPpTYjz5D8cV/hsFkoy03hqNFPcL65l9ZeN9ctyyDdYZu3QHCxpZdN/7CPNy4tjAluvzxax3X/vJ+6zoXTtBlvJBAsQMXpDrSGmvaBQI1gKoVpidQFqRH84kgtFrOJi8293PXNl/nGvnORKPIEbX1ukhMs2K3RX0h+IdlUnEZ5dSen67sDtb6tSzNIT5q/QHCyrguvZl5vDCbz2zcbcI94OXCmKdpFiVsSCBYg/xDS4zWd9Lk90woERWkOajsG8I6auTrs8fLkiQZuX53Dc395K9cvy+Cnh6ojVu7R2nrjew5BKO++phCrxcSd//US/7n/AgWpiRSlO8hIts1bZ3FVq6//qTpIDXK+DQ57eOWibx7F/oq4HzQYNRIIFiD/pDL/H8joWcWhFKYl4vZ4A4vBgG+iUlufm10b8nHarawvSqWj3z0vE8/a4zzPUCjri1J54XPbuP+GUroG3Gwr882JSXPY5u13c8kIBJfb+iL+WVM5eLGNwWEvZbkpvHqxjX63pO2OBgkEC1Bmsg2HzcyrF3xNB9NrGvIFi9Ejh/Ycq8Npt3DLKv/FxsqwR8/LYimtvUOkx/Fkssm4HFb+9h1reP2vd/DFO9cAvr4Uj1fTPRD5342/RnB5AdQI9lc04bCZ+fwdq3CPeAPfeTG/JBAsQEopitMdNHYPAhMnkwVTlO4LFjXtvn6CfvcIz5xu4s6r8wKzW9OMUSIdfZFfPtGXglpqBJNJT7IF+lD8ner++ReRorWm0ggEte0Dk66KB/DGpfbAAkORKMtzFS3cuDyTG5dnkWQzc+CsNA9FgwSCBcrfT+C0WwLrFUymIHVsjWDf6Sb63R52bSgI7OO/2HT0R7Yt2uvVdMR5nqGZmq/fTVufm57BEVZkJ+P2eAM3G8G09Azx3kde45+eOhNyn3CcbeqhrnOA28qysVlM3LwyiwNnmhdUzqx4IYFggVqS4esnmE5tACDRZiYzOYGa9gG01vzscA15LjtbStID+6QZF5v2CF9sugeHGfFqaRqagQzj/6otwvmi/M1CtxrNhf4Z7ME8daIej1fz+1ONEVld7YDROeyfXLetLJvG7kFOx8AyrIuNBIIFyp9zyN/kMx2FaYnUdvaz/0wzr1xo48M3lmIyXZlEdqVpKPJ3nYA0Dc1AWpKv1hfpIaRXAoHv4lvdHrrD+Nfl9aQkWOhze3g2AkM7D5xp5qoCFzlOOwDbjDI9J6OH5p0EggXK3zQ03RqBb99Eqlr6+MqTp1mencx915eMeT3dHwj6I9tH0CYJ52bMXyOIdG2tqrUPq1mxuSQNi0kFstyOd6m1j/KaTv5s23JynXb2lNfNaTmaugc5Ut3B9tVXMs9npSSwKieFY9Wdc/pZYmoSCBYo//q9JRnTDwRF6Q7quwapbu/n7+9ei9U89tebYrdgNqnI1wiMzsUMaRqatkSbmUSrOZC1NVKqWvooSneQYDFTmJYYcuTQ3uP1KAX3bMzn7g35PH+2ZU6/N785Xo/WcPf6/DHb81Ptk/ZbiMiQQLBAFaY52H3/Ft59TdEMjvE1I719XS43LM+c8LrJpEhzWCN+1ylNQ7OTnmSblxrBUuMmozgjKWgfgdaaX5fXsaUknTxXInevz2fEq3nqzYY5K8evy+u4utDF0qzkMdtzXXZZoCcKJBAsYLeszCLRNv0UDVuXZrClNJ0vvmNNyH1SHbZ5qBH43j9NmoZmJNJpJrxezaW2vkBtc0m6I+ikspN13VS29HHPRt+Is7X5TpZnJ7O3fG7Wxb7Q3MvJuu4xI9r8cpx22vqGGPZ45+SzxPRIIFhElmYl87OPbqUgNXQHc7oxgzWS2vuGcCVaJzRNiclFOhD4Ehl6Kc303YUvyXDQPThC57jvw+6Dl7CZTexclwf45rXcvT6fQ5fa56R8e8rrMCm4a33ehNdynHa0huYeqRXMJ/lLjTNpSdaITyhrlfQSsxLpQFDV4rv799cI/CPTRncYH6vu4IkjtXzohhJco9bAWG2siBcsw+1MaK3ZU17PDcszyU6xT3g91xhB1CT9BPNKAkGcSXNEvh26XRLOzcroQKC15nhN55xOrqpq7QVgaZbRNGTMVfF3GHu9mi/vPUV2SgKf3L5izLH5qb4LdH2YqaKPVndS3d4ftFkICAwlbeqSQDBev3uEp040RKRpVwJBnElL8vURRHL2ZlvfkIwYmoX0JBv9bg+Dwx4OXmxj13+/wvdfuTRn71/Z2ofDZiY7xfe7CayPbfQT/PxIDcdru/jCzjKSE8auWeVvbgxnzYABt4evPnUah83M29bmBN0nx+krm4wcmqi8ppNP/Pgo5bWdc/7eEgjiTLrDxog3sonn2nrdpEuNYMb88y7a+9w8c9o3gevf950LLG4frsqWPkoykgIr1SUaQeFyWz9Pn2zkod9V8JaSNO4JcrfuSrTisJlnHQg8Xs2nfnqM8ppOvvGHG0ixB0+bkp5kw2Y2SSAIwj+/YmNR6py/twSCOOMfyROpfgKPV9PR7yZT+ghmbHQgOFDRzOo8J4MjHh5+uiLs9/Z6NeU1nawrcI7ZviTDwS+P1fGx/z1CVkoC//yuq4MuaaqUoiA1cdZNQ3//m1PsO93El+9ayx3rckPup5Qi25lAswwhneBYdQdLs5IissSoBII4k2Z0AEaqn+B8cw9eDfmTjFwSwfkDwRuX2qlu7+ePry3m/htK+fmRWo4Zy1vO1umGbroGhtm6LGPM9muWpJPmsPLVe9bx20/dxPLs5BDv4Pud1nfO/E79bGMP/3PwMvffUDphtnswOU47jdJHMIbWmqPVnWwqTovI+0sgiDNXagSRCQR7yusxmxQ71gRvAxah+QPBE0dqAbitLJtPbl9BdkoCn/rpMQ5UNM26b8e/LOZ1S8cGgr+6YxWHv3g7H7huCZYphvvmz7JG8OvyOswmxZ9tWzat/XOddhk1NM7ltn7a+9xsLE6NyPtLIIgzV/INzT4QHLzYxqvG6mmjeb2aveX13Lg8k8xk6SyeKf+Q21P13ZTlplCQmkhygoVvvX8TVpOJ+39wmHsfOzSt9QGeOdXIyboraxIfvNhGSYaDPNfYmlqwZqBQClLttPW5Z5SJ1P+duGnF9L8TORIIJjhW46sRSo1AzIm0Ue3Q4414vFPecb58vpV7H3udP919eEL1/fDlDuo6B7hnY36Io8VknHYrZiNb7G1lV5KxbS5J5/efvZkv37WGg5Vt/GCKkUQ9g8M88JNjfO7nx9FaM+LxcqiqfUKz0EwVGClM6ruu1AqmmgHs/07s2jD970SuK4E+t4eewcgvoBQrjl7uJDnBwsqclIi8vwSCOOP0J54bVyMYGvFw88PP8ehLVSGPPVXfxcf+9wglmUkMezX//LuxC5bsKa8j0WrmrWtCdwaK0Py5oGBsIACwmk188IZSrilOC+TxD+Xpk424R7xUNPbwyoU2Tjd00zM0MqFZaKbyjdqEv3noyOUO1n7p97xxqT3kMbP5TuTIpLIJjlZ3sL7IFbhRmGsSCOKMUr6LzfhU1M+fbaG+a5DnQiwV2No7xIcefwOn3cL/fvhaPnrzUvaU13OoyncRcI94eerNBm5fk0PSuDHoYvrSk2ykOqxsDNEEcNvqbE43dE/ambqnvJ7CtEQykxN49OVKDl709Q9sDTcQpI4NBC+ca8E94uXv9pwKuuTlbL8TVwKBjBwC30SyisYeNhZFplkIJBDEpbQgief8+eaP13QG/aN+5UIrzT1D/Of7NpLrsvNnty4n32Xn7/ac5HhNJz99o5rO/uEZNQGIie5en8/HblkW8s5vu1FTCFUraO4e5NWLrbxzYwF/snUJz59t4edHalmWlUS2c2JKh5nIddkxKajr8AWCY9UdJFrNnGno5sevX56w/4vnWujsH55xU6E/zYSMHPI5UduFx6vZtCQ1Yp8hgSAOpY3LadM9OMyzZ5rJddrpc3s419Qz4Rj/RCJ/zplEm5kvvmMNFY097PrvV/i7PafISLJx88qs+TmJReqB21bwsVtCj65Znp1MYVoiByqCrxj2mxMNeDXs2lDA+68txmYxcaG5N+z+AfA1T+U47dR1DgbmJbxzUwHXL8vga8+cm9Dv9Ns3G0h1WLlpxcy+E/4agUwq8zlqDB2WGoGYU76moSt/tP425S/sLAOufPFGq+8cINVhHVPF33lVHnsfuIHvf3Az3//gZp74+PWScTTClFJsL8vmlQttDA5PHL2zp7yOdQW+tNEZyQm8y0glvXXpxPUpZsM/hPRCSy89gyNsKk7jy3evpXdohH/bdy6wn9aaVy+2ccPyzBl/JxJtZpx2C80SCGjuHuTpk42UZiZFNK27/NXGofQk25g+gr3l9SzJcHD3+nwykmwcvdw54Zj6zsFAZ+FoVxemcltZDreV5QSyWorIum11DgPDHg5WtqG15sjlDp4+2cDP3qjhRG3XmBQRD9y2nHdtKuCWVXNTU8tPTaS+ayAwwW1jcSorc1LYtT6fPeV1jBijiC619dPYPTjrfolc1+JaqezN2q7A/810jHi8fPPAeW792vOcaejm/91UGsHSgfTqxSF/H4HWmpaeIV692MoD25ajlGJjcWrQWaz1nQMUpU9/2UwROdeWppNoNfPj16v5/stVvHT+ypwOm9nEXaOWfyxMc/CNP9wwZ5+dn2rn9ycHOXypg1SHNbDa2e1rcvjlsTqOVneypTT9Sgf1LJukcpx2GhdJZ/G5ph7u+ubLfGXXWv5ka8m0jvnZ4Vq+9sw53romh7/euZqSCN9kSSCIQ2lG4rmeoRF+cbQOr4a7jbvIjcVpPHummY4+95iqaF3HQNjDD8XcsFvN3Lgik32nm3DaLXzxztWBpUlTHdZAG3skFKYm4vZ4OVDRzMai1MCEtBtXZGI1K/ZXNLGlNJ3XKtvITkkIBIqZynHaudA8cdJiLNpnJBDcd7pp2oHgV8dqWZ6dzHfvvWZGk/5mS5qG4pD/An+huZdvPX+Bm1ZkBnLM+Gcultd0BvbvHhymZ2gkkJNeRN9ndqzgz29fyQt/uY3/d9NSVuc5WZ3nnDBzeK75h5C29bnHzHJNsVvZUprOgTPNaK05WNnGdUszZn0Ry3Xaae4ZCjqCLRK01uw73RS03yVczxkjvF6vbJ9W1t/ajn7euNTBPRvy5yUIgASCuJSe5Ju09Le/PsmA28OX7lobeG19kQuTGtth7B83LonkFo61+S4+tX3FvK8LPfo7sGnJ2FEst5XlcL65l+fPtdDSMxTWSKUcZwIer6ZtGuk05sLByjb+9H8O85vjc7Mus197n5uj1R1cW5qO2+Pl5fNT13L2GGtDh1q8JxIkEMShNMeVnDb331g6JuOkw2ahLNcZNBBMthayiA/+QKAUXF3oGvOaf47Dv/zOlzY7nAlsuUbN5kJz76T7dQ8Oc+u/PsfP3qiZ9WcB7Dnmu/jWdIS3Att4L5xrxqvh83esIsVuCTnsd7S95fVcsyRtXvvkJBDEIX8gyEpJ4JO3LZ/w+qYlqRyv6QpUy/0TiCQQCFeilZQEC6tyUiYsLlOSmcTSzCQqGnvIc9lZkjH7C9l1S9PJTE7gX585i9f4Hg4Oe9j96iU6Rw19/r9DNVxq6+erT50O1B601vzscA3/+NRp/vGp03znhYu4R0KP2Bkc9vDbkw1A+EtxjnegooXM5AQ2FqVx88osnjvbEjifYM40dHO2qYd75nlipgSCOJTrsrM6z8k/7FoXdKWoTcVp9A6NcL7ZN7GsrnMQq1lJRlEBwO1rc7hnY/BmC3+OpK1h9A+Ar8/hwbeXcay6k18eq8Pj1Xzmp+V8ae8p/v43pwHfEMsfvHqJFdnJ9Ls9fO2ZswB876VKPv/ECX742mV+9Ho1D/2ugs8/cTzkBfj5s830DI6QYDEFbnrmwrDHywtnm9m2KguTyTf/o6VniJP1XRP2bekZorFrkP97owazSbHzqrw5K8d0yKihOGS3mvndp28K+bq/E/Do5U7Kcp3Udw6Q50rEFKGEVyK2TDYcdfvqHB59uYrrl4c/ge1dGwv40euXeeh3FRy53M7Tpxq5utDFr47V8f5ri2nsHqSuc4BH7r2GQ1XtPPZKFWkOG996/iJ3XpXHf71vIyaT4psHzvO1Z86R60rkwbeXTficXx+rJzPZxpbSdE7Vd4ddbr8jlzvoHhxh+2pfcLxlZRZKwf4zzVxdmAr4ai9fefI0j4/KKLttVRYZ83zTFVaNQCmVrpTap5Q6b/wMOgdaKZWqlHpCKVWhlDqjlNpqbP+yUqpOKVVu/NsZTnnE3FiS4SA9yRaYT1DXOSAjhsS0XLc0nR986C1z0rRhMim+cvc62vqG+MmhGj58Yyk//ch1Ro6rUzz6UhVLMhxsX53Dp3esICMpgW89f5Etpel8/Q/XB25cPrFtOX98bTHfeeEiPz1UPeYzugaGOVDRzDuuzqco3UGDkT5jLjxX0YzVrLjRSLGRkZzAxqJUnnqzIbAO9XdfrOTxVy7xnmsK+ed3XcU/v+sqvvrOq+bk82ci3KahB4H9WusVwH7jeTD/ATyttS4D1gOj8xf/m9Z6g/Hvt2GWR8wBpRQbi1IDHcb1nQMUpMpkMjE1pRS3rsqecrWz6bqq0MXn3rqKD91Qwt/sXI3DZuGv71zN6YZuyms6uf+GUswmRYrdysPvvoq3rsnhe/duxm41jynTV+5ey/pCFz949dKY93/6ZANuj5d7NhZQYMyRaO2bm5FKFY09lOU6SR6VluWDN5RyqbWPW//1Of7y58d56HcV3LU+n3/5g6t535Zi3relOCp9ceE2De0CbjUe7waeB/5q9A5KKSdwM/BBAK21G4jMOolizmxaksb+imbaeodo6h6kQGoEIko+sW3sgIY7r8rjx8uqOVXfzbuvKQxs96c6CcZiNrFjdQ5f3+dLjudfFvTJEw0syXCwvtBFq3GXXtcxQHZK+N/3zn73hOG9d6/PZ12+k3/6bQU/P1LLdUvT+dp7ro56s2u4gSBHa90AoLVuUEplB9lnKdACPK6UWg8cAT6tte4zXn9AKfUnwGHgL7TWQVfpVkp9BPgIQHFxcZjFFlPxr4369KlGWYxeLChKKb5z7zV09Q/PaJ2DrcsyYB8cqmrjjnV59A6N8FplGx+8vgSl1JUV2DoH2TgHl5iO/uGgqSGWZiXz6H2bqWjspiQjiQSLOcjR82vK+ptS6lml1Mkg/3ZN8zMswCbg21rrjUAfV5qQvg0sAzYADcDXQ72J1voRrfVmrfXmrCxJdRxp6wtTMSl48rhvWJ0EArGQOO3WGY+zv7owlUSrOZAH6eXzrQx7dKAWMX7hnXB19LsDQ7WDKct1jmnCiqYpw6nWekeo15RSTUqpPKM2kAcEWy2jFqjVWr9uPH8CIxBorQOzK5RS3wOenEnhReQkJVhYlevktSrfH40EAhHrbBYTm0vSOFjp+04fqGgixW5hc4lvjIvTbiE5wRJYeyMcIx4vPYMjpDomDs9eiMLt0dkL3Gc8vg/YM34HrXUjUKOUWmVs2g6cBjCCh987gZNhlkfMoU3FqfjXspfJZGIxuG5pBueaemnpGeK5sy3cvDIrsF6CUor8VPuc1Ai6Bnxp3ierESwk4QaCh4DblVLngduN5yil8pVSo0cAfRL4kVLqBL5moH8ytj+slHrT2L4N+GyY5RFzyD+fID3JRqJtYVRhhQiHP//Roy9X0tIzFEiL4ZefmjgnNQL/eh+xUiMIq7NYa92G7w5//PZ6YOeo5+XA5iD73RvO54vI8ncYyxwCsVhcVeAiyWbm8VcuoRTcumpsIChITeT4qMy7s+VPgxEvNQKxiJVmJpGeZKNQ5hCIRcJqNvGW0nTcI142FacFhpH65acm0tE/TL976nTRk/HXCCQQiJinlOJb79/E5962MtpFEWLO+LOi3lY2cbR7QeqVIaTh8K8JHitNQxIIxKSuW5rB8uyUaBdDiDnztrW5rMhO5h1XT0zs5h8dF24/QWeMBQJJOieEiCslmUns+/Nbgr52ZVJZeIGgo38Yi0mNSS+xkEmNQAghDDkpCZhU+IGgs99NqsM2b0tNhksCgRBCGCxmE7lOe9hNQx19w6TFSLMQSCAQQogx8lMTw16gZqr0EguNBAIhhBhlLiaVdfYPx0xHMUggEEKIMbJSEmjvCy9TvtQIhBAihrkSrfS7PQx7Qi94Pxmtta9GkCQ1AiGEiEmuRN8F3J84bqb63R7cHq/UCIQQIlaFGwg6AnmGpEYghBAxyZnomwTWPctA0BnIPCo1AiGEiEnh1gg6YyzhHEggEEKIMeaqaUiGjwohRIxyGoFg9k1DEgiEECKmOe3h1giMPoJEaRoSQoiYZLeaSbCY6B6c3eI0Hf1ukhMs2Cyxc3mNnZIKIcQ8cSVa6eqffWdxLDULgQQCIYSYwJVoDauzOJZGDIEEAiGEmCC8QCA1AiGEiHmuRCvdg7MfNSQ1AiGEiHFh1Qj63DGVXgIkEAghxATOWQaCEY+X7sGRmEovARIIhBBiAmeilZ7BETxePaPj/MFDagRCCBHj/GkmembYT+CfTJaWJDUCIYSIaa5AmomZTSrz5xnyHx8rJBAIIcQ4s008V9PeD0BRumPOyxRJEgiEEGIcp923JsFMA0FVax9mk6IoTQKBEELENJdjdjWCytY+itISYyrPEEggEEKICWbbNFTV0kdJZlIkihRREgiEEGKcQGfxDEYNaa251NZHqQQCIYSIfYlWM1azmlGNoLlniH63h6USCIQQIvYppaZMM3GuqYf7f/AGvUO+IaaVLX0AlGYmz0sZ55IEAiGECMJpnzwQPP5KFQcqmnn5fCvgGzEEUJolNQIhhFgUnInWkOsWD414eOpEAwCvVbYBUNXaS4LFRJ7TPm9lnCsSCIQQIgjXJIHg+bMtdA+O4Eq0jgoE/ZRkJGEyqfks5pwIKxAopdKVUvuUUueNn2lB9lmllCof9a9bKfWZ6R4vhBDRMFkfwZ7yOjKTbdx/QykVjT209Q5R1dobkyOGIPwawYPAfq31CmC/8XwMrfVZrfUGrfUG4BqgH/jVdI8XQohoCBUIugeHefZMM++4Op8bV2QC8OrFNqrb+2OyfwDCDwS7gN3G493APVPsvx24qLW+PMvjhRBiXvhWKRtB67GpqH9/shH3iJe7N+RzdaELh83Mz4/UMuzRcVsjyNFaNwAYP7On2P+9wE9mc7xS6iNKqcNKqcMtLS1hFlsIISbnTLTg8erA8FDwpaX+yaFqlmQ42FiUitVsYnNJOi+d912TYnEOAUwjECilnlVKnQzyb9dMPkgpZQPuBn4+m4JqrR/RWm/WWm/OysqazVsIIcS0XZld7Fug5kevX+bWf32eo9Wd/OlNS1HK1ym8dWkG/kpDrNYILFPtoLXeEeo1pVSTUipPa92glMoDmid5q7cDR7XWTaO2zeR4IYSYN4F8Q/3D/PDgZb7zwkW2lKTz+IdWc3VhamC/rcsyAEixW0iPsQVp/MJtGtoL3Gc8vg/YM8m+72Nss9BMjxdCiHnjNALBsZoOHn2pkj/YVMj/ffS6MUEAYF2+k+QEC0szkwK1hFgzZY1gCg8BP1NKfRioBt4DoJTKBx7VWu80njuA24GPTud4IYSINn+N4KHfVZBoM/OFnWVBL/QWs4lPbV8ecwvWjxZWINBat+EbCTR+ez2wc9TzfiBjuscLIUS0Oe3+dYtH+NJda8hMTgi570duXjZfxYoImVkshBBB+BenWZWTwr3XLYlyaSIr3KYhIYRYlFISLHxq+wretjYHi3lx3zNLIBBCiCCUUvz57SujXYx5sbjDnBBCiClJIBBCiDgngUAIIeKcBAIhhIhzEgiEECLOSSAQQog4J4FACCHinAQCIYSIc2r86juxQCnVAlyecsfgMoHWOSxONMm5LFyL6XzkXBam2ZzLEq31hAVdYjIQhEMpdVhrvTna5ZgLci4L12I6HzmXhWkuz0WahoQQIs5JIBBCiDgXj4HgkWgXYA7JuSxci+l85FwWpjk7l7jrIxBCCDFWPNYIhBBCjCKBQAgh4lxcBQKl1B1KqbNKqQtKqQejXZ6ZUEoVKaWeU0qdUUqdUkp92tierpTap5Q6b/xMi3ZZp0spZVZKHVNKPWk8j8lzUUqlKqWeUEpVGL+frTF8Lp81vl8nlVI/UUrZY+VclFLfV0o1K6VOjtoWsuxKqS8Y14KzSqm3RafUoYU4n381vmcnlFK/Ukqljnpt1ucTN4FAKWUG/ht4O7AGeJ9Sak10SzUjI8BfaK1XA9cBnzDK/yCwX2u9AthvPI8VnwbOjHoeq+fyH8DTWusyYD2+c4q5c1FKFQCfAjZrrdcBZuC9xM65/AC4Y9y2oGU3/nbeC6w1jvmWcY1YSH7AxPPZB6zTWl8NnAO+AOGfT9wEAmALcEFrXam1dgM/BXZFuUzTprVu0FofNR734LvYFOA7h93GbruBe6JSwBlSShUCdwKPjtocc+eilHICNwOPAWit3VrrTmLwXAwWIFEpZQEcQD0xci5a6xeB9nGbQ5V9F/BTrfWQ1roKuIDvGrFgBDsfrfUzWusR4+lrQKHxOKzziadAUADUjHpea2yLOUqpEmAj8DqQo7VuAF+wALKjWLSZ+Hfg84B31LZYPJelQAvwuNHM9ahSKokYPBetdR3wNaAaaAC6tNbPEIPnMkqosi+G68H9wO+Mx2GdTzwFAhVkW8yNnVVKJQO/AD6jte6OdnlmQyn1DqBZa30k2mWZAxZgE/BtrfVGoI+F23QyKaP9fBdQCuQDSUqpD0S3VBET09cDpdTf4Gsu/pF/U5Ddpn0+8RQIaoGiUc8L8VV7Y4ZSyoovCPxIa/1LY3OTUirPeD0PaI5W+WbgBuBupdQlfE10tyml/pfYPJdaoFZr/brx/Al8gSEWz2UHUKW1btFaDwO/BK4nNs/FL1TZY/Z6oJS6D3gH8H59ZSJYWOcTT4HgDWCFUqpUKWXD17GyN8plmjallMLXDn1Ga/2NUS/tBe4zHt8H7Jnvss2U1voLWutCrXUJvt/DAa31B4jNc2kEapRSq4xN24HTxOC54GsSuk4p5TC+b9vx9UXF4rn4hSr7XuC9SqkEpVQpsAI4FIXyzYhS6g7gr4C7tdb9o14K73y01nHzD9iJr6f9IvA30S7PDMt+I76q3gmg3Pi3E8jANxrivPEzPdplneF53Qo8aTyOyXMBNgCHjd/Nr4G0GD6XvwcqgJPAD4GEWDkX4Cf4+jaG8d0hf3iysgN/Y1wLzgJvj3b5p3k+F/D1BfivAd+Zi/ORFBNCCBHn4qlpSAghRBASCIQQIs5JIBBCiDgngUAIIeKcBAIhhIhzEgiEECLOSSAQQog49/8B8Y70F8FIGSkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "tensor([15., 13., 12., 12., 11., 10.,  9., 10.,  9.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "tensor([1., -0., -0., 1., 2., 1., 1., 2., 4.])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for day in range(4):\n",
    "    # cut data short so no backwards flow of info\n",
    "    test_day = torch.tensor(fx['validation']['ohlcv'][day][:121]).unsqueeze(0).cuda()\n",
    "    after = torch.tensor(fx['validation']['ohlcv'][day][120:240])\n",
    "    with torch.no_grad():\n",
    "        # no access to futures\n",
    "        pred = model(test_day)[0][120]\n",
    "        \n",
    "    torch.cuda.empty_cache()\n",
    "#     if (pred.abs() >= .9).any():\n",
    "    if True:\n",
    "        print(day)\n",
    "#         plt.pcolormesh(pred.cpu().unsqueeze(0))\n",
    "        plt.show()\n",
    "        print((pred.cpu() * 100).round())\n",
    "        \n",
    "        plt.plot(after.select(dim = 1, index = -1))\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: graph these instead of showing raw data (maybe even on same plot or at least side by side)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_profit, soft_trade = trainer.predict(fx['validation']).predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36486486486486486"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(soft_profit.sum(axis = (1, 2)) < 0).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08853438"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soft_profit.sum(axis = (1, 2)).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(soft_profit.sum(axis = (1, 2)), bins = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  0.,  0.,  2.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,\n",
       "        0.,  0.,  0.,  0.,  0.,  0.,  0.,  3., 47., 63., 30.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full trade percent on 24 hours, ignoring last hour, it makes most trades in london and ny sessions (esp overlap)\n",
    "((np.abs(soft_trade) > .2).mean(axis = (0, 2)).reshape(-1, 60).mean(axis = 1) * 100).round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-1ac9a154e44f>:2: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(np.where(np.abs(soft_trade) > .2, soft_profit > 0, np.nan), axis = (0, 2)).reshape(-1, 60).mean(axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([       nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "              nan,        nan,        nan,        nan,        nan,\n",
       "       0.49909872, 0.56307941, 0.50657518, 0.19721548])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full trade accuracy on 24 hours\n",
    "np.nanmean(np.where(np.abs(soft_trade) > .2, soft_profit > 0, np.nan), axis = (0, 2)).reshape(-1, 60).mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-b1a53ae86831>:2: RuntimeWarning: Mean of empty slice\n",
      "  np.nanmean(np.where(np.abs(soft_trade) > .3, soft_profit, np.nan), axis = (0, 2)).reshape(-1, 60).mean(axis = 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([          nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan,           nan,           nan,           nan,\n",
       "                 nan, 5.8730193e-06, 6.4541244e-05, 7.6953938e-06],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full trade profit on 24 hours\n",
    "np.nanmean(np.where(np.abs(soft_trade) > .3, soft_profit, np.nan), axis = (0, 2)).reshape(-1, 60).mean(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04648086, 0.05411036, 0.05850225, 0.06303491, 0.06889077,\n",
       "       0.07491554, 0.07476539, 0.06384197, 0.05048799])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percent full trades on all timeframes\n",
    "(np.abs(soft_trade) > .2).mean(axis = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.37633757, 0.44103365, 0.47273019, 0.50498735, 0.52581392,\n",
       "       0.52223475, 0.51186143, 0.44700867, 0.38754647])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full trade accuracy on all timeframes\n",
    "np.nanmean(np.where(np.abs(soft_trade) > .2, soft_profit > 0, np.nan), axis = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.12292492e-05, 1.01473204e-04, 1.15278272e-04, 1.22520345e-04,\n",
       "       1.32214962e-04, 1.40028264e-04, 1.68057697e-04, 2.00559676e-04,\n",
       "       2.91359669e-04], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full trade gain on all timeframes\n",
    "np.nanmean(np.where((np.abs(soft_trade) > .3) & (soft_profit > 0), soft_profit, np.nan), axis = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-4.76083405e-05, -6.22327861e-05, -6.94265182e-05, -7.35067224e-05,\n",
       "       -8.38432024e-05, -9.17941215e-05, -1.03077306e-04, -1.05229068e-04,\n",
       "       -1.17557916e-04], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full trade loss on all timeframes\n",
    "np.nanmean(np.where((np.abs(soft_trade) > .3) & (soft_profit < 0), soft_profit, np.nan), axis = (0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del trainer\n",
    "# del model\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SRU experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 34 layers\n"
     ]
    }
   ],
   "source": [
    "config = SGConvConfig(\n",
    "    n_embd = 1024, n_head = 5 * 4, hidden_dropout_prob = 0\n",
    ")\n",
    "\n",
    "model = SGConvTrader(config)\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = fx['train'],\n",
    "    eval_dataset = fx['validation'],\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4370' max='4370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4370/4370 1:15:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.254200</td>\n",
       "      <td>2.231734</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.4064</td>\n",
       "      <td>6.3818</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>50.6751</td>\n",
       "      <td>1.8062</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>46.5371</td>\n",
       "      <td>1.2629</td>\n",
       "      <td>2.5954</td>\n",
       "      <td>50.2792</td>\n",
       "      <td>1.1951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.215000</td>\n",
       "      <td>2.218014</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>8.1351</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>63.0332</td>\n",
       "      <td>4.7094</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>61.0924</td>\n",
       "      <td>2.8094</td>\n",
       "      <td>4.3714</td>\n",
       "      <td>60.5014</td>\n",
       "      <td>1.1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.222800</td>\n",
       "      <td>2.258496</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.4278</td>\n",
       "      <td>7.2867</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>37.2263</td>\n",
       "      <td>2.3042</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>53.6585</td>\n",
       "      <td>1.6169</td>\n",
       "      <td>2.6964</td>\n",
       "      <td>57.7572</td>\n",
       "      <td>1.1863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.199000</td>\n",
       "      <td>2.211952</td>\n",
       "      <td>0.0805</td>\n",
       "      <td>1.0515</td>\n",
       "      <td>6.3457</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>57.9710</td>\n",
       "      <td>3.3084</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>45.7854</td>\n",
       "      <td>2.4971</td>\n",
       "      <td>2.0552</td>\n",
       "      <td>61.583</td>\n",
       "      <td>1.2458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.216700</td>\n",
       "      <td>2.220958</td>\n",
       "      <td>0.1141</td>\n",
       "      <td>0.5813</td>\n",
       "      <td>7.2691</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>61.1765</td>\n",
       "      <td>2.9638</td>\n",
       "      <td>0.092</td>\n",
       "      <td>65.5329</td>\n",
       "      <td>2.1350</td>\n",
       "      <td>2.2743</td>\n",
       "      <td>64.3804</td>\n",
       "      <td>1.3098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.192300</td>\n",
       "      <td>2.221125</td>\n",
       "      <td>0.1514</td>\n",
       "      <td>0.7927</td>\n",
       "      <td>8.7405</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>63.3431</td>\n",
       "      <td>0.7091</td>\n",
       "      <td>0.1928</td>\n",
       "      <td>55.6517</td>\n",
       "      <td>2.5370</td>\n",
       "      <td>7.5028</td>\n",
       "      <td>58.4963</td>\n",
       "      <td>1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.208700</td>\n",
       "      <td>2.215595</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>8.2134</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>68.6667</td>\n",
       "      <td>3.4398</td>\n",
       "      <td>0.0760</td>\n",
       "      <td>72.5652</td>\n",
       "      <td>2.0032</td>\n",
       "      <td>4.9196</td>\n",
       "      <td>59.9245</td>\n",
       "      <td>1.4295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.187200</td>\n",
       "      <td>2.206578</td>\n",
       "      <td>0.1646</td>\n",
       "      <td>0.8054</td>\n",
       "      <td>7.8332</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>71.2042</td>\n",
       "      <td>3.3337</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>72.6913</td>\n",
       "      <td>2.9198</td>\n",
       "      <td>3.6575</td>\n",
       "      <td>65.6926</td>\n",
       "      <td>1.6473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.186400</td>\n",
       "      <td>2.216811</td>\n",
       "      <td>0.2254</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>14.7438</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>76.4045</td>\n",
       "      <td>4.0391</td>\n",
       "      <td>1.6878</td>\n",
       "      <td>62.4699</td>\n",
       "      <td>1.4770</td>\n",
       "      <td>28.2683</td>\n",
       "      <td>55.9966</td>\n",
       "      <td>1.2313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.199600</td>\n",
       "      <td>2.203983</td>\n",
       "      <td>0.225</td>\n",
       "      <td>1.1874</td>\n",
       "      <td>10.4436</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>69.2308</td>\n",
       "      <td>3.7514</td>\n",
       "      <td>0.3206</td>\n",
       "      <td>54.4065</td>\n",
       "      <td>2.2544</td>\n",
       "      <td>11.8138</td>\n",
       "      <td>60.9935</td>\n",
       "      <td>1.4159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.184100</td>\n",
       "      <td>2.208849</td>\n",
       "      <td>0.1567</td>\n",
       "      <td>0.9301</td>\n",
       "      <td>8.7107</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>67.5</td>\n",
       "      <td>3.7202</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>75.1938</td>\n",
       "      <td>2.3149</td>\n",
       "      <td>5.9076</td>\n",
       "      <td>63.0366</td>\n",
       "      <td>1.2483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.185200</td>\n",
       "      <td>2.207005</td>\n",
       "      <td>0.1722</td>\n",
       "      <td>1.4331</td>\n",
       "      <td>10.3157</td>\n",
       "      <td>0.029</td>\n",
       "      <td>69.0647</td>\n",
       "      <td>4.1934</td>\n",
       "      <td>0.3457</td>\n",
       "      <td>60.0302</td>\n",
       "      <td>2.2549</td>\n",
       "      <td>13.5807</td>\n",
       "      <td>59.3739</td>\n",
       "      <td>1.4111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.174100</td>\n",
       "      <td>2.202400</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>1.4819</td>\n",
       "      <td>10.5333</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>73.3840</td>\n",
       "      <td>3.4997</td>\n",
       "      <td>0.4371</td>\n",
       "      <td>61.9990</td>\n",
       "      <td>2.0745</td>\n",
       "      <td>13.3852</td>\n",
       "      <td>60.3074</td>\n",
       "      <td>1.3491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.179700</td>\n",
       "      <td>2.200829</td>\n",
       "      <td>0.2148</td>\n",
       "      <td>1.7576</td>\n",
       "      <td>10.1721</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>80.5233</td>\n",
       "      <td>3.0816</td>\n",
       "      <td>0.4337</td>\n",
       "      <td>62.4669</td>\n",
       "      <td>1.9791</td>\n",
       "      <td>12.1305</td>\n",
       "      <td>61.08</td>\n",
       "      <td>1.3864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.180800</td>\n",
       "      <td>2.206373</td>\n",
       "      <td>0.2267</td>\n",
       "      <td>1.3999</td>\n",
       "      <td>11.2817</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>77.3196</td>\n",
       "      <td>3.2479</td>\n",
       "      <td>0.5382</td>\n",
       "      <td>66.7764</td>\n",
       "      <td>1.8295</td>\n",
       "      <td>15.3864</td>\n",
       "      <td>60.9066</td>\n",
       "      <td>1.3689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.176300</td>\n",
       "      <td>2.204535</td>\n",
       "      <td>0.2855</td>\n",
       "      <td>1.4200</td>\n",
       "      <td>13.8359</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>80.0578</td>\n",
       "      <td>3.1911</td>\n",
       "      <td>1.4132</td>\n",
       "      <td>65.9854</td>\n",
       "      <td>1.8109</td>\n",
       "      <td>24.1117</td>\n",
       "      <td>58.6289</td>\n",
       "      <td>1.319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.172800</td>\n",
       "      <td>2.199093</td>\n",
       "      <td>0.28</td>\n",
       "      <td>1.5624</td>\n",
       "      <td>12.8245</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>76.4846</td>\n",
       "      <td>3.038</td>\n",
       "      <td>1.1098</td>\n",
       "      <td>65.1226</td>\n",
       "      <td>1.7729</td>\n",
       "      <td>20.3096</td>\n",
       "      <td>59.9932</td>\n",
       "      <td>1.3798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.174700</td>\n",
       "      <td>2.197882</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>1.4755</td>\n",
       "      <td>11.0373</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>80.1223</td>\n",
       "      <td>2.9815</td>\n",
       "      <td>0.7237</td>\n",
       "      <td>65.0194</td>\n",
       "      <td>1.5721</td>\n",
       "      <td>14.0695</td>\n",
       "      <td>62.0172</td>\n",
       "      <td>1.4031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.174900</td>\n",
       "      <td>2.196073</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>1.4614</td>\n",
       "      <td>13.3464</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>81.6537</td>\n",
       "      <td>2.9137</td>\n",
       "      <td>1.4566</td>\n",
       "      <td>65.9460</td>\n",
       "      <td>1.7721</td>\n",
       "      <td>22.3679</td>\n",
       "      <td>59.4107</td>\n",
       "      <td>1.353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.176900</td>\n",
       "      <td>2.197489</td>\n",
       "      <td>0.2802</td>\n",
       "      <td>1.5653</td>\n",
       "      <td>12.2928</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>79.8956</td>\n",
       "      <td>3.1425</td>\n",
       "      <td>1.0152</td>\n",
       "      <td>65.8587</td>\n",
       "      <td>1.8044</td>\n",
       "      <td>18.8287</td>\n",
       "      <td>60.2708</td>\n",
       "      <td>1.3682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.178600</td>\n",
       "      <td>2.196964</td>\n",
       "      <td>0.2778</td>\n",
       "      <td>1.5243</td>\n",
       "      <td>12.1396</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>81.3514</td>\n",
       "      <td>2.9946</td>\n",
       "      <td>0.9214</td>\n",
       "      <td>66.0631</td>\n",
       "      <td>1.8034</td>\n",
       "      <td>18.2564</td>\n",
       "      <td>60.4303</td>\n",
       "      <td>1.3956</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4370, training_loss=2.1916934853560317, metrics={'train_runtime': 4517.9523, 'train_samples_per_second': 7.738, 'train_steps_per_second': 0.967, 'total_flos': 0.0, 'train_loss': 2.1916934853560317, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# firstrate data no volume\n",
    "\n",
    "# SGCONV! lr of 1e-3, batch size 8 hidden size 1024,\n",
    "# fp16, NO dropout, weight decay\n",
    "# NO diagonal attention allowed, NO rotary embed, norm or residual on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4407' max='4407' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4407/4407 1:11:09, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.220000</td>\n",
       "      <td>2.187652</td>\n",
       "      <td>-0.031</td>\n",
       "      <td>-0.1425</td>\n",
       "      <td>6.4645</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>24.1379</td>\n",
       "      <td>0.3601</td>\n",
       "      <td>0.2179</td>\n",
       "      <td>29.2344</td>\n",
       "      <td>0.557</td>\n",
       "      <td>2.1444</td>\n",
       "      <td>40.2363</td>\n",
       "      <td>0.8548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.190100</td>\n",
       "      <td>2.198269</td>\n",
       "      <td>-0.0177</td>\n",
       "      <td>-0.1158</td>\n",
       "      <td>5.4631</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.016</td>\n",
       "      <td>37.2549</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>46.3537</td>\n",
       "      <td>0.6796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.187100</td>\n",
       "      <td>2.180087</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>-0.0326</td>\n",
       "      <td>5.6219</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>15.625</td>\n",
       "      <td>1.2553</td>\n",
       "      <td>0.2038</td>\n",
       "      <td>32.6854</td>\n",
       "      <td>0.6072</td>\n",
       "      <td>1.8546</td>\n",
       "      <td>46.8683</td>\n",
       "      <td>0.8487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.181000</td>\n",
       "      <td>2.179209</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>6.1098</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>43.8517</td>\n",
       "      <td>0.5461</td>\n",
       "      <td>4.7949</td>\n",
       "      <td>52.7368</td>\n",
       "      <td>0.9696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.180400</td>\n",
       "      <td>2.184720</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>5.4193</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>24.3902</td>\n",
       "      <td>0.4179</td>\n",
       "      <td>0.038</td>\n",
       "      <td>49.4505</td>\n",
       "      <td>0.7933</td>\n",
       "      <td>2.0929</td>\n",
       "      <td>56.6610</td>\n",
       "      <td>0.7902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.177600</td>\n",
       "      <td>2.178763</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.1851</td>\n",
       "      <td>5.6066</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>50.</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>0.095</td>\n",
       "      <td>45.2250</td>\n",
       "      <td>0.7581</td>\n",
       "      <td>1.9855</td>\n",
       "      <td>49.0495</td>\n",
       "      <td>0.9744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.180300</td>\n",
       "      <td>2.183460</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>6.0035</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>33.3333</td>\n",
       "      <td>0.2226</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>75.1648</td>\n",
       "      <td>0.7444</td>\n",
       "      <td>2.7303</td>\n",
       "      <td>60.2864</td>\n",
       "      <td>0.9349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.175100</td>\n",
       "      <td>2.179679</td>\n",
       "      <td>-0.0025</td>\n",
       "      <td>-0.0264</td>\n",
       "      <td>5.4435</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1473</td>\n",
       "      <td>40.2689</td>\n",
       "      <td>0.3282</td>\n",
       "      <td>2.3318</td>\n",
       "      <td>49.1616</td>\n",
       "      <td>0.9353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.175600</td>\n",
       "      <td>2.178945</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.1985</td>\n",
       "      <td>4.8669</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3218</td>\n",
       "      <td>47.0188</td>\n",
       "      <td>0.7521</td>\n",
       "      <td>1.7703</td>\n",
       "      <td>52.5680</td>\n",
       "      <td>0.9509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.177700</td>\n",
       "      <td>2.178137</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.2469</td>\n",
       "      <td>6.0138</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>50.</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>46.504</td>\n",
       "      <td>0.5508</td>\n",
       "      <td>3.3165</td>\n",
       "      <td>52.1363</td>\n",
       "      <td>0.9324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.171700</td>\n",
       "      <td>2.178968</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>4.8883</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>60.0198</td>\n",
       "      <td>1.3534</td>\n",
       "      <td>2.0763</td>\n",
       "      <td>53.563</td>\n",
       "      <td>0.9783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.175500</td>\n",
       "      <td>2.177012</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>0.0991</td>\n",
       "      <td>5.1274</td>\n",
       "      <td>0.002</td>\n",
       "      <td>94.7368</td>\n",
       "      <td>2.2014</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>57.1429</td>\n",
       "      <td>1.2773</td>\n",
       "      <td>2.5409</td>\n",
       "      <td>54.6947</td>\n",
       "      <td>0.9516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.174600</td>\n",
       "      <td>2.178370</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.22</td>\n",
       "      <td>5.6223</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.5445</td>\n",
       "      <td>45.7488</td>\n",
       "      <td>0.5714</td>\n",
       "      <td>3.0727</td>\n",
       "      <td>49.1279</td>\n",
       "      <td>0.9233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.167200</td>\n",
       "      <td>2.177537</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>5.6525</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.4371</td>\n",
       "      <td>51.7891</td>\n",
       "      <td>0.7297</td>\n",
       "      <td>2.8276</td>\n",
       "      <td>51.8290</td>\n",
       "      <td>0.8979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.170900</td>\n",
       "      <td>2.177057</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.1572</td>\n",
       "      <td>6.0577</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3374</td>\n",
       "      <td>51.8541</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>4.0558</td>\n",
       "      <td>53.7085</td>\n",
       "      <td>0.9411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.172400</td>\n",
       "      <td>2.175043</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.2539</td>\n",
       "      <td>6.0647</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>56.6667</td>\n",
       "      <td>0.9197</td>\n",
       "      <td>0.6566</td>\n",
       "      <td>50.7702</td>\n",
       "      <td>0.7607</td>\n",
       "      <td>3.2380</td>\n",
       "      <td>51.7518</td>\n",
       "      <td>0.9832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.169200</td>\n",
       "      <td>2.174808</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.2569</td>\n",
       "      <td>5.1783</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3672</td>\n",
       "      <td>51.8171</td>\n",
       "      <td>0.7398</td>\n",
       "      <td>2.6253</td>\n",
       "      <td>50.7268</td>\n",
       "      <td>0.9680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.170000</td>\n",
       "      <td>2.174528</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.2710</td>\n",
       "      <td>5.8157</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>71.4286</td>\n",
       "      <td>1.3091</td>\n",
       "      <td>0.4459</td>\n",
       "      <td>52.3620</td>\n",
       "      <td>0.6957</td>\n",
       "      <td>3.4906</td>\n",
       "      <td>53.5249</td>\n",
       "      <td>0.9958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.165900</td>\n",
       "      <td>2.173964</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.2803</td>\n",
       "      <td>5.8983</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>70.</td>\n",
       "      <td>1.7936</td>\n",
       "      <td>0.3984</td>\n",
       "      <td>52.3423</td>\n",
       "      <td>0.7195</td>\n",
       "      <td>3.3343</td>\n",
       "      <td>53.8324</td>\n",
       "      <td>1.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.166200</td>\n",
       "      <td>2.173504</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.2739</td>\n",
       "      <td>5.7829</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.5336</td>\n",
       "      <td>52.7653</td>\n",
       "      <td>0.7557</td>\n",
       "      <td>3.237</td>\n",
       "      <td>53.3308</td>\n",
       "      <td>1.0195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.167900</td>\n",
       "      <td>2.174058</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.2789</td>\n",
       "      <td>5.8195</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>87.5</td>\n",
       "      <td>1.9143</td>\n",
       "      <td>0.5626</td>\n",
       "      <td>52.2424</td>\n",
       "      <td>0.7741</td>\n",
       "      <td>3.2293</td>\n",
       "      <td>53.1966</td>\n",
       "      <td>1.0121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>2.172700</td>\n",
       "      <td>2.173944</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.2801</td>\n",
       "      <td>5.8367</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>92.3077</td>\n",
       "      <td>3.2993</td>\n",
       "      <td>0.5827</td>\n",
       "      <td>52.1832</td>\n",
       "      <td>0.786</td>\n",
       "      <td>3.2479</td>\n",
       "      <td>53.1863</td>\n",
       "      <td>1.0146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4407, training_loss=2.176770738931045, metrics={'train_runtime': 4274.2353, 'train_samples_per_second': 8.248, 'train_steps_per_second': 1.031, 'total_flos': 0.0, 'train_loss': 2.176770738931045, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OANDA finnhub data no volume\n",
    "\n",
    "# SGCONV! lr of 1e-3, batch size 8 hidden size 1024,\n",
    "# fp16, NO dropout, weight decay\n",
    "# NO diagonal attention allowed, NO rotary embed, norm or residual on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3398' max='4407' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3398/4407 25:07 < 07:27, 2.25 it/s, Epoch 0.77/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.227400</td>\n",
       "      <td>2.188564</td>\n",
       "      <td>-0.0206</td>\n",
       "      <td>-0.1159</td>\n",
       "      <td>5.6270</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>66.6667</td>\n",
       "      <td>0.4501</td>\n",
       "      <td>0.0717</td>\n",
       "      <td>25.4360</td>\n",
       "      <td>0.4706</td>\n",
       "      <td>1.2853</td>\n",
       "      <td>37.6572</td>\n",
       "      <td>0.8081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.189500</td>\n",
       "      <td>2.195636</td>\n",
       "      <td>-0.0163</td>\n",
       "      <td>-0.0995</td>\n",
       "      <td>5.1954</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>35.2941</td>\n",
       "      <td>0.5145</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>44.0891</td>\n",
       "      <td>0.7485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.181500</td>\n",
       "      <td>2.182680</td>\n",
       "      <td>-0.0103</td>\n",
       "      <td>-0.0543</td>\n",
       "      <td>5.6947</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>18.6047</td>\n",
       "      <td>0.3742</td>\n",
       "      <td>0.1315</td>\n",
       "      <td>34.6550</td>\n",
       "      <td>0.8360</td>\n",
       "      <td>1.7467</td>\n",
       "      <td>47.4869</td>\n",
       "      <td>0.8045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.180100</td>\n",
       "      <td>2.180270</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.1732</td>\n",
       "      <td>5.6727</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0533</td>\n",
       "      <td>33.2681</td>\n",
       "      <td>0.313</td>\n",
       "      <td>3.3532</td>\n",
       "      <td>52.3617</td>\n",
       "      <td>0.9107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.178900</td>\n",
       "      <td>2.184605</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>-0.003</td>\n",
       "      <td>5.5146</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>25.</td>\n",
       "      <td>0.5593</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>54.1096</td>\n",
       "      <td>0.7466</td>\n",
       "      <td>1.8253</td>\n",
       "      <td>58.2348</td>\n",
       "      <td>0.7710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.176800</td>\n",
       "      <td>2.180275</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.1499</td>\n",
       "      <td>5.6542</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>40.</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>41.0575</td>\n",
       "      <td>0.6331</td>\n",
       "      <td>2.1548</td>\n",
       "      <td>47.6022</td>\n",
       "      <td>0.9732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.179800</td>\n",
       "      <td>2.184742</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.1604</td>\n",
       "      <td>5.5228</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>86.6972</td>\n",
       "      <td>0.4913</td>\n",
       "      <td>1.9391</td>\n",
       "      <td>60.5313</td>\n",
       "      <td>0.8973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.175400</td>\n",
       "      <td>2.180443</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0034</td>\n",
       "      <td>5.2729</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1116</td>\n",
       "      <td>36.3551</td>\n",
       "      <td>0.3165</td>\n",
       "      <td>2.3695</td>\n",
       "      <td>50.1628</td>\n",
       "      <td>0.9041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.175700</td>\n",
       "      <td>2.178481</td>\n",
       "      <td>0.0163</td>\n",
       "      <td>0.2107</td>\n",
       "      <td>4.757</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>47.6907</td>\n",
       "      <td>0.5832</td>\n",
       "      <td>1.6609</td>\n",
       "      <td>53.5878</td>\n",
       "      <td>0.867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.177600</td>\n",
       "      <td>2.178528</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>5.9153</td>\n",
       "      <td>0.002</td>\n",
       "      <td>63.1579</td>\n",
       "      <td>0.1797</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>56.7127</td>\n",
       "      <td>0.5402</td>\n",
       "      <td>3.2639</td>\n",
       "      <td>51.8753</td>\n",
       "      <td>0.9301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.172100</td>\n",
       "      <td>2.179314</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>4.9282</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>85.7143</td>\n",
       "      <td>1.8157</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>63.6605</td>\n",
       "      <td>0.9512</td>\n",
       "      <td>2.2285</td>\n",
       "      <td>54.3141</td>\n",
       "      <td>0.9395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.175900</td>\n",
       "      <td>2.178197</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>5.048</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0675</td>\n",
       "      <td>68.3153</td>\n",
       "      <td>1.9143</td>\n",
       "      <td>2.1571</td>\n",
       "      <td>54.7880</td>\n",
       "      <td>0.9365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.174900</td>\n",
       "      <td>2.178337</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>0.1852</td>\n",
       "      <td>5.3998</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>91.6667</td>\n",
       "      <td>1.3929</td>\n",
       "      <td>0.3036</td>\n",
       "      <td>47.6305</td>\n",
       "      <td>0.5378</td>\n",
       "      <td>3.0351</td>\n",
       "      <td>49.1480</td>\n",
       "      <td>0.8634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.167800</td>\n",
       "      <td>2.177496</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>5.5875</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2386</td>\n",
       "      <td>54.4580</td>\n",
       "      <td>0.6094</td>\n",
       "      <td>2.8617</td>\n",
       "      <td>51.6050</td>\n",
       "      <td>0.8717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.171800</td>\n",
       "      <td>2.177266</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>5.8744</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1728</td>\n",
       "      <td>56.548</td>\n",
       "      <td>0.7081</td>\n",
       "      <td>3.9326</td>\n",
       "      <td>54.3444</td>\n",
       "      <td>0.9108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.173200</td>\n",
       "      <td>2.175159</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>5.9729</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3959</td>\n",
       "      <td>52.0411</td>\n",
       "      <td>0.6363</td>\n",
       "      <td>3.3091</td>\n",
       "      <td>52.0986</td>\n",
       "      <td>0.9796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-abc3145f04b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ce loss with conditioned kelly betting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1738\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2486\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2487\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2488\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2490\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub data no volume\n",
    "\n",
    "# SGCONV! lr of 1e-3, batch size 8 hidden size 512,\n",
    "# fp16, NO dropout, weight decay\n",
    "# NO diagonal attention allowed, NO rotary embed, norm or residual on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1837' max='4026' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1837/4026 12:38 < 15:04, 2.42 it/s, Epoch 0.46/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.232700</td>\n",
       "      <td>2.195208</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>4.5811</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0040</td>\n",
       "      <td>60.</td>\n",
       "      <td>2.2225</td>\n",
       "      <td>0.3617</td>\n",
       "      <td>42.7571</td>\n",
       "      <td>1.1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.194400</td>\n",
       "      <td>2.188654</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.021</td>\n",
       "      <td>5.1786</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>29.5597</td>\n",
       "      <td>0.3414</td>\n",
       "      <td>1.6661</td>\n",
       "      <td>40.4783</td>\n",
       "      <td>0.6777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.186300</td>\n",
       "      <td>2.186910</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>4.1490</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>46.</td>\n",
       "      <td>0.2779</td>\n",
       "      <td>0.8453</td>\n",
       "      <td>41.4850</td>\n",
       "      <td>0.5658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.182300</td>\n",
       "      <td>2.181452</td>\n",
       "      <td>0.0138</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>5.0521</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>20.</td>\n",
       "      <td>0.1284</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>29.7297</td>\n",
       "      <td>0.2408</td>\n",
       "      <td>1.2248</td>\n",
       "      <td>56.0696</td>\n",
       "      <td>0.7624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.185100</td>\n",
       "      <td>2.189359</td>\n",
       "      <td>-0.0144</td>\n",
       "      <td>-0.1099</td>\n",
       "      <td>5.8305</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>10.8108</td>\n",
       "      <td>0.2840</td>\n",
       "      <td>0.2177</td>\n",
       "      <td>33.0688</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>2.4124</td>\n",
       "      <td>43.8535</td>\n",
       "      <td>0.7403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.180200</td>\n",
       "      <td>2.185004</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>4.8414</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>21.7391</td>\n",
       "      <td>0.3164</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>48.7078</td>\n",
       "      <td>1.3516</td>\n",
       "      <td>1.5452</td>\n",
       "      <td>47.3951</td>\n",
       "      <td>0.8241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.180700</td>\n",
       "      <td>2.186272</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0220</td>\n",
       "      <td>5.4116</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>50.</td>\n",
       "      <td>0.1280</td>\n",
       "      <td>0.2699</td>\n",
       "      <td>38.2253</td>\n",
       "      <td>0.4572</td>\n",
       "      <td>2.3795</td>\n",
       "      <td>46.3072</td>\n",
       "      <td>0.8331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.182900</td>\n",
       "      <td>2.179692</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>6.1707</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>37.7816</td>\n",
       "      <td>0.416</td>\n",
       "      <td>2.837</td>\n",
       "      <td>53.8768</td>\n",
       "      <td>0.8557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.180900</td>\n",
       "      <td>2.183378</td>\n",
       "      <td>-0.001</td>\n",
       "      <td>-0.0139</td>\n",
       "      <td>5.0281</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1330</td>\n",
       "      <td>38.5281</td>\n",
       "      <td>0.4297</td>\n",
       "      <td>2.3575</td>\n",
       "      <td>49.8412</td>\n",
       "      <td>0.8325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-2094252bbcb0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ce loss with conditioned kelly betting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1714\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m                 \u001b[1;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m         \u001b[1;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2227\u001b[1;33m         return self._getitem(\n\u001b[0m\u001b[0;32m   2228\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2229\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[1;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[0;32m   2210\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2212\u001b[1;33m         formatted_output = format_table(\n\u001b[0m\u001b[0;32m   2213\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2214\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"column\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mRowFormat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mColumnFormat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchFormat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"row\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"column\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mformat_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFormatter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mextract_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPythonArrowExtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseArrowExtractor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unnest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pydict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36m_unnest\u001b[1;34m(py_dict)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_unnest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_dict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[1;34m\"\"\"Return the first element of a batch (dict) as a row (dict)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpy_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub data no volume\n",
    "\n",
    "# SGCONV! lr of 1e-3, batch size 8 hidden size 320,\n",
    "# fp16, NO dropout, weight decay\n",
    "# NO diagonal attention allowed, NO rotary embed, norm or residual on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4370' max='4370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4370/4370 26:04, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.271000</td>\n",
       "      <td>2.230693</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>5.7062</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>65.3333</td>\n",
       "      <td>4.3685</td>\n",
       "      <td>0.09</td>\n",
       "      <td>63.0359</td>\n",
       "      <td>1.4701</td>\n",
       "      <td>1.7201</td>\n",
       "      <td>59.8509</td>\n",
       "      <td>1.1555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.217600</td>\n",
       "      <td>2.225278</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.6827</td>\n",
       "      <td>6.4037</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>69.9029</td>\n",
       "      <td>5.5255</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>66.5625</td>\n",
       "      <td>1.7779</td>\n",
       "      <td>1.4557</td>\n",
       "      <td>57.6463</td>\n",
       "      <td>1.3213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.207200</td>\n",
       "      <td>2.241364</td>\n",
       "      <td>0.0573</td>\n",
       "      <td>0.5304</td>\n",
       "      <td>5.1940</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>58.8235</td>\n",
       "      <td>9.3187</td>\n",
       "      <td>0.0589</td>\n",
       "      <td>42.8319</td>\n",
       "      <td>3.1488</td>\n",
       "      <td>0.7115</td>\n",
       "      <td>53.8834</td>\n",
       "      <td>1.4850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.197700</td>\n",
       "      <td>2.210183</td>\n",
       "      <td>0.0892</td>\n",
       "      <td>0.8594</td>\n",
       "      <td>6.5144</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>53.5714</td>\n",
       "      <td>6.5159</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>54.1806</td>\n",
       "      <td>3.8670</td>\n",
       "      <td>1.7302</td>\n",
       "      <td>59.6215</td>\n",
       "      <td>1.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.205000</td>\n",
       "      <td>2.213922</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.6076</td>\n",
       "      <td>6.9463</td>\n",
       "      <td>0.0107</td>\n",
       "      <td>66.9903</td>\n",
       "      <td>5.4746</td>\n",
       "      <td>0.041</td>\n",
       "      <td>70.2290</td>\n",
       "      <td>3.1549</td>\n",
       "      <td>1.0588</td>\n",
       "      <td>60.5082</td>\n",
       "      <td>1.4909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.190200</td>\n",
       "      <td>2.215203</td>\n",
       "      <td>0.1577</td>\n",
       "      <td>1.0051</td>\n",
       "      <td>9.7561</td>\n",
       "      <td>0.0098</td>\n",
       "      <td>60.6383</td>\n",
       "      <td>6.6245</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>54.4218</td>\n",
       "      <td>3.1242</td>\n",
       "      <td>9.8843</td>\n",
       "      <td>58.8149</td>\n",
       "      <td>1.3665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.196600</td>\n",
       "      <td>2.210343</td>\n",
       "      <td>0.1259</td>\n",
       "      <td>1.0800</td>\n",
       "      <td>7.3453</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>72.3982</td>\n",
       "      <td>3.549</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>72.2772</td>\n",
       "      <td>2.3376</td>\n",
       "      <td>2.7651</td>\n",
       "      <td>59.9706</td>\n",
       "      <td>1.4347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.188700</td>\n",
       "      <td>2.209135</td>\n",
       "      <td>0.1739</td>\n",
       "      <td>0.8220</td>\n",
       "      <td>9.6679</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>74.8954</td>\n",
       "      <td>3.3733</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>64.6617</td>\n",
       "      <td>3.0852</td>\n",
       "      <td>7.6354</td>\n",
       "      <td>61.2657</td>\n",
       "      <td>1.4929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.188000</td>\n",
       "      <td>2.213350</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>1.1639</td>\n",
       "      <td>10.6311</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>72.1053</td>\n",
       "      <td>3.5221</td>\n",
       "      <td>0.1497</td>\n",
       "      <td>63.7187</td>\n",
       "      <td>1.4271</td>\n",
       "      <td>14.3504</td>\n",
       "      <td>58.6837</td>\n",
       "      <td>1.2741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.193700</td>\n",
       "      <td>2.205798</td>\n",
       "      <td>0.2006</td>\n",
       "      <td>1.2266</td>\n",
       "      <td>10.3597</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>75.3488</td>\n",
       "      <td>3.3845</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>51.1768</td>\n",
       "      <td>2.4396</td>\n",
       "      <td>12.3673</td>\n",
       "      <td>59.6027</td>\n",
       "      <td>1.3792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.184100</td>\n",
       "      <td>2.211518</td>\n",
       "      <td>0.1527</td>\n",
       "      <td>1.1032</td>\n",
       "      <td>9.2166</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>69.4444</td>\n",
       "      <td>4.413</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>60.5823</td>\n",
       "      <td>2.2477</td>\n",
       "      <td>7.1459</td>\n",
       "      <td>61.3057</td>\n",
       "      <td>1.2738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.183700</td>\n",
       "      <td>2.207210</td>\n",
       "      <td>0.1486</td>\n",
       "      <td>1.5832</td>\n",
       "      <td>8.3704</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>75.</td>\n",
       "      <td>3.4689</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>62.2973</td>\n",
       "      <td>2.6867</td>\n",
       "      <td>6.3602</td>\n",
       "      <td>61.8309</td>\n",
       "      <td>1.4496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.176400</td>\n",
       "      <td>2.204481</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>1.4483</td>\n",
       "      <td>10.2196</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>70.4545</td>\n",
       "      <td>3.4322</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>55.5766</td>\n",
       "      <td>2.1473</td>\n",
       "      <td>12.4742</td>\n",
       "      <td>59.9124</td>\n",
       "      <td>1.3742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.182400</td>\n",
       "      <td>2.205279</td>\n",
       "      <td>0.1991</td>\n",
       "      <td>1.5885</td>\n",
       "      <td>9.9351</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>78.0405</td>\n",
       "      <td>3.1617</td>\n",
       "      <td>0.2468</td>\n",
       "      <td>56.7385</td>\n",
       "      <td>2.0587</td>\n",
       "      <td>11.4287</td>\n",
       "      <td>60.9</td>\n",
       "      <td>1.3774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.181800</td>\n",
       "      <td>2.203535</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>1.3812</td>\n",
       "      <td>9.9348</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>78.0669</td>\n",
       "      <td>3.2691</td>\n",
       "      <td>0.2043</td>\n",
       "      <td>58.0398</td>\n",
       "      <td>1.8918</td>\n",
       "      <td>10.8183</td>\n",
       "      <td>61.4041</td>\n",
       "      <td>1.3719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.179200</td>\n",
       "      <td>2.204987</td>\n",
       "      <td>0.2377</td>\n",
       "      <td>1.4373</td>\n",
       "      <td>11.8542</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>77.4691</td>\n",
       "      <td>3.1766</td>\n",
       "      <td>0.5118</td>\n",
       "      <td>62.4287</td>\n",
       "      <td>1.9367</td>\n",
       "      <td>17.6455</td>\n",
       "      <td>59.7121</td>\n",
       "      <td>1.3391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.175700</td>\n",
       "      <td>2.201742</td>\n",
       "      <td>0.2345</td>\n",
       "      <td>1.6028</td>\n",
       "      <td>11.6815</td>\n",
       "      <td>0.0334</td>\n",
       "      <td>78.125</td>\n",
       "      <td>3.2097</td>\n",
       "      <td>0.5409</td>\n",
       "      <td>62.8494</td>\n",
       "      <td>1.852</td>\n",
       "      <td>17.2127</td>\n",
       "      <td>59.8412</td>\n",
       "      <td>1.3435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.178500</td>\n",
       "      <td>2.202770</td>\n",
       "      <td>0.2157</td>\n",
       "      <td>1.3908</td>\n",
       "      <td>10.2562</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>77.3700</td>\n",
       "      <td>3.2532</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>60.94</td>\n",
       "      <td>1.6652</td>\n",
       "      <td>11.4272</td>\n",
       "      <td>62.0535</td>\n",
       "      <td>1.3677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.177800</td>\n",
       "      <td>2.200579</td>\n",
       "      <td>0.2393</td>\n",
       "      <td>1.5318</td>\n",
       "      <td>11.5909</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>79.7654</td>\n",
       "      <td>3.007</td>\n",
       "      <td>0.4844</td>\n",
       "      <td>63.474</td>\n",
       "      <td>1.998</td>\n",
       "      <td>17.1461</td>\n",
       "      <td>59.8165</td>\n",
       "      <td>1.3408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>2.201719</td>\n",
       "      <td>0.2355</td>\n",
       "      <td>1.5291</td>\n",
       "      <td>11.3775</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>78.3133</td>\n",
       "      <td>3.2061</td>\n",
       "      <td>0.4160</td>\n",
       "      <td>62.9073</td>\n",
       "      <td>1.865</td>\n",
       "      <td>16.3027</td>\n",
       "      <td>60.0196</td>\n",
       "      <td>1.3507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>2.182900</td>\n",
       "      <td>2.201185</td>\n",
       "      <td>0.2312</td>\n",
       "      <td>1.5269</td>\n",
       "      <td>11.1206</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>78.4661</td>\n",
       "      <td>3.1729</td>\n",
       "      <td>0.3697</td>\n",
       "      <td>62.6058</td>\n",
       "      <td>1.7349</td>\n",
       "      <td>15.1508</td>\n",
       "      <td>60.3467</td>\n",
       "      <td>1.3780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4370, training_loss=2.1917871401020808, metrics={'train_runtime': 1567.6106, 'train_samples_per_second': 22.3, 'train_steps_per_second': 2.788, 'total_flos': 0.0, 'train_loss': 2.1917871401020808, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# firstrate data no volume\n",
    "\n",
    "# SGCONV! lr of 1e-3, batch size 8 hidden size 320,\n",
    "# fp16, NO dropout, weight decay\n",
    "# NO diagonal attention allowed, NO rotary embed, or norm on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3611' max='4370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3611/4370 21:57 < 04:37, 2.74 it/s, Epoch 0.83/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.264900</td>\n",
       "      <td>2.229113</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.6311</td>\n",
       "      <td>4.9520</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>76.</td>\n",
       "      <td>2.5136</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>60.0746</td>\n",
       "      <td>2.3828</td>\n",
       "      <td>0.7740</td>\n",
       "      <td>59.1675</td>\n",
       "      <td>1.2146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.211900</td>\n",
       "      <td>2.217265</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>7.2526</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>65.812</td>\n",
       "      <td>5.7062</td>\n",
       "      <td>0.0559</td>\n",
       "      <td>64.7388</td>\n",
       "      <td>2.5893</td>\n",
       "      <td>1.8538</td>\n",
       "      <td>59.2947</td>\n",
       "      <td>1.2525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.203300</td>\n",
       "      <td>2.227097</td>\n",
       "      <td>0.058</td>\n",
       "      <td>0.4592</td>\n",
       "      <td>5.5918</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>63.3333</td>\n",
       "      <td>7.3884</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>62.1359</td>\n",
       "      <td>2.7424</td>\n",
       "      <td>0.4416</td>\n",
       "      <td>57.7096</td>\n",
       "      <td>1.5507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.193900</td>\n",
       "      <td>2.209114</td>\n",
       "      <td>0.1030</td>\n",
       "      <td>0.97</td>\n",
       "      <td>7.3735</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>56.5217</td>\n",
       "      <td>4.2156</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>55.914</td>\n",
       "      <td>4.9033</td>\n",
       "      <td>4.0070</td>\n",
       "      <td>59.057</td>\n",
       "      <td>1.4891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.199400</td>\n",
       "      <td>2.211903</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>0.6121</td>\n",
       "      <td>8.0036</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>64.9123</td>\n",
       "      <td>5.9017</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>74.0061</td>\n",
       "      <td>2.5981</td>\n",
       "      <td>2.0531</td>\n",
       "      <td>63.7532</td>\n",
       "      <td>1.3343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.187500</td>\n",
       "      <td>2.219035</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.8958</td>\n",
       "      <td>12.1946</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>42.5287</td>\n",
       "      <td>9.5385</td>\n",
       "      <td>0.2964</td>\n",
       "      <td>61.3085</td>\n",
       "      <td>2.1953</td>\n",
       "      <td>21.5696</td>\n",
       "      <td>56.4234</td>\n",
       "      <td>1.3265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.194300</td>\n",
       "      <td>2.208715</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>0.8761</td>\n",
       "      <td>7.7654</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>72.9592</td>\n",
       "      <td>3.71</td>\n",
       "      <td>0.0670</td>\n",
       "      <td>69.0513</td>\n",
       "      <td>1.8592</td>\n",
       "      <td>3.4253</td>\n",
       "      <td>58.9315</td>\n",
       "      <td>1.4020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.186700</td>\n",
       "      <td>2.206259</td>\n",
       "      <td>0.1644</td>\n",
       "      <td>0.7964</td>\n",
       "      <td>9.3841</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>72.3214</td>\n",
       "      <td>3.8677</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>64.3836</td>\n",
       "      <td>2.9664</td>\n",
       "      <td>7.1413</td>\n",
       "      <td>61.1348</td>\n",
       "      <td>1.4599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.186300</td>\n",
       "      <td>2.207227</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>1.3044</td>\n",
       "      <td>11.0333</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>71.9512</td>\n",
       "      <td>3.8237</td>\n",
       "      <td>0.2659</td>\n",
       "      <td>51.2549</td>\n",
       "      <td>2.2243</td>\n",
       "      <td>15.9507</td>\n",
       "      <td>57.5686</td>\n",
       "      <td>1.3904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.192000</td>\n",
       "      <td>2.202816</td>\n",
       "      <td>0.1925</td>\n",
       "      <td>1.2530</td>\n",
       "      <td>10.0022</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>69.3182</td>\n",
       "      <td>4.0807</td>\n",
       "      <td>0.2779</td>\n",
       "      <td>47.8049</td>\n",
       "      <td>2.2724</td>\n",
       "      <td>10.9574</td>\n",
       "      <td>59.8643</td>\n",
       "      <td>1.4378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.182400</td>\n",
       "      <td>2.211895</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>9.9535</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>71.9424</td>\n",
       "      <td>4.7611</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>65.4517</td>\n",
       "      <td>1.8051</td>\n",
       "      <td>9.4825</td>\n",
       "      <td>60.9516</td>\n",
       "      <td>1.2415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.181800</td>\n",
       "      <td>2.204054</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>1.6178</td>\n",
       "      <td>9.1064</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>66.6667</td>\n",
       "      <td>4.1054</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>57.5686</td>\n",
       "      <td>2.6941</td>\n",
       "      <td>9.225</td>\n",
       "      <td>60.5046</td>\n",
       "      <td>1.4662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.174500</td>\n",
       "      <td>2.201927</td>\n",
       "      <td>0.2031</td>\n",
       "      <td>1.521</td>\n",
       "      <td>10.9944</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>70.9402</td>\n",
       "      <td>3.6025</td>\n",
       "      <td>0.388</td>\n",
       "      <td>55.9258</td>\n",
       "      <td>2.0957</td>\n",
       "      <td>15.4583</td>\n",
       "      <td>59.3817</td>\n",
       "      <td>1.3889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.180800</td>\n",
       "      <td>2.202982</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>1.6611</td>\n",
       "      <td>10.5324</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>76.1364</td>\n",
       "      <td>3.2669</td>\n",
       "      <td>0.4144</td>\n",
       "      <td>57.9014</td>\n",
       "      <td>1.9770</td>\n",
       "      <td>13.6984</td>\n",
       "      <td>60.7187</td>\n",
       "      <td>1.4017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.180300</td>\n",
       "      <td>2.202178</td>\n",
       "      <td>0.1987</td>\n",
       "      <td>1.3577</td>\n",
       "      <td>10.6067</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>76.1062</td>\n",
       "      <td>3.259</td>\n",
       "      <td>0.3093</td>\n",
       "      <td>60.0472</td>\n",
       "      <td>1.8316</td>\n",
       "      <td>13.0508</td>\n",
       "      <td>60.6382</td>\n",
       "      <td>1.3763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.177800</td>\n",
       "      <td>2.203414</td>\n",
       "      <td>0.2366</td>\n",
       "      <td>1.4479</td>\n",
       "      <td>12.4823</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>71.9723</td>\n",
       "      <td>3.906</td>\n",
       "      <td>0.825</td>\n",
       "      <td>62.8286</td>\n",
       "      <td>1.9014</td>\n",
       "      <td>20.0137</td>\n",
       "      <td>58.8369</td>\n",
       "      <td>1.3428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.174200</td>\n",
       "      <td>2.199774</td>\n",
       "      <td>0.2420</td>\n",
       "      <td>1.5902</td>\n",
       "      <td>12.3046</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>75.0865</td>\n",
       "      <td>3.3535</td>\n",
       "      <td>0.9223</td>\n",
       "      <td>63.8779</td>\n",
       "      <td>1.9333</td>\n",
       "      <td>19.2839</td>\n",
       "      <td>59.2965</td>\n",
       "      <td>1.3697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.176800</td>\n",
       "      <td>2.199737</td>\n",
       "      <td>0.23</td>\n",
       "      <td>1.5136</td>\n",
       "      <td>11.1351</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>68.9542</td>\n",
       "      <td>3.5811</td>\n",
       "      <td>0.4892</td>\n",
       "      <td>64.6633</td>\n",
       "      <td>1.8100</td>\n",
       "      <td>14.8665</td>\n",
       "      <td>61.22</td>\n",
       "      <td>1.3799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f320a7af0571>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ce loss with conditioned kelly betting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1783\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m                             \u001b[1;31m# Revert to normal clipping otherwise, handling Apex or full precision\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1785\u001b[1;33m                             nn.utils.clip_grad_norm_(\n\u001b[0m\u001b[0;32m   1786\u001b[0m                                 \u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaster_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_apex\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m                                 \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36mclip_grad_norm_\u001b[1;34m(parameters, max_norm, norm_type, error_if_nonfinite)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         raise RuntimeError(\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\utils\\clip_grad.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnorms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mtotal_norm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0merror_if_nonfinite\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_or\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtotal_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_norm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         raise RuntimeError(\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# firstrate data no volume\n",
    "\n",
    "# SGCONV! lr of 1e-3, batch size 8 hidden size 320,\n",
    "# fp16, NO dropout, weight decay\n",
    "# NO diagonal attention allowed, NO rotary embed, norm or residual on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3863' max='4370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3863/4370 23:01 < 03:01, 2.80 it/s, Epoch 0.88/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.268200</td>\n",
       "      <td>2.239735</td>\n",
       "      <td>0.0620</td>\n",
       "      <td>0.988</td>\n",
       "      <td>4.6885</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>69.0909</td>\n",
       "      <td>3.2635</td>\n",
       "      <td>0.0448</td>\n",
       "      <td>67.2093</td>\n",
       "      <td>1.6570</td>\n",
       "      <td>0.6962</td>\n",
       "      <td>59.3230</td>\n",
       "      <td>1.1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.215000</td>\n",
       "      <td>2.218279</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.7048</td>\n",
       "      <td>5.8088</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>70.6349</td>\n",
       "      <td>4.9675</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>72.5055</td>\n",
       "      <td>3.2190</td>\n",
       "      <td>0.913</td>\n",
       "      <td>60.9068</td>\n",
       "      <td>1.6044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.207300</td>\n",
       "      <td>2.230922</td>\n",
       "      <td>0.0622</td>\n",
       "      <td>0.4952</td>\n",
       "      <td>5.3525</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>56.0000</td>\n",
       "      <td>8.3060</td>\n",
       "      <td>0.0572</td>\n",
       "      <td>56.6485</td>\n",
       "      <td>3.4767</td>\n",
       "      <td>0.6537</td>\n",
       "      <td>55.1125</td>\n",
       "      <td>1.3348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.196200</td>\n",
       "      <td>2.208523</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>0.913</td>\n",
       "      <td>5.8864</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>54.8387</td>\n",
       "      <td>6.9334</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>67.9012</td>\n",
       "      <td>3.4866</td>\n",
       "      <td>0.9249</td>\n",
       "      <td>60.7892</td>\n",
       "      <td>1.5586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.201700</td>\n",
       "      <td>2.212023</td>\n",
       "      <td>0.1134</td>\n",
       "      <td>0.6804</td>\n",
       "      <td>7.4853</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>73.8462</td>\n",
       "      <td>5.0778</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>67.3171</td>\n",
       "      <td>3.0497</td>\n",
       "      <td>2.2404</td>\n",
       "      <td>61.7798</td>\n",
       "      <td>1.1547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.188200</td>\n",
       "      <td>2.213837</td>\n",
       "      <td>0.1479</td>\n",
       "      <td>0.9606</td>\n",
       "      <td>9.8281</td>\n",
       "      <td>0.0116</td>\n",
       "      <td>63.964</td>\n",
       "      <td>5.9025</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>61.1801</td>\n",
       "      <td>3.0235</td>\n",
       "      <td>11.1763</td>\n",
       "      <td>58.8497</td>\n",
       "      <td>1.3592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.195400</td>\n",
       "      <td>2.209037</td>\n",
       "      <td>0.1199</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>7.4521</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>71.7822</td>\n",
       "      <td>3.7082</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>69.6154</td>\n",
       "      <td>2.3321</td>\n",
       "      <td>2.9434</td>\n",
       "      <td>60.7553</td>\n",
       "      <td>1.4525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.187400</td>\n",
       "      <td>2.206240</td>\n",
       "      <td>0.1658</td>\n",
       "      <td>0.7796</td>\n",
       "      <td>9.4529</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>73.0769</td>\n",
       "      <td>3.2652</td>\n",
       "      <td>0.0710</td>\n",
       "      <td>70.4846</td>\n",
       "      <td>3.1809</td>\n",
       "      <td>7.8769</td>\n",
       "      <td>61.328</td>\n",
       "      <td>1.4181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.187200</td>\n",
       "      <td>2.208302</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>1.2654</td>\n",
       "      <td>9.1741</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>75.9615</td>\n",
       "      <td>3.3266</td>\n",
       "      <td>0.0615</td>\n",
       "      <td>60.</td>\n",
       "      <td>2.8277</td>\n",
       "      <td>9.1404</td>\n",
       "      <td>59.4855</td>\n",
       "      <td>1.4076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.193700</td>\n",
       "      <td>2.203616</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>1.1746</td>\n",
       "      <td>9.7183</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>74.7664</td>\n",
       "      <td>3.3666</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>60.3996</td>\n",
       "      <td>2.5884</td>\n",
       "      <td>10.0761</td>\n",
       "      <td>60.6267</td>\n",
       "      <td>1.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.183300</td>\n",
       "      <td>2.209929</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>1.0471</td>\n",
       "      <td>9.0699</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>72.6776</td>\n",
       "      <td>3.8569</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>70.4778</td>\n",
       "      <td>2.5219</td>\n",
       "      <td>7.0629</td>\n",
       "      <td>61.2481</td>\n",
       "      <td>1.3529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.182800</td>\n",
       "      <td>2.205309</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>1.5364</td>\n",
       "      <td>8.4355</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>73.0088</td>\n",
       "      <td>3.4952</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>69.906</td>\n",
       "      <td>2.9159</td>\n",
       "      <td>6.4162</td>\n",
       "      <td>61.722</td>\n",
       "      <td>1.4651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.175800</td>\n",
       "      <td>2.203498</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>1.4436</td>\n",
       "      <td>10.2781</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>72.4409</td>\n",
       "      <td>3.4480</td>\n",
       "      <td>0.1754</td>\n",
       "      <td>63.6742</td>\n",
       "      <td>2.5184</td>\n",
       "      <td>12.4092</td>\n",
       "      <td>59.9845</td>\n",
       "      <td>1.3759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>2.182000</td>\n",
       "      <td>2.203954</td>\n",
       "      <td>0.2021</td>\n",
       "      <td>1.5167</td>\n",
       "      <td>10.0580</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>77.2308</td>\n",
       "      <td>3.112</td>\n",
       "      <td>0.2058</td>\n",
       "      <td>62.7153</td>\n",
       "      <td>2.3752</td>\n",
       "      <td>11.4498</td>\n",
       "      <td>61.0502</td>\n",
       "      <td>1.3613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.181700</td>\n",
       "      <td>2.202254</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>1.2767</td>\n",
       "      <td>9.8561</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>74.8031</td>\n",
       "      <td>3.3011</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>66.4789</td>\n",
       "      <td>2.4758</td>\n",
       "      <td>10.2593</td>\n",
       "      <td>61.8644</td>\n",
       "      <td>1.3563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>2.179200</td>\n",
       "      <td>2.203786</td>\n",
       "      <td>0.2295</td>\n",
       "      <td>1.3735</td>\n",
       "      <td>11.6355</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>75.8112</td>\n",
       "      <td>3.2237</td>\n",
       "      <td>0.4929</td>\n",
       "      <td>63.8671</td>\n",
       "      <td>2.0564</td>\n",
       "      <td>16.6154</td>\n",
       "      <td>59.8395</td>\n",
       "      <td>1.3188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>2.175700</td>\n",
       "      <td>2.200891</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>1.4754</td>\n",
       "      <td>11.5530</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>77.6435</td>\n",
       "      <td>3.1023</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>65.6348</td>\n",
       "      <td>2.0887</td>\n",
       "      <td>16.4683</td>\n",
       "      <td>59.8938</td>\n",
       "      <td>1.3468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>2.178500</td>\n",
       "      <td>2.201375</td>\n",
       "      <td>0.2161</td>\n",
       "      <td>1.3932</td>\n",
       "      <td>10.2695</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>76.1905</td>\n",
       "      <td>3.1933</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>65.8715</td>\n",
       "      <td>2.1651</td>\n",
       "      <td>11.7449</td>\n",
       "      <td>61.901</td>\n",
       "      <td>1.3609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>2.178900</td>\n",
       "      <td>2.199924</td>\n",
       "      <td>0.2357</td>\n",
       "      <td>1.4653</td>\n",
       "      <td>11.4694</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>76.0563</td>\n",
       "      <td>3.2368</td>\n",
       "      <td>0.5375</td>\n",
       "      <td>65.4898</td>\n",
       "      <td>2.1070</td>\n",
       "      <td>16.2495</td>\n",
       "      <td>59.9568</td>\n",
       "      <td>1.3463</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-f26d9573f660>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ce loss with conditioned kelly betting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1714\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m                 \u001b[1;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m         \u001b[1;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2227\u001b[1;33m         return self._getitem(\n\u001b[0m\u001b[0;32m   2228\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2229\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[1;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[0;32m   2210\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2212\u001b[1;33m         formatted_output = format_table(\n\u001b[0m\u001b[0;32m   2213\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2214\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"column\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mRowFormat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mColumnFormat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchFormat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"row\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"column\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mformat_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFormatter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mextract_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPythonArrowExtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseArrowExtractor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unnest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pydict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36m_unnest\u001b[1;34m(py_dict)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_unnest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_dict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[1;34m\"\"\"Return the first element of a batch (dict) as a row (dict)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpy_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# firstrate data no volume\n",
    "\n",
    "# SGCONV! lr of 7e-4, batch size 8 hidden size 320,\n",
    "# fp16, NO dropout, weight decay,\n",
    "# NO diagonal attention allowed, NO rotary embed, norm or residual on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2656' max='4370' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2656/4370 15:22 < 09:55, 2.88 it/s, Epoch 0.61/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>2.281100</td>\n",
       "      <td>2.255800</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>4.1832</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>54.5455</td>\n",
       "      <td>2.2548</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>61.0973</td>\n",
       "      <td>1.6546</td>\n",
       "      <td>0.6911</td>\n",
       "      <td>59.7918</td>\n",
       "      <td>1.2492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>2.228500</td>\n",
       "      <td>2.227618</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>5.2637</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>48.6486</td>\n",
       "      <td>7.1328</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>67.0423</td>\n",
       "      <td>3.2666</td>\n",
       "      <td>1.0913</td>\n",
       "      <td>61.3415</td>\n",
       "      <td>1.5290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>2.213700</td>\n",
       "      <td>2.227064</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.6953</td>\n",
       "      <td>5.1905</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>87.5</td>\n",
       "      <td>17.6254</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>59.0038</td>\n",
       "      <td>3.8734</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>59.8048</td>\n",
       "      <td>1.4125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.200500</td>\n",
       "      <td>2.213450</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.7954</td>\n",
       "      <td>5.9141</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>55.5556</td>\n",
       "      <td>8.9900</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>64.9805</td>\n",
       "      <td>3.8504</td>\n",
       "      <td>0.7709</td>\n",
       "      <td>61.4365</td>\n",
       "      <td>1.5092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.207700</td>\n",
       "      <td>2.213576</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>6.6976</td>\n",
       "      <td>0.0086</td>\n",
       "      <td>68.2927</td>\n",
       "      <td>5.2056</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>71.6792</td>\n",
       "      <td>2.7144</td>\n",
       "      <td>1.3362</td>\n",
       "      <td>61.7714</td>\n",
       "      <td>1.2657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>2.191900</td>\n",
       "      <td>2.212270</td>\n",
       "      <td>0.1331</td>\n",
       "      <td>1.153</td>\n",
       "      <td>8.1508</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>64.8352</td>\n",
       "      <td>5.6052</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>73.3925</td>\n",
       "      <td>2.7101</td>\n",
       "      <td>4.8843</td>\n",
       "      <td>60.3006</td>\n",
       "      <td>1.3283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>2.196700</td>\n",
       "      <td>2.213488</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.8775</td>\n",
       "      <td>7.8242</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>63.3028</td>\n",
       "      <td>5.5263</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>65.6863</td>\n",
       "      <td>3.0546</td>\n",
       "      <td>3.3305</td>\n",
       "      <td>61.7388</td>\n",
       "      <td>1.4423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.190800</td>\n",
       "      <td>2.210958</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>0.7173</td>\n",
       "      <td>8.9136</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>70.</td>\n",
       "      <td>4.1582</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>68.3135</td>\n",
       "      <td>3.2333</td>\n",
       "      <td>5.4321</td>\n",
       "      <td>61.7034</td>\n",
       "      <td>1.3096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>2.190800</td>\n",
       "      <td>2.212844</td>\n",
       "      <td>0.1451</td>\n",
       "      <td>1.2689</td>\n",
       "      <td>7.8147</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>69.4656</td>\n",
       "      <td>4.0779</td>\n",
       "      <td>0.0483</td>\n",
       "      <td>68.4665</td>\n",
       "      <td>3.0381</td>\n",
       "      <td>3.4992</td>\n",
       "      <td>62.6002</td>\n",
       "      <td>1.4875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.193900</td>\n",
       "      <td>2.209403</td>\n",
       "      <td>0.1718</td>\n",
       "      <td>1.0855</td>\n",
       "      <td>9.4908</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>71.6129</td>\n",
       "      <td>3.9016</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>62.5</td>\n",
       "      <td>2.8928</td>\n",
       "      <td>8.3427</td>\n",
       "      <td>60.5674</td>\n",
       "      <td>1.4772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>2.186500</td>\n",
       "      <td>2.209876</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>1.0535</td>\n",
       "      <td>8.7438</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>72.2222</td>\n",
       "      <td>3.772</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>72.8216</td>\n",
       "      <td>2.6357</td>\n",
       "      <td>5.4555</td>\n",
       "      <td>61.9515</td>\n",
       "      <td>1.5074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>2.186800</td>\n",
       "      <td>2.209745</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>1.4195</td>\n",
       "      <td>7.4169</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>71.4286</td>\n",
       "      <td>3.7472</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>75.5102</td>\n",
       "      <td>3.0133</td>\n",
       "      <td>2.6514</td>\n",
       "      <td>63.5441</td>\n",
       "      <td>1.5371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>2.180100</td>\n",
       "      <td>2.207236</td>\n",
       "      <td>0.1607</td>\n",
       "      <td>1.3606</td>\n",
       "      <td>8.4684</td>\n",
       "      <td>0.021</td>\n",
       "      <td>76.1194</td>\n",
       "      <td>3.3078</td>\n",
       "      <td>0.0514</td>\n",
       "      <td>73.0223</td>\n",
       "      <td>3.0283</td>\n",
       "      <td>5.2060</td>\n",
       "      <td>62.3598</td>\n",
       "      <td>1.5058</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-181a4042c763>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ce loss with conditioned kelly betting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1714\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m                 \u001b[1;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m         \u001b[1;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2227\u001b[1;33m         return self._getitem(\n\u001b[0m\u001b[0;32m   2228\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2229\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[1;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[0;32m   2209\u001b[0m         \u001b[0mformat_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mformat_kwargs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mformat_kwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2210\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2211\u001b[1;33m         \u001b[0mpa_subtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2212\u001b[0m         formatted_output = format_table(\n\u001b[0;32m   2213\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mquery_table\u001b[1;34m(table, key, indices)\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;31m# Query the main table\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mindices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 489\u001b[1;33m         \u001b[0mpa_subtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_query_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    490\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_query_table_with_indices_mapping\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36m_query_table\u001b[1;34m(table, key)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \"\"\"\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfast_slice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_rows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\table.py\u001b[0m in \u001b[0;36mfast_slice\u001b[1;34m(self, offset, length)\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[0mbatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moffset\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_offsets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[0mbatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatches\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_offsets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_batches\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_schema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# firstrate data no volume\n",
    "\n",
    "# SGCONV! lr of 3e-4, batch size 8 hidden size 320,\n",
    "# fp16, NO dropout, weight decay,\n",
    "# NO diagonal attention allowed, NO rotary embed, norm or residual on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16104' max='16104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16104/16104 1:17:06, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.235700</td>\n",
       "      <td>2.213605</td>\n",
       "      <td>0.0273</td>\n",
       "      <td>0.4427</td>\n",
       "      <td>5.6110</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.6298</td>\n",
       "      <td>59.2979</td>\n",
       "      <td>0.9995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.197700</td>\n",
       "      <td>2.187213</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>6.9179</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>70.9763</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>3.4410</td>\n",
       "      <td>56.5782</td>\n",
       "      <td>0.8138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.179000</td>\n",
       "      <td>2.198010</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>6.7576</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>56.7261</td>\n",
       "      <td>1.3831</td>\n",
       "      <td>4.4753</td>\n",
       "      <td>48.7210</td>\n",
       "      <td>0.9084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.182600</td>\n",
       "      <td>2.179321</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>0.1389</td>\n",
       "      <td>7.3919</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>70.4403</td>\n",
       "      <td>1.1805</td>\n",
       "      <td>5.8077</td>\n",
       "      <td>51.2879</td>\n",
       "      <td>0.8976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.171500</td>\n",
       "      <td>2.171666</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>6.0869</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1525</td>\n",
       "      <td>72.3565</td>\n",
       "      <td>1.3270</td>\n",
       "      <td>4.1846</td>\n",
       "      <td>55.7574</td>\n",
       "      <td>1.0612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.172400</td>\n",
       "      <td>2.173419</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>6.7863</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>76.1905</td>\n",
       "      <td>1.224</td>\n",
       "      <td>0.8523</td>\n",
       "      <td>73.5711</td>\n",
       "      <td>1.2437</td>\n",
       "      <td>3.2213</td>\n",
       "      <td>56.6015</td>\n",
       "      <td>0.8912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.173700</td>\n",
       "      <td>2.174485</td>\n",
       "      <td>0.0185</td>\n",
       "      <td>0.1341</td>\n",
       "      <td>8.5804</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>73.75</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>1.6078</td>\n",
       "      <td>57.7537</td>\n",
       "      <td>1.1041</td>\n",
       "      <td>7.6930</td>\n",
       "      <td>48.4641</td>\n",
       "      <td>0.9006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.170100</td>\n",
       "      <td>2.171442</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.2501</td>\n",
       "      <td>6.2384</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>60.8696</td>\n",
       "      <td>1.0764</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>69.2404</td>\n",
       "      <td>1.2480</td>\n",
       "      <td>4.219</td>\n",
       "      <td>52.3748</td>\n",
       "      <td>0.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.167700</td>\n",
       "      <td>2.169738</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.2713</td>\n",
       "      <td>6.6446</td>\n",
       "      <td>0.0610</td>\n",
       "      <td>76.7925</td>\n",
       "      <td>1.1126</td>\n",
       "      <td>1.1598</td>\n",
       "      <td>70.7973</td>\n",
       "      <td>1.2067</td>\n",
       "      <td>4.1232</td>\n",
       "      <td>52.3336</td>\n",
       "      <td>0.8524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.164900</td>\n",
       "      <td>2.168763</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.2253</td>\n",
       "      <td>7.3099</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>77.3700</td>\n",
       "      <td>1.1695</td>\n",
       "      <td>1.5978</td>\n",
       "      <td>67.349</td>\n",
       "      <td>1.0937</td>\n",
       "      <td>4.7618</td>\n",
       "      <td>52.0775</td>\n",
       "      <td>0.8502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.169000</td>\n",
       "      <td>2.170804</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.2699</td>\n",
       "      <td>7.2943</td>\n",
       "      <td>0.1336</td>\n",
       "      <td>79.4828</td>\n",
       "      <td>1.2175</td>\n",
       "      <td>1.6943</td>\n",
       "      <td>66.3064</td>\n",
       "      <td>1.1779</td>\n",
       "      <td>5.022</td>\n",
       "      <td>51.1317</td>\n",
       "      <td>0.8154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.161600</td>\n",
       "      <td>2.168510</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>7.2823</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>82.0175</td>\n",
       "      <td>1.7171</td>\n",
       "      <td>2.1507</td>\n",
       "      <td>58.8862</td>\n",
       "      <td>0.9594</td>\n",
       "      <td>5.1444</td>\n",
       "      <td>50.4388</td>\n",
       "      <td>0.8809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.159000</td>\n",
       "      <td>2.166526</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.2402</td>\n",
       "      <td>7.1990</td>\n",
       "      <td>0.1129</td>\n",
       "      <td>71.6327</td>\n",
       "      <td>1.3455</td>\n",
       "      <td>1.9455</td>\n",
       "      <td>59.8177</td>\n",
       "      <td>1.0039</td>\n",
       "      <td>5.1076</td>\n",
       "      <td>51.0237</td>\n",
       "      <td>0.8751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.159000</td>\n",
       "      <td>2.167321</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.2067</td>\n",
       "      <td>7.1393</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>75.0714</td>\n",
       "      <td>1.3430</td>\n",
       "      <td>1.8288</td>\n",
       "      <td>59.7607</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>5.0289</td>\n",
       "      <td>50.8279</td>\n",
       "      <td>0.8594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.160500</td>\n",
       "      <td>2.166773</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.2302</td>\n",
       "      <td>7.1544</td>\n",
       "      <td>0.1157</td>\n",
       "      <td>75.4229</td>\n",
       "      <td>1.3046</td>\n",
       "      <td>2.0722</td>\n",
       "      <td>57.4557</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>4.9793</td>\n",
       "      <td>50.3539</td>\n",
       "      <td>0.8746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.156800</td>\n",
       "      <td>2.166997</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>7.1672</td>\n",
       "      <td>0.1148</td>\n",
       "      <td>75.326</td>\n",
       "      <td>1.3316</td>\n",
       "      <td>2.0589</td>\n",
       "      <td>58.077</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>5.0138</td>\n",
       "      <td>50.4387</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16104, training_loss=2.173753637966681, metrics={'train_runtime': 4629.2715, 'train_samples_per_second': 6.957, 'train_steps_per_second': 3.479, 'total_flos': 0.0, 'train_loss': 2.173753637966681, 'epoch': 1.0})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OANDA finnhub, only from 2009 and only top 10 majors, no volume (to be similar to firstrate) only close and close diff\n",
    "\n",
    "# sru lr of 1e-4, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, NO rotary embed on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6972' max='17479' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6972/17479 33:21 < 50:17, 3.48 it/s, Epoch 0.40/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.261700</td>\n",
       "      <td>2.297693</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>9.8641</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3519</td>\n",
       "      <td>61.363</td>\n",
       "      <td>1.4808</td>\n",
       "      <td>10.5224</td>\n",
       "      <td>53.3048</td>\n",
       "      <td>0.9895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.218700</td>\n",
       "      <td>2.223172</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>6.9033</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>59.375</td>\n",
       "      <td>3.9073</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>82.2695</td>\n",
       "      <td>2.4466</td>\n",
       "      <td>1.7448</td>\n",
       "      <td>59.3677</td>\n",
       "      <td>1.3346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.205600</td>\n",
       "      <td>2.207914</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>1.0999</td>\n",
       "      <td>7.8623</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>83.5938</td>\n",
       "      <td>3.111</td>\n",
       "      <td>0.1084</td>\n",
       "      <td>78.9423</td>\n",
       "      <td>2.3539</td>\n",
       "      <td>3.9947</td>\n",
       "      <td>59.2989</td>\n",
       "      <td>1.1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.199300</td>\n",
       "      <td>2.199579</td>\n",
       "      <td>0.1239</td>\n",
       "      <td>1.1717</td>\n",
       "      <td>7.5447</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>77.4566</td>\n",
       "      <td>2.8855</td>\n",
       "      <td>0.119</td>\n",
       "      <td>77.213</td>\n",
       "      <td>2.4334</td>\n",
       "      <td>3.8439</td>\n",
       "      <td>59.5497</td>\n",
       "      <td>1.3626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.191100</td>\n",
       "      <td>2.202494</td>\n",
       "      <td>0.1427</td>\n",
       "      <td>1.3551</td>\n",
       "      <td>8.212</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>86.4542</td>\n",
       "      <td>3.7456</td>\n",
       "      <td>0.4742</td>\n",
       "      <td>70.0967</td>\n",
       "      <td>2.0056</td>\n",
       "      <td>6.5016</td>\n",
       "      <td>59.1824</td>\n",
       "      <td>1.2743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.191600</td>\n",
       "      <td>2.198232</td>\n",
       "      <td>0.1611</td>\n",
       "      <td>1.0243</td>\n",
       "      <td>8.8200</td>\n",
       "      <td>0.041</td>\n",
       "      <td>88.2952</td>\n",
       "      <td>3.3829</td>\n",
       "      <td>0.3074</td>\n",
       "      <td>71.8792</td>\n",
       "      <td>2.4424</td>\n",
       "      <td>6.4019</td>\n",
       "      <td>60.5372</td>\n",
       "      <td>1.3091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37' max='37' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37/37 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-cd7a14091f72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ce loss with conditioned kelly betting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1800\u001b[0m                     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_grad_scaling\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1801\u001b[0m                         \u001b[0mscale_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1802\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1803\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m                         \u001b[0mscale_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stage\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\optimization.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    360\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m                 \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eps\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m                 \u001b[0mstep_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"lr\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# firstrate data with only close diff and day close features\n",
    "\n",
    "# sru lr of 1e-4, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, NO rotary embed on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='16104' max='16104' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [16104/16104 1:18:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.229700</td>\n",
       "      <td>2.207908</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.2045</td>\n",
       "      <td>5.2825</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>61.0977</td>\n",
       "      <td>1.0193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.190400</td>\n",
       "      <td>2.181227</td>\n",
       "      <td>0.0115</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>6.9469</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1112</td>\n",
       "      <td>77.1222</td>\n",
       "      <td>1.272</td>\n",
       "      <td>3.2335</td>\n",
       "      <td>53.6738</td>\n",
       "      <td>0.8655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.173200</td>\n",
       "      <td>2.186217</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>6.4122</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>74.0340</td>\n",
       "      <td>1.945</td>\n",
       "      <td>4.4211</td>\n",
       "      <td>50.465</td>\n",
       "      <td>0.9230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.177600</td>\n",
       "      <td>2.177140</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>7.4010</td>\n",
       "      <td>0.003</td>\n",
       "      <td>76.9231</td>\n",
       "      <td>2.5196</td>\n",
       "      <td>0.4561</td>\n",
       "      <td>74.1667</td>\n",
       "      <td>1.2518</td>\n",
       "      <td>5.4119</td>\n",
       "      <td>50.3586</td>\n",
       "      <td>0.9248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.167500</td>\n",
       "      <td>2.171044</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.2229</td>\n",
       "      <td>6.1450</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.4017</td>\n",
       "      <td>77.867</td>\n",
       "      <td>1.6598</td>\n",
       "      <td>3.6548</td>\n",
       "      <td>54.7471</td>\n",
       "      <td>0.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.167700</td>\n",
       "      <td>2.174675</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.152</td>\n",
       "      <td>6.2926</td>\n",
       "      <td>0.0130</td>\n",
       "      <td>84.0708</td>\n",
       "      <td>3.2329</td>\n",
       "      <td>0.7326</td>\n",
       "      <td>73.086</td>\n",
       "      <td>1.3347</td>\n",
       "      <td>2.8549</td>\n",
       "      <td>58.6567</td>\n",
       "      <td>0.8198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.168600</td>\n",
       "      <td>2.176449</td>\n",
       "      <td>0.0178</td>\n",
       "      <td>0.1357</td>\n",
       "      <td>8.1767</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>84.6995</td>\n",
       "      <td>1.3442</td>\n",
       "      <td>1.5839</td>\n",
       "      <td>54.9916</td>\n",
       "      <td>1.041</td>\n",
       "      <td>6.9005</td>\n",
       "      <td>48.2977</td>\n",
       "      <td>0.9153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.165200</td>\n",
       "      <td>2.172665</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.2702</td>\n",
       "      <td>6.0165</td>\n",
       "      <td>0.0290</td>\n",
       "      <td>81.7460</td>\n",
       "      <td>1.9660</td>\n",
       "      <td>0.9085</td>\n",
       "      <td>71.6821</td>\n",
       "      <td>1.2348</td>\n",
       "      <td>3.5629</td>\n",
       "      <td>53.5896</td>\n",
       "      <td>0.8735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.162400</td>\n",
       "      <td>2.167740</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.2925</td>\n",
       "      <td>6.2208</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>75.3681</td>\n",
       "      <td>1.4401</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>70.9589</td>\n",
       "      <td>1.1925</td>\n",
       "      <td>3.3681</td>\n",
       "      <td>55.4537</td>\n",
       "      <td>0.8603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.158900</td>\n",
       "      <td>2.168921</td>\n",
       "      <td>0.0261</td>\n",
       "      <td>0.266</td>\n",
       "      <td>6.956</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>73.7944</td>\n",
       "      <td>1.701</td>\n",
       "      <td>1.2677</td>\n",
       "      <td>69.6221</td>\n",
       "      <td>1.0854</td>\n",
       "      <td>3.9636</td>\n",
       "      <td>54.8857</td>\n",
       "      <td>0.8024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.162800</td>\n",
       "      <td>2.169165</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.3445</td>\n",
       "      <td>6.7733</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>79.5334</td>\n",
       "      <td>1.9290</td>\n",
       "      <td>1.3175</td>\n",
       "      <td>65.0699</td>\n",
       "      <td>1.1935</td>\n",
       "      <td>4.6271</td>\n",
       "      <td>50.9831</td>\n",
       "      <td>0.8349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.154400</td>\n",
       "      <td>2.168996</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>7.2779</td>\n",
       "      <td>0.1620</td>\n",
       "      <td>71.5707</td>\n",
       "      <td>1.6848</td>\n",
       "      <td>2.2998</td>\n",
       "      <td>52.2434</td>\n",
       "      <td>0.8356</td>\n",
       "      <td>4.4959</td>\n",
       "      <td>52.1965</td>\n",
       "      <td>0.8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.152800</td>\n",
       "      <td>2.166647</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.2943</td>\n",
       "      <td>6.6591</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>69.1368</td>\n",
       "      <td>1.5534</td>\n",
       "      <td>1.726</td>\n",
       "      <td>60.0320</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>4.6718</td>\n",
       "      <td>51.7946</td>\n",
       "      <td>0.8766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.150600</td>\n",
       "      <td>2.168200</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.2841</td>\n",
       "      <td>6.7766</td>\n",
       "      <td>0.1841</td>\n",
       "      <td>75.8599</td>\n",
       "      <td>1.583</td>\n",
       "      <td>1.565</td>\n",
       "      <td>60.3356</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>4.3648</td>\n",
       "      <td>52.9868</td>\n",
       "      <td>0.8643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.153600</td>\n",
       "      <td>2.167240</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.3071</td>\n",
       "      <td>6.7236</td>\n",
       "      <td>0.1582</td>\n",
       "      <td>76.0553</td>\n",
       "      <td>1.6514</td>\n",
       "      <td>1.6619</td>\n",
       "      <td>58.9633</td>\n",
       "      <td>0.8674</td>\n",
       "      <td>4.4959</td>\n",
       "      <td>51.9685</td>\n",
       "      <td>0.8892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.149400</td>\n",
       "      <td>2.167608</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.3072</td>\n",
       "      <td>6.8177</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>76.0454</td>\n",
       "      <td>1.6441</td>\n",
       "      <td>1.7313</td>\n",
       "      <td>58.6709</td>\n",
       "      <td>0.8665</td>\n",
       "      <td>4.5505</td>\n",
       "      <td>52.1929</td>\n",
       "      <td>0.8918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=16104, training_loss=2.1677288040259675, metrics={'train_runtime': 4696.5168, 'train_samples_per_second': 6.858, 'train_steps_per_second': 3.429, 'total_flos': 0.0, 'train_loss': 2.1677288040259675, 'epoch': 1.0})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OANDA finnhub, only from 2009 and only top 10 majors, no volume (to be similar to firstrate)\n",
    "\n",
    "# sru lr of 1e-4, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, NO rotary embed on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10723' max='17479' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10723/17479 52:32 < 33:06, 3.40 it/s, Epoch 0.61/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.242100</td>\n",
       "      <td>2.252204</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.5631</td>\n",
       "      <td>9.9642</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>78.9474</td>\n",
       "      <td>2.7878</td>\n",
       "      <td>0.1764</td>\n",
       "      <td>68.2624</td>\n",
       "      <td>1.4332</td>\n",
       "      <td>9.7356</td>\n",
       "      <td>57.9235</td>\n",
       "      <td>1.0714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.199400</td>\n",
       "      <td>2.206672</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>8.7523</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>81.8182</td>\n",
       "      <td>3.1578</td>\n",
       "      <td>0.2931</td>\n",
       "      <td>75.2757</td>\n",
       "      <td>2.0415</td>\n",
       "      <td>6.9344</td>\n",
       "      <td>60.7407</td>\n",
       "      <td>1.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.186700</td>\n",
       "      <td>2.196291</td>\n",
       "      <td>0.19</td>\n",
       "      <td>2.2239</td>\n",
       "      <td>9.7341</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>88.8186</td>\n",
       "      <td>2.9741</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>72.2314</td>\n",
       "      <td>1.8674</td>\n",
       "      <td>10.3468</td>\n",
       "      <td>60.9342</td>\n",
       "      <td>1.3822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.172000</td>\n",
       "      <td>2.179211</td>\n",
       "      <td>0.2566</td>\n",
       "      <td>1.8965</td>\n",
       "      <td>9.9227</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>88.5442</td>\n",
       "      <td>3.4792</td>\n",
       "      <td>1.2516</td>\n",
       "      <td>63.0926</td>\n",
       "      <td>1.7876</td>\n",
       "      <td>10.4753</td>\n",
       "      <td>61.6084</td>\n",
       "      <td>1.6210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.164200</td>\n",
       "      <td>2.177389</td>\n",
       "      <td>0.4089</td>\n",
       "      <td>1.6968</td>\n",
       "      <td>12.2209</td>\n",
       "      <td>0.1177</td>\n",
       "      <td>60.8503</td>\n",
       "      <td>2.9828</td>\n",
       "      <td>2.6091</td>\n",
       "      <td>63.7639</td>\n",
       "      <td>1.8566</td>\n",
       "      <td>14.9421</td>\n",
       "      <td>63.7609</td>\n",
       "      <td>1.721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.161100</td>\n",
       "      <td>2.166125</td>\n",
       "      <td>0.5752</td>\n",
       "      <td>1.3475</td>\n",
       "      <td>16.8428</td>\n",
       "      <td>0.6188</td>\n",
       "      <td>22.3083</td>\n",
       "      <td>3.1728</td>\n",
       "      <td>5.7853</td>\n",
       "      <td>65.6724</td>\n",
       "      <td>2.1605</td>\n",
       "      <td>26.8259</td>\n",
       "      <td>61.3128</td>\n",
       "      <td>1.4556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.158300</td>\n",
       "      <td>2.166374</td>\n",
       "      <td>0.7017</td>\n",
       "      <td>1.6031</td>\n",
       "      <td>18.3057</td>\n",
       "      <td>1.0571</td>\n",
       "      <td>26.8002</td>\n",
       "      <td>2.5323</td>\n",
       "      <td>8.0023</td>\n",
       "      <td>71.0613</td>\n",
       "      <td>1.9128</td>\n",
       "      <td>27.5049</td>\n",
       "      <td>61.6522</td>\n",
       "      <td>1.4564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.148200</td>\n",
       "      <td>2.156734</td>\n",
       "      <td>0.7360</td>\n",
       "      <td>1.6552</td>\n",
       "      <td>17.3859</td>\n",
       "      <td>1.2082</td>\n",
       "      <td>18.9178</td>\n",
       "      <td>3.9519</td>\n",
       "      <td>7.6688</td>\n",
       "      <td>71.2837</td>\n",
       "      <td>2.1712</td>\n",
       "      <td>23.6598</td>\n",
       "      <td>63.727</td>\n",
       "      <td>1.5695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.147600</td>\n",
       "      <td>2.153547</td>\n",
       "      <td>0.7901</td>\n",
       "      <td>1.5418</td>\n",
       "      <td>19.6792</td>\n",
       "      <td>1.2776</td>\n",
       "      <td>20.191</td>\n",
       "      <td>3.4026</td>\n",
       "      <td>10.2425</td>\n",
       "      <td>71.2267</td>\n",
       "      <td>2.3701</td>\n",
       "      <td>27.844</td>\n",
       "      <td>61.1343</td>\n",
       "      <td>1.4351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.142700</td>\n",
       "      <td>2.148682</td>\n",
       "      <td>1.0392</td>\n",
       "      <td>1.6243</td>\n",
       "      <td>25.1267</td>\n",
       "      <td>2.2339</td>\n",
       "      <td>53.1600</td>\n",
       "      <td>2.6964</td>\n",
       "      <td>19.3049</td>\n",
       "      <td>66.913</td>\n",
       "      <td>1.9480</td>\n",
       "      <td>30.3248</td>\n",
       "      <td>58.0507</td>\n",
       "      <td>1.2837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-81860e47f52d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ce loss with conditioned kelly betting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# firstrate data, no volume\n",
    "\n",
    "# sru lr of 1e-4, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, NO rotary embed on conv embed, kernel size of 5\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29124' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29124/43942 2:24:03 < 1:13:17, 3.37 it/s, Epoch 0.66/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.248300</td>\n",
       "      <td>2.194513</td>\n",
       "      <td>-0.0166</td>\n",
       "      <td>-0.0983</td>\n",
       "      <td>7.3370</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.1883</td>\n",
       "      <td>48.4162</td>\n",
       "      <td>0.7838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.203900</td>\n",
       "      <td>2.200736</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>8.4379</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.6036</td>\n",
       "      <td>65.3814</td>\n",
       "      <td>1.1249</td>\n",
       "      <td>6.7058</td>\n",
       "      <td>54.2433</td>\n",
       "      <td>0.8839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.198300</td>\n",
       "      <td>2.187346</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>7.676</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2664</td>\n",
       "      <td>51.7569</td>\n",
       "      <td>1.6309</td>\n",
       "      <td>5.1169</td>\n",
       "      <td>48.7071</td>\n",
       "      <td>0.9342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.187600</td>\n",
       "      <td>2.194386</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.2721</td>\n",
       "      <td>7.0423</td>\n",
       "      <td>0.0022</td>\n",
       "      <td>70.5882</td>\n",
       "      <td>1.6644</td>\n",
       "      <td>0.7421</td>\n",
       "      <td>65.7065</td>\n",
       "      <td>1.0201</td>\n",
       "      <td>4.5894</td>\n",
       "      <td>54.1177</td>\n",
       "      <td>1.0439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.191500</td>\n",
       "      <td>2.175651</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>6.6826</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>80.4688</td>\n",
       "      <td>1.7080</td>\n",
       "      <td>1.4633</td>\n",
       "      <td>64.2635</td>\n",
       "      <td>1.1497</td>\n",
       "      <td>4.6578</td>\n",
       "      <td>53.1842</td>\n",
       "      <td>0.9963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.177200</td>\n",
       "      <td>2.184132</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.077</td>\n",
       "      <td>8.1531</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>52.8512</td>\n",
       "      <td>1.0879</td>\n",
       "      <td>1.9069</td>\n",
       "      <td>60.9685</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>6.9584</td>\n",
       "      <td>49.062</td>\n",
       "      <td>0.8147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.184400</td>\n",
       "      <td>2.175615</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.046</td>\n",
       "      <td>8.2817</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>50.4640</td>\n",
       "      <td>1.0796</td>\n",
       "      <td>1.3659</td>\n",
       "      <td>56.2789</td>\n",
       "      <td>0.8789</td>\n",
       "      <td>4.4659</td>\n",
       "      <td>50.8129</td>\n",
       "      <td>0.8461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.182200</td>\n",
       "      <td>2.181967</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>10.7293</td>\n",
       "      <td>0.9593</td>\n",
       "      <td>56.5796</td>\n",
       "      <td>1.4609</td>\n",
       "      <td>4.3625</td>\n",
       "      <td>49.6984</td>\n",
       "      <td>0.9720</td>\n",
       "      <td>7.234</td>\n",
       "      <td>49.0636</td>\n",
       "      <td>0.9220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.178600</td>\n",
       "      <td>2.175615</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.1872</td>\n",
       "      <td>7.0264</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>74.1899</td>\n",
       "      <td>1.5848</td>\n",
       "      <td>2.4166</td>\n",
       "      <td>61.6802</td>\n",
       "      <td>1.1207</td>\n",
       "      <td>4.5187</td>\n",
       "      <td>49.1000</td>\n",
       "      <td>0.8562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.177500</td>\n",
       "      <td>2.177185</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.2543</td>\n",
       "      <td>7.9500</td>\n",
       "      <td>0.1596</td>\n",
       "      <td>66.878</td>\n",
       "      <td>1.3406</td>\n",
       "      <td>2.0201</td>\n",
       "      <td>63.2248</td>\n",
       "      <td>1.1015</td>\n",
       "      <td>5.0959</td>\n",
       "      <td>51.1071</td>\n",
       "      <td>0.8767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.171700</td>\n",
       "      <td>2.165913</td>\n",
       "      <td>0.0362</td>\n",
       "      <td>0.27</td>\n",
       "      <td>8.5149</td>\n",
       "      <td>0.2348</td>\n",
       "      <td>63.7931</td>\n",
       "      <td>1.2211</td>\n",
       "      <td>2.6366</td>\n",
       "      <td>56.2128</td>\n",
       "      <td>1.0268</td>\n",
       "      <td>5.286</td>\n",
       "      <td>50.5372</td>\n",
       "      <td>0.8078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.175100</td>\n",
       "      <td>2.169939</td>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.1954</td>\n",
       "      <td>7.8406</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>77.4332</td>\n",
       "      <td>1.4534</td>\n",
       "      <td>1.4674</td>\n",
       "      <td>56.09</td>\n",
       "      <td>1.0096</td>\n",
       "      <td>5.2389</td>\n",
       "      <td>54.171</td>\n",
       "      <td>0.9233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.168900</td>\n",
       "      <td>2.165720</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.2690</td>\n",
       "      <td>7.2175</td>\n",
       "      <td>0.3153</td>\n",
       "      <td>68.2310</td>\n",
       "      <td>1.2462</td>\n",
       "      <td>2.3296</td>\n",
       "      <td>55.8614</td>\n",
       "      <td>1.0017</td>\n",
       "      <td>4.33</td>\n",
       "      <td>49.3442</td>\n",
       "      <td>0.8528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.170700</td>\n",
       "      <td>2.177166</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.2564</td>\n",
       "      <td>8.4287</td>\n",
       "      <td>0.5783</td>\n",
       "      <td>59.4926</td>\n",
       "      <td>1.1057</td>\n",
       "      <td>2.859</td>\n",
       "      <td>60.623</td>\n",
       "      <td>0.9501</td>\n",
       "      <td>4.5474</td>\n",
       "      <td>53.1516</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.170800</td>\n",
       "      <td>2.171136</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1481</td>\n",
       "      <td>8.8538</td>\n",
       "      <td>0.4685</td>\n",
       "      <td>39.9028</td>\n",
       "      <td>1.4229</td>\n",
       "      <td>3.0239</td>\n",
       "      <td>54.2249</td>\n",
       "      <td>1.0529</td>\n",
       "      <td>5.4178</td>\n",
       "      <td>49.8167</td>\n",
       "      <td>0.8507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.171400</td>\n",
       "      <td>2.167282</td>\n",
       "      <td>0.0393</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>7.3541</td>\n",
       "      <td>0.7056</td>\n",
       "      <td>58.8383</td>\n",
       "      <td>1.0277</td>\n",
       "      <td>2.9288</td>\n",
       "      <td>59.1863</td>\n",
       "      <td>1.1016</td>\n",
       "      <td>3.6701</td>\n",
       "      <td>49.066</td>\n",
       "      <td>0.8462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.166500</td>\n",
       "      <td>2.170048</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.3342</td>\n",
       "      <td>9.1154</td>\n",
       "      <td>1.0471</td>\n",
       "      <td>58.7702</td>\n",
       "      <td>1.1346</td>\n",
       "      <td>3.2056</td>\n",
       "      <td>57.7973</td>\n",
       "      <td>0.9869</td>\n",
       "      <td>4.4514</td>\n",
       "      <td>49.5354</td>\n",
       "      <td>0.8252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.169300</td>\n",
       "      <td>2.169171</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.1722</td>\n",
       "      <td>8.0690</td>\n",
       "      <td>0.4003</td>\n",
       "      <td>59.0205</td>\n",
       "      <td>1.0531</td>\n",
       "      <td>2.233</td>\n",
       "      <td>61.5419</td>\n",
       "      <td>1.0329</td>\n",
       "      <td>4.5417</td>\n",
       "      <td>50.94</td>\n",
       "      <td>0.8752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.168700</td>\n",
       "      <td>2.164824</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.2481</td>\n",
       "      <td>7.947</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>59.6588</td>\n",
       "      <td>1.4595</td>\n",
       "      <td>2.8589</td>\n",
       "      <td>58.0638</td>\n",
       "      <td>1.0907</td>\n",
       "      <td>5.41</td>\n",
       "      <td>52.1242</td>\n",
       "      <td>0.9020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.162500</td>\n",
       "      <td>2.165025</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.3208</td>\n",
       "      <td>7.3924</td>\n",
       "      <td>0.3090</td>\n",
       "      <td>57.7159</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>1.9628</td>\n",
       "      <td>55.2426</td>\n",
       "      <td>1.1625</td>\n",
       "      <td>3.8452</td>\n",
       "      <td>55.64</td>\n",
       "      <td>0.9434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.169100</td>\n",
       "      <td>2.170976</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.3855</td>\n",
       "      <td>8.8882</td>\n",
       "      <td>1.0604</td>\n",
       "      <td>43.7433</td>\n",
       "      <td>1.3041</td>\n",
       "      <td>3.5299</td>\n",
       "      <td>53.4652</td>\n",
       "      <td>0.9344</td>\n",
       "      <td>4.6163</td>\n",
       "      <td>53.0538</td>\n",
       "      <td>0.9397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>2.164100</td>\n",
       "      <td>2.162541</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>0.2890</td>\n",
       "      <td>9.2383</td>\n",
       "      <td>0.4878</td>\n",
       "      <td>58.9730</td>\n",
       "      <td>1.1112</td>\n",
       "      <td>3.1046</td>\n",
       "      <td>60.9803</td>\n",
       "      <td>1.0049</td>\n",
       "      <td>4.1016</td>\n",
       "      <td>51.8627</td>\n",
       "      <td>0.9107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>2.165300</td>\n",
       "      <td>2.164835</td>\n",
       "      <td>0.0538</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>8.1452</td>\n",
       "      <td>0.5857</td>\n",
       "      <td>58.3801</td>\n",
       "      <td>1.1865</td>\n",
       "      <td>3.1777</td>\n",
       "      <td>57.997</td>\n",
       "      <td>1.0219</td>\n",
       "      <td>4.0605</td>\n",
       "      <td>49.7991</td>\n",
       "      <td>0.8391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>2.163100</td>\n",
       "      <td>2.161448</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.3432</td>\n",
       "      <td>7.4431</td>\n",
       "      <td>0.6272</td>\n",
       "      <td>52.5615</td>\n",
       "      <td>1.0865</td>\n",
       "      <td>2.8963</td>\n",
       "      <td>57.0599</td>\n",
       "      <td>1.1847</td>\n",
       "      <td>3.3335</td>\n",
       "      <td>52.3963</td>\n",
       "      <td>0.8298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>2.160200</td>\n",
       "      <td>2.166016</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.3763</td>\n",
       "      <td>7.6154</td>\n",
       "      <td>1.2048</td>\n",
       "      <td>47.2651</td>\n",
       "      <td>1.2891</td>\n",
       "      <td>3.5008</td>\n",
       "      <td>56.1967</td>\n",
       "      <td>0.9896</td>\n",
       "      <td>3.1808</td>\n",
       "      <td>50.6005</td>\n",
       "      <td>0.8109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>2.163400</td>\n",
       "      <td>2.166307</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.3330</td>\n",
       "      <td>7.7612</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>51.9155</td>\n",
       "      <td>1.0568</td>\n",
       "      <td>3.2659</td>\n",
       "      <td>57.082</td>\n",
       "      <td>1.0705</td>\n",
       "      <td>3.6825</td>\n",
       "      <td>49.9828</td>\n",
       "      <td>0.8574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>2.155500</td>\n",
       "      <td>2.167125</td>\n",
       "      <td>0.0581</td>\n",
       "      <td>0.4907</td>\n",
       "      <td>8.5096</td>\n",
       "      <td>1.3687</td>\n",
       "      <td>53.9002</td>\n",
       "      <td>1.2486</td>\n",
       "      <td>3.4291</td>\n",
       "      <td>57.6488</td>\n",
       "      <td>1.0304</td>\n",
       "      <td>3.6269</td>\n",
       "      <td>49.7192</td>\n",
       "      <td>0.8349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>2.155700</td>\n",
       "      <td>2.165004</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.4210</td>\n",
       "      <td>8.0326</td>\n",
       "      <td>1.1468</td>\n",
       "      <td>52.1288</td>\n",
       "      <td>1.1257</td>\n",
       "      <td>3.4276</td>\n",
       "      <td>57.0063</td>\n",
       "      <td>1.0546</td>\n",
       "      <td>3.3885</td>\n",
       "      <td>49.7051</td>\n",
       "      <td>0.8503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>2.163600</td>\n",
       "      <td>2.162527</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>0.4114</td>\n",
       "      <td>7.6774</td>\n",
       "      <td>0.9988</td>\n",
       "      <td>54.6226</td>\n",
       "      <td>1.1146</td>\n",
       "      <td>3.2235</td>\n",
       "      <td>57.3301</td>\n",
       "      <td>1.0233</td>\n",
       "      <td>3.4978</td>\n",
       "      <td>49.1827</td>\n",
       "      <td>0.8586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-143bc33375a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ce loss with conditioned kelly betting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 1e-4, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30330' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30330/43942 2:33:21 < 1:08:50, 3.30 it/s, Epoch 0.69/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.007300</td>\n",
       "      <td>1.962605</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>-0.088</td>\n",
       "      <td>7.3127</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>85.7143</td>\n",
       "      <td>1.6529</td>\n",
       "      <td>2.9835</td>\n",
       "      <td>52.1623</td>\n",
       "      <td>0.8554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.969100</td>\n",
       "      <td>1.968284</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>9.6481</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.3183</td>\n",
       "      <td>61.4086</td>\n",
       "      <td>1.0233</td>\n",
       "      <td>8.9929</td>\n",
       "      <td>51.5177</td>\n",
       "      <td>0.8695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.964100</td>\n",
       "      <td>1.956301</td>\n",
       "      <td>0.0096</td>\n",
       "      <td>0.0961</td>\n",
       "      <td>8.3087</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3747</td>\n",
       "      <td>53.5787</td>\n",
       "      <td>1.4254</td>\n",
       "      <td>6.5265</td>\n",
       "      <td>48.4514</td>\n",
       "      <td>0.9287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.955100</td>\n",
       "      <td>1.960319</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.265</td>\n",
       "      <td>8.3036</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>88.4615</td>\n",
       "      <td>2.5445</td>\n",
       "      <td>1.1855</td>\n",
       "      <td>65.9838</td>\n",
       "      <td>1.1186</td>\n",
       "      <td>5.7377</td>\n",
       "      <td>50.0882</td>\n",
       "      <td>0.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.959200</td>\n",
       "      <td>1.945983</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.2153</td>\n",
       "      <td>7.1422</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>73.6842</td>\n",
       "      <td>2.0155</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>66.2383</td>\n",
       "      <td>1.2214</td>\n",
       "      <td>5.422</td>\n",
       "      <td>52.277</td>\n",
       "      <td>0.9428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.946500</td>\n",
       "      <td>1.951810</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0942</td>\n",
       "      <td>9.5063</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>68.3157</td>\n",
       "      <td>1.1704</td>\n",
       "      <td>2.5426</td>\n",
       "      <td>59.1712</td>\n",
       "      <td>0.9256</td>\n",
       "      <td>8.1957</td>\n",
       "      <td>47.7451</td>\n",
       "      <td>0.8148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.952600</td>\n",
       "      <td>1.944788</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.1290</td>\n",
       "      <td>9.0866</td>\n",
       "      <td>0.2053</td>\n",
       "      <td>67.8373</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>1.9090</td>\n",
       "      <td>59.1638</td>\n",
       "      <td>1.0077</td>\n",
       "      <td>6.25</td>\n",
       "      <td>49.9109</td>\n",
       "      <td>0.9057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>1.950500</td>\n",
       "      <td>1.947618</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.2378</td>\n",
       "      <td>10.9292</td>\n",
       "      <td>0.9543</td>\n",
       "      <td>52.5186</td>\n",
       "      <td>1.5748</td>\n",
       "      <td>4.4863</td>\n",
       "      <td>45.3492</td>\n",
       "      <td>1.0143</td>\n",
       "      <td>6.4668</td>\n",
       "      <td>51.1971</td>\n",
       "      <td>0.9656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>1.948100</td>\n",
       "      <td>1.947254</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.2265</td>\n",
       "      <td>7.8691</td>\n",
       "      <td>0.1924</td>\n",
       "      <td>70.4799</td>\n",
       "      <td>1.2856</td>\n",
       "      <td>2.5664</td>\n",
       "      <td>60.5747</td>\n",
       "      <td>1.0644</td>\n",
       "      <td>5.2164</td>\n",
       "      <td>48.8203</td>\n",
       "      <td>0.8906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>1.946900</td>\n",
       "      <td>1.947026</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.2272</td>\n",
       "      <td>8.1077</td>\n",
       "      <td>0.1074</td>\n",
       "      <td>52.5324</td>\n",
       "      <td>1.1095</td>\n",
       "      <td>1.8450</td>\n",
       "      <td>63.3278</td>\n",
       "      <td>1.0780</td>\n",
       "      <td>5.3296</td>\n",
       "      <td>52.3686</td>\n",
       "      <td>0.8661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>1.941800</td>\n",
       "      <td>1.937511</td>\n",
       "      <td>0.0401</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>9.2136</td>\n",
       "      <td>0.3676</td>\n",
       "      <td>58.4652</td>\n",
       "      <td>1.2727</td>\n",
       "      <td>3.2961</td>\n",
       "      <td>57.6829</td>\n",
       "      <td>0.9692</td>\n",
       "      <td>6.0915</td>\n",
       "      <td>49.4238</td>\n",
       "      <td>0.8267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>1.945000</td>\n",
       "      <td>1.940203</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>0.1985</td>\n",
       "      <td>7.2383</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>69.5533</td>\n",
       "      <td>1.2394</td>\n",
       "      <td>1.6417</td>\n",
       "      <td>59.1879</td>\n",
       "      <td>1.0077</td>\n",
       "      <td>3.7816</td>\n",
       "      <td>52.9335</td>\n",
       "      <td>0.8182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>1.938800</td>\n",
       "      <td>1.938030</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.2095</td>\n",
       "      <td>7.7729</td>\n",
       "      <td>0.3548</td>\n",
       "      <td>58.1105</td>\n",
       "      <td>1.122</td>\n",
       "      <td>2.6100</td>\n",
       "      <td>56.8576</td>\n",
       "      <td>1.1588</td>\n",
       "      <td>4.3634</td>\n",
       "      <td>49.8217</td>\n",
       "      <td>0.8223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>1.940600</td>\n",
       "      <td>1.946373</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.2791</td>\n",
       "      <td>9.3995</td>\n",
       "      <td>1.006</td>\n",
       "      <td>63.3346</td>\n",
       "      <td>1.1090</td>\n",
       "      <td>3.0277</td>\n",
       "      <td>59.9181</td>\n",
       "      <td>1.0354</td>\n",
       "      <td>5.0729</td>\n",
       "      <td>51.4213</td>\n",
       "      <td>0.8678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>1.941100</td>\n",
       "      <td>1.942560</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>9.5705</td>\n",
       "      <td>0.3877</td>\n",
       "      <td>53.3116</td>\n",
       "      <td>1.1895</td>\n",
       "      <td>3.4782</td>\n",
       "      <td>51.0638</td>\n",
       "      <td>0.7366</td>\n",
       "      <td>6.7773</td>\n",
       "      <td>48.3753</td>\n",
       "      <td>0.7767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>1.941500</td>\n",
       "      <td>1.938383</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>7.6085</td>\n",
       "      <td>0.7132</td>\n",
       "      <td>55.9950</td>\n",
       "      <td>1.001</td>\n",
       "      <td>2.849</td>\n",
       "      <td>57.1593</td>\n",
       "      <td>1.055</td>\n",
       "      <td>3.6348</td>\n",
       "      <td>51.0701</td>\n",
       "      <td>0.8642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>1.937200</td>\n",
       "      <td>1.940546</td>\n",
       "      <td>0.0564</td>\n",
       "      <td>0.3982</td>\n",
       "      <td>9.7525</td>\n",
       "      <td>0.9629</td>\n",
       "      <td>59.0384</td>\n",
       "      <td>1.0736</td>\n",
       "      <td>3.4372</td>\n",
       "      <td>57.9951</td>\n",
       "      <td>1.0840</td>\n",
       "      <td>5.2303</td>\n",
       "      <td>50.1874</td>\n",
       "      <td>0.8874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>1.939400</td>\n",
       "      <td>1.940110</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.2640</td>\n",
       "      <td>9.1928</td>\n",
       "      <td>0.7397</td>\n",
       "      <td>58.0711</td>\n",
       "      <td>1.1132</td>\n",
       "      <td>2.9439</td>\n",
       "      <td>58.6946</td>\n",
       "      <td>1.1114</td>\n",
       "      <td>4.8964</td>\n",
       "      <td>49.9135</td>\n",
       "      <td>0.8574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>1.938900</td>\n",
       "      <td>1.936854</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.2452</td>\n",
       "      <td>8.2259</td>\n",
       "      <td>0.4168</td>\n",
       "      <td>57.4203</td>\n",
       "      <td>1.1527</td>\n",
       "      <td>3.3158</td>\n",
       "      <td>57.3799</td>\n",
       "      <td>1.0610</td>\n",
       "      <td>5.4389</td>\n",
       "      <td>51.1047</td>\n",
       "      <td>0.8636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>1.933800</td>\n",
       "      <td>1.936924</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.3264</td>\n",
       "      <td>8.0244</td>\n",
       "      <td>0.4731</td>\n",
       "      <td>56.1765</td>\n",
       "      <td>1.0343</td>\n",
       "      <td>2.3101</td>\n",
       "      <td>56.9676</td>\n",
       "      <td>1.2378</td>\n",
       "      <td>4.0636</td>\n",
       "      <td>53.9051</td>\n",
       "      <td>0.8799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>1.939500</td>\n",
       "      <td>1.939427</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>0.3646</td>\n",
       "      <td>9.3715</td>\n",
       "      <td>1.014</td>\n",
       "      <td>46.1203</td>\n",
       "      <td>1.164</td>\n",
       "      <td>3.3515</td>\n",
       "      <td>49.2301</td>\n",
       "      <td>0.9429</td>\n",
       "      <td>5.3356</td>\n",
       "      <td>54.2401</td>\n",
       "      <td>0.9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>1.934800</td>\n",
       "      <td>1.934761</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.2976</td>\n",
       "      <td>9.6936</td>\n",
       "      <td>0.571</td>\n",
       "      <td>61.2317</td>\n",
       "      <td>1.1161</td>\n",
       "      <td>3.0228</td>\n",
       "      <td>60.6938</td>\n",
       "      <td>1.0742</td>\n",
       "      <td>4.5680</td>\n",
       "      <td>52.3856</td>\n",
       "      <td>0.9107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>1.936100</td>\n",
       "      <td>1.937390</td>\n",
       "      <td>0.0540</td>\n",
       "      <td>0.3579</td>\n",
       "      <td>8.3214</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>54.7923</td>\n",
       "      <td>1.1698</td>\n",
       "      <td>3.2922</td>\n",
       "      <td>57.0677</td>\n",
       "      <td>1.0287</td>\n",
       "      <td>3.9926</td>\n",
       "      <td>51.0138</td>\n",
       "      <td>0.8565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>1.934200</td>\n",
       "      <td>1.935113</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>7.9683</td>\n",
       "      <td>0.9169</td>\n",
       "      <td>53.9799</td>\n",
       "      <td>1.1353</td>\n",
       "      <td>3.1054</td>\n",
       "      <td>56.1466</td>\n",
       "      <td>1.0685</td>\n",
       "      <td>3.4831</td>\n",
       "      <td>50.7191</td>\n",
       "      <td>0.8634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>1.931500</td>\n",
       "      <td>1.938685</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.3431</td>\n",
       "      <td>7.7008</td>\n",
       "      <td>0.94</td>\n",
       "      <td>49.0782</td>\n",
       "      <td>1.1376</td>\n",
       "      <td>3.3922</td>\n",
       "      <td>53.7308</td>\n",
       "      <td>1.1075</td>\n",
       "      <td>3.6773</td>\n",
       "      <td>50.5074</td>\n",
       "      <td>0.819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>1.934600</td>\n",
       "      <td>1.939010</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.314</td>\n",
       "      <td>8.5452</td>\n",
       "      <td>1.0109</td>\n",
       "      <td>53.8664</td>\n",
       "      <td>1.0697</td>\n",
       "      <td>3.6499</td>\n",
       "      <td>55.5432</td>\n",
       "      <td>1.0623</td>\n",
       "      <td>4.1032</td>\n",
       "      <td>48.5511</td>\n",
       "      <td>0.8357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>1.927500</td>\n",
       "      <td>1.938491</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.4635</td>\n",
       "      <td>9.1458</td>\n",
       "      <td>1.3824</td>\n",
       "      <td>57.4984</td>\n",
       "      <td>1.1467</td>\n",
       "      <td>3.7516</td>\n",
       "      <td>56.0639</td>\n",
       "      <td>1.0372</td>\n",
       "      <td>4.0217</td>\n",
       "      <td>48.7136</td>\n",
       "      <td>0.8193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>1.927400</td>\n",
       "      <td>1.936296</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>8.4599</td>\n",
       "      <td>1.4382</td>\n",
       "      <td>55.6640</td>\n",
       "      <td>1.1169</td>\n",
       "      <td>3.5627</td>\n",
       "      <td>55.8211</td>\n",
       "      <td>0.9928</td>\n",
       "      <td>3.3436</td>\n",
       "      <td>48.7081</td>\n",
       "      <td>0.8455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>1.934400</td>\n",
       "      <td>1.935448</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.3836</td>\n",
       "      <td>7.8174</td>\n",
       "      <td>1.0080</td>\n",
       "      <td>58.0248</td>\n",
       "      <td>1.0838</td>\n",
       "      <td>3.2476</td>\n",
       "      <td>57.1746</td>\n",
       "      <td>1.0311</td>\n",
       "      <td>3.3451</td>\n",
       "      <td>49.4044</td>\n",
       "      <td>0.893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>1.930100</td>\n",
       "      <td>1.935202</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.3353</td>\n",
       "      <td>8.5872</td>\n",
       "      <td>1.0488</td>\n",
       "      <td>55.7472</td>\n",
       "      <td>1.0662</td>\n",
       "      <td>3.3245</td>\n",
       "      <td>57.8305</td>\n",
       "      <td>1.0688</td>\n",
       "      <td>4.0896</td>\n",
       "      <td>50.8490</td>\n",
       "      <td>0.8967</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-cacad506cdf0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# .1 lq loss with conditioned kelly betting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 1e-4, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# .1 lq loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3314' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3314/43942 16:14 < 3:19:13, 3.40 it/s, Epoch 0.08/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.664100</td>\n",
       "      <td>0.650676</td>\n",
       "      <td>0.0066</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>15.9033</td>\n",
       "      <td>2.1766</td>\n",
       "      <td>43.1685</td>\n",
       "      <td>1.0254</td>\n",
       "      <td>5.7688</td>\n",
       "      <td>43.0185</td>\n",
       "      <td>0.9422</td>\n",
       "      <td>18.0830</td>\n",
       "      <td>50.3676</td>\n",
       "      <td>0.944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.652900</td>\n",
       "      <td>0.649014</td>\n",
       "      <td>0.027</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>17.3993</td>\n",
       "      <td>2.0565</td>\n",
       "      <td>37.3785</td>\n",
       "      <td>0.9042</td>\n",
       "      <td>8.1851</td>\n",
       "      <td>47.9941</td>\n",
       "      <td>0.9329</td>\n",
       "      <td>19.0856</td>\n",
       "      <td>50.4265</td>\n",
       "      <td>0.9411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.651900</td>\n",
       "      <td>0.648749</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>17.9478</td>\n",
       "      <td>4.8679</td>\n",
       "      <td>39.4632</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>4.5464</td>\n",
       "      <td>45.8572</td>\n",
       "      <td>1.0331</td>\n",
       "      <td>19.7826</td>\n",
       "      <td>51.1519</td>\n",
       "      <td>0.9437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-201e9f6b8861>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# .5 lq loss with assumed 1:1 rr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 1e-4, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# .5 lq loss with assumed 1:1 rr\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87883' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87883/87883 6:27:57, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.667000</td>\n",
       "      <td>0.655451</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.0898</td>\n",
       "      <td>15.3858</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>30.</td>\n",
       "      <td>2.9798</td>\n",
       "      <td>2.8299</td>\n",
       "      <td>48.3059</td>\n",
       "      <td>1.0029</td>\n",
       "      <td>27.5772</td>\n",
       "      <td>49.5587</td>\n",
       "      <td>0.9389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.656000</td>\n",
       "      <td>0.650970</td>\n",
       "      <td>-0.0109</td>\n",
       "      <td>-0.0556</td>\n",
       "      <td>15.7351</td>\n",
       "      <td>0.3013</td>\n",
       "      <td>40.974</td>\n",
       "      <td>0.7897</td>\n",
       "      <td>5.3742</td>\n",
       "      <td>48.8608</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>23.6307</td>\n",
       "      <td>49.6422</td>\n",
       "      <td>0.9091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.655500</td>\n",
       "      <td>0.649778</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.1372</td>\n",
       "      <td>16.8886</td>\n",
       "      <td>0.7493</td>\n",
       "      <td>47.2316</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>5.5449</td>\n",
       "      <td>47.7644</td>\n",
       "      <td>0.9594</td>\n",
       "      <td>26.3971</td>\n",
       "      <td>50.6313</td>\n",
       "      <td>0.9778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.652600</td>\n",
       "      <td>0.653715</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>17.3191</td>\n",
       "      <td>0.3581</td>\n",
       "      <td>60.8266</td>\n",
       "      <td>0.9558</td>\n",
       "      <td>7.7295</td>\n",
       "      <td>51.1537</td>\n",
       "      <td>0.8766</td>\n",
       "      <td>25.3773</td>\n",
       "      <td>50.094</td>\n",
       "      <td>0.9559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.652900</td>\n",
       "      <td>0.654328</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.0819</td>\n",
       "      <td>19.5381</td>\n",
       "      <td>0.9842</td>\n",
       "      <td>62.6783</td>\n",
       "      <td>1.0526</td>\n",
       "      <td>11.0116</td>\n",
       "      <td>50.3153</td>\n",
       "      <td>0.8907</td>\n",
       "      <td>26.8223</td>\n",
       "      <td>50.3900</td>\n",
       "      <td>0.9317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.652600</td>\n",
       "      <td>0.649119</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0863</td>\n",
       "      <td>16.8579</td>\n",
       "      <td>0.4707</td>\n",
       "      <td>39.8818</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>7.1575</td>\n",
       "      <td>45.3839</td>\n",
       "      <td>0.9354</td>\n",
       "      <td>23.8249</td>\n",
       "      <td>50.7444</td>\n",
       "      <td>0.9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.649700</td>\n",
       "      <td>0.647446</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>17.0034</td>\n",
       "      <td>1.3593</td>\n",
       "      <td>62.6745</td>\n",
       "      <td>1.1580</td>\n",
       "      <td>8.4913</td>\n",
       "      <td>49.7296</td>\n",
       "      <td>0.8851</td>\n",
       "      <td>19.6069</td>\n",
       "      <td>50.4264</td>\n",
       "      <td>0.9484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.649300</td>\n",
       "      <td>0.650871</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>16.8794</td>\n",
       "      <td>2.4796</td>\n",
       "      <td>41.7538</td>\n",
       "      <td>0.9853</td>\n",
       "      <td>7.1138</td>\n",
       "      <td>50.2356</td>\n",
       "      <td>0.9050</td>\n",
       "      <td>18.2185</td>\n",
       "      <td>50.8353</td>\n",
       "      <td>0.934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.651600</td>\n",
       "      <td>0.646624</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0504</td>\n",
       "      <td>14.9984</td>\n",
       "      <td>0.2124</td>\n",
       "      <td>58.5468</td>\n",
       "      <td>1.2194</td>\n",
       "      <td>5.0433</td>\n",
       "      <td>54.4821</td>\n",
       "      <td>0.8846</td>\n",
       "      <td>21.7011</td>\n",
       "      <td>50.4197</td>\n",
       "      <td>0.9263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.650400</td>\n",
       "      <td>0.646390</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.2055</td>\n",
       "      <td>14.7952</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>61.2721</td>\n",
       "      <td>1.1778</td>\n",
       "      <td>6.4277</td>\n",
       "      <td>48.0744</td>\n",
       "      <td>0.9870</td>\n",
       "      <td>16.2772</td>\n",
       "      <td>50.5801</td>\n",
       "      <td>0.9451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.645500</td>\n",
       "      <td>0.647278</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>14.6251</td>\n",
       "      <td>1.4666</td>\n",
       "      <td>39.4342</td>\n",
       "      <td>1.0877</td>\n",
       "      <td>5.0414</td>\n",
       "      <td>49.793</td>\n",
       "      <td>0.9179</td>\n",
       "      <td>15.6473</td>\n",
       "      <td>50.2712</td>\n",
       "      <td>0.9523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.647000</td>\n",
       "      <td>0.648636</td>\n",
       "      <td>0.0228</td>\n",
       "      <td>0.1018</td>\n",
       "      <td>16.2516</td>\n",
       "      <td>1.8241</td>\n",
       "      <td>40.5312</td>\n",
       "      <td>0.9183</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>51.6835</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>19.562</td>\n",
       "      <td>51.0149</td>\n",
       "      <td>0.9370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.647700</td>\n",
       "      <td>0.646226</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>15.7061</td>\n",
       "      <td>1.9412</td>\n",
       "      <td>37.0781</td>\n",
       "      <td>0.8753</td>\n",
       "      <td>5.9712</td>\n",
       "      <td>50.9384</td>\n",
       "      <td>0.9325</td>\n",
       "      <td>16.4915</td>\n",
       "      <td>51.7906</td>\n",
       "      <td>0.8983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.648700</td>\n",
       "      <td>0.647607</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.0106</td>\n",
       "      <td>17.6867</td>\n",
       "      <td>1.8234</td>\n",
       "      <td>57.9535</td>\n",
       "      <td>1.0543</td>\n",
       "      <td>5.952</td>\n",
       "      <td>52.1975</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>25.3642</td>\n",
       "      <td>49.6088</td>\n",
       "      <td>0.9650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.649100</td>\n",
       "      <td>0.644926</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.1875</td>\n",
       "      <td>13.7921</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>57.4689</td>\n",
       "      <td>1.2083</td>\n",
       "      <td>4.9347</td>\n",
       "      <td>54.0987</td>\n",
       "      <td>0.8594</td>\n",
       "      <td>15.2081</td>\n",
       "      <td>50.571</td>\n",
       "      <td>0.9207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.646500</td>\n",
       "      <td>0.646162</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.2075</td>\n",
       "      <td>19.8514</td>\n",
       "      <td>4.7561</td>\n",
       "      <td>45.4468</td>\n",
       "      <td>1.0358</td>\n",
       "      <td>6.2885</td>\n",
       "      <td>49.4810</td>\n",
       "      <td>0.8818</td>\n",
       "      <td>23.6059</td>\n",
       "      <td>52.7026</td>\n",
       "      <td>0.9674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.646100</td>\n",
       "      <td>0.645853</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.2065</td>\n",
       "      <td>17.5085</td>\n",
       "      <td>2.9447</td>\n",
       "      <td>49.6993</td>\n",
       "      <td>1.0002</td>\n",
       "      <td>6.4895</td>\n",
       "      <td>51.7767</td>\n",
       "      <td>0.8733</td>\n",
       "      <td>19.5435</td>\n",
       "      <td>51.4301</td>\n",
       "      <td>0.954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.647400</td>\n",
       "      <td>0.648624</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>14.7463</td>\n",
       "      <td>3.3538</td>\n",
       "      <td>41.9212</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>5.858</td>\n",
       "      <td>49.3770</td>\n",
       "      <td>1.0164</td>\n",
       "      <td>9.9490</td>\n",
       "      <td>52.9935</td>\n",
       "      <td>0.9243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.646300</td>\n",
       "      <td>0.645089</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>15.8397</td>\n",
       "      <td>3.8942</td>\n",
       "      <td>50.</td>\n",
       "      <td>0.8643</td>\n",
       "      <td>6.0609</td>\n",
       "      <td>49.3895</td>\n",
       "      <td>0.8882</td>\n",
       "      <td>11.9395</td>\n",
       "      <td>51.1479</td>\n",
       "      <td>0.9415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.647400</td>\n",
       "      <td>0.646285</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>14.8209</td>\n",
       "      <td>1.3757</td>\n",
       "      <td>48.8139</td>\n",
       "      <td>1.1215</td>\n",
       "      <td>5.1929</td>\n",
       "      <td>53.5016</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>16.8711</td>\n",
       "      <td>50.7100</td>\n",
       "      <td>0.9124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.645578</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>0.1775</td>\n",
       "      <td>17.1475</td>\n",
       "      <td>3.9773</td>\n",
       "      <td>50.0970</td>\n",
       "      <td>1.0672</td>\n",
       "      <td>6.5992</td>\n",
       "      <td>49.7230</td>\n",
       "      <td>0.8374</td>\n",
       "      <td>16.0164</td>\n",
       "      <td>51.3667</td>\n",
       "      <td>0.9369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.645300</td>\n",
       "      <td>0.643881</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>0.2083</td>\n",
       "      <td>17.6056</td>\n",
       "      <td>3.4896</td>\n",
       "      <td>52.677</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>6.9045</td>\n",
       "      <td>49.4064</td>\n",
       "      <td>0.8167</td>\n",
       "      <td>18.6002</td>\n",
       "      <td>51.5696</td>\n",
       "      <td>0.9566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.646400</td>\n",
       "      <td>0.647067</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>18.9914</td>\n",
       "      <td>4.0580</td>\n",
       "      <td>44.2817</td>\n",
       "      <td>1.0078</td>\n",
       "      <td>7.2049</td>\n",
       "      <td>51.8145</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>20.9779</td>\n",
       "      <td>50.9367</td>\n",
       "      <td>0.8947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.646100</td>\n",
       "      <td>0.644817</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.1313</td>\n",
       "      <td>15.4763</td>\n",
       "      <td>1.9737</td>\n",
       "      <td>45.3503</td>\n",
       "      <td>1.053</td>\n",
       "      <td>5.3043</td>\n",
       "      <td>49.5636</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>15.8026</td>\n",
       "      <td>51.2867</td>\n",
       "      <td>0.919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.644900</td>\n",
       "      <td>0.645459</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>14.0866</td>\n",
       "      <td>1.3953</td>\n",
       "      <td>58.2449</td>\n",
       "      <td>1.0426</td>\n",
       "      <td>4.311</td>\n",
       "      <td>52.9415</td>\n",
       "      <td>0.8194</td>\n",
       "      <td>16.2261</td>\n",
       "      <td>50.5024</td>\n",
       "      <td>0.8946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.643600</td>\n",
       "      <td>0.643571</td>\n",
       "      <td>0.021</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>13.7545</td>\n",
       "      <td>2.1105</td>\n",
       "      <td>48.5406</td>\n",
       "      <td>1.0819</td>\n",
       "      <td>4.9923</td>\n",
       "      <td>49.6364</td>\n",
       "      <td>0.8781</td>\n",
       "      <td>11.0223</td>\n",
       "      <td>51.446</td>\n",
       "      <td>0.8755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.645500</td>\n",
       "      <td>0.645186</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.1863</td>\n",
       "      <td>14.9858</td>\n",
       "      <td>2.1309</td>\n",
       "      <td>47.7621</td>\n",
       "      <td>1.1362</td>\n",
       "      <td>4.9187</td>\n",
       "      <td>50.3845</td>\n",
       "      <td>0.9095</td>\n",
       "      <td>15.7922</td>\n",
       "      <td>51.1698</td>\n",
       "      <td>0.9014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.644300</td>\n",
       "      <td>0.645657</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.1936</td>\n",
       "      <td>14.6580</td>\n",
       "      <td>1.9833</td>\n",
       "      <td>64.2643</td>\n",
       "      <td>0.9796</td>\n",
       "      <td>4.3816</td>\n",
       "      <td>53.3503</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>15.3749</td>\n",
       "      <td>50.4829</td>\n",
       "      <td>0.9189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.645600</td>\n",
       "      <td>0.644046</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.1911</td>\n",
       "      <td>14.2518</td>\n",
       "      <td>2.2761</td>\n",
       "      <td>44.8594</td>\n",
       "      <td>1.1624</td>\n",
       "      <td>4.1605</td>\n",
       "      <td>50.3937</td>\n",
       "      <td>0.8989</td>\n",
       "      <td>14.3501</td>\n",
       "      <td>52.1905</td>\n",
       "      <td>0.9341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.644500</td>\n",
       "      <td>0.645357</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>17.2159</td>\n",
       "      <td>3.5576</td>\n",
       "      <td>48.9636</td>\n",
       "      <td>1.0915</td>\n",
       "      <td>5.7782</td>\n",
       "      <td>49.6541</td>\n",
       "      <td>0.8716</td>\n",
       "      <td>17.6908</td>\n",
       "      <td>51.2878</td>\n",
       "      <td>0.9444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>0.645203</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>16.3638</td>\n",
       "      <td>3.4869</td>\n",
       "      <td>45.0954</td>\n",
       "      <td>1.1274</td>\n",
       "      <td>5.0679</td>\n",
       "      <td>51.4764</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>16.7273</td>\n",
       "      <td>51.1755</td>\n",
       "      <td>0.9263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.646600</td>\n",
       "      <td>0.644788</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.1756</td>\n",
       "      <td>14.8448</td>\n",
       "      <td>3.0301</td>\n",
       "      <td>57.5037</td>\n",
       "      <td>1.0698</td>\n",
       "      <td>4.6361</td>\n",
       "      <td>48.3097</td>\n",
       "      <td>0.7808</td>\n",
       "      <td>13.5753</td>\n",
       "      <td>50.7123</td>\n",
       "      <td>0.9370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.643847</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>15.618</td>\n",
       "      <td>3.4403</td>\n",
       "      <td>45.4592</td>\n",
       "      <td>1.0236</td>\n",
       "      <td>5.4351</td>\n",
       "      <td>49.3344</td>\n",
       "      <td>0.8389</td>\n",
       "      <td>12.6809</td>\n",
       "      <td>52.2464</td>\n",
       "      <td>0.8977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.644100</td>\n",
       "      <td>0.645603</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>0.3099</td>\n",
       "      <td>18.4568</td>\n",
       "      <td>4.9532</td>\n",
       "      <td>50.7738</td>\n",
       "      <td>1.0011</td>\n",
       "      <td>5.5567</td>\n",
       "      <td>49.3615</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>18.7075</td>\n",
       "      <td>52.1306</td>\n",
       "      <td>0.9914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.645000</td>\n",
       "      <td>0.644850</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>17.5827</td>\n",
       "      <td>4.6244</td>\n",
       "      <td>48.7048</td>\n",
       "      <td>1.1111</td>\n",
       "      <td>5.0467</td>\n",
       "      <td>50.2895</td>\n",
       "      <td>0.833</td>\n",
       "      <td>15.9072</td>\n",
       "      <td>51.3152</td>\n",
       "      <td>0.9339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.644300</td>\n",
       "      <td>0.645886</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>17.9197</td>\n",
       "      <td>5.3013</td>\n",
       "      <td>50.4605</td>\n",
       "      <td>1.0455</td>\n",
       "      <td>5.6968</td>\n",
       "      <td>48.4246</td>\n",
       "      <td>0.8243</td>\n",
       "      <td>16.9114</td>\n",
       "      <td>50.5621</td>\n",
       "      <td>0.9051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.643900</td>\n",
       "      <td>0.643876</td>\n",
       "      <td>0.0534</td>\n",
       "      <td>0.2209</td>\n",
       "      <td>15.077</td>\n",
       "      <td>4.0512</td>\n",
       "      <td>51.6470</td>\n",
       "      <td>1.1468</td>\n",
       "      <td>4.9665</td>\n",
       "      <td>48.8322</td>\n",
       "      <td>0.7688</td>\n",
       "      <td>11.8153</td>\n",
       "      <td>51.3463</td>\n",
       "      <td>0.9044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.644600</td>\n",
       "      <td>0.643829</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>15.1596</td>\n",
       "      <td>4.0373</td>\n",
       "      <td>52.5582</td>\n",
       "      <td>1.1370</td>\n",
       "      <td>5.0029</td>\n",
       "      <td>48.4564</td>\n",
       "      <td>0.7691</td>\n",
       "      <td>12.2394</td>\n",
       "      <td>50.1385</td>\n",
       "      <td>0.8726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.643500</td>\n",
       "      <td>0.643485</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>15.9503</td>\n",
       "      <td>3.4659</td>\n",
       "      <td>49.3139</td>\n",
       "      <td>1.166</td>\n",
       "      <td>4.8693</td>\n",
       "      <td>50.8066</td>\n",
       "      <td>0.8825</td>\n",
       "      <td>14.0428</td>\n",
       "      <td>52.0920</td>\n",
       "      <td>0.9160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.643584</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>14.7777</td>\n",
       "      <td>2.1343</td>\n",
       "      <td>52.3143</td>\n",
       "      <td>1.164</td>\n",
       "      <td>4.8768</td>\n",
       "      <td>51.3099</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>14.8883</td>\n",
       "      <td>51.8033</td>\n",
       "      <td>0.9238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.644500</td>\n",
       "      <td>0.643422</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>15.2512</td>\n",
       "      <td>3.4686</td>\n",
       "      <td>53.2366</td>\n",
       "      <td>1.1215</td>\n",
       "      <td>4.8005</td>\n",
       "      <td>49.0316</td>\n",
       "      <td>0.8271</td>\n",
       "      <td>13.2762</td>\n",
       "      <td>51.7045</td>\n",
       "      <td>0.8947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.644500</td>\n",
       "      <td>0.644861</td>\n",
       "      <td>0.0830</td>\n",
       "      <td>0.2547</td>\n",
       "      <td>19.0319</td>\n",
       "      <td>6.0491</td>\n",
       "      <td>44.1847</td>\n",
       "      <td>0.9288</td>\n",
       "      <td>5.1975</td>\n",
       "      <td>55.3506</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>18.0496</td>\n",
       "      <td>53.2549</td>\n",
       "      <td>0.9952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.642200</td>\n",
       "      <td>0.644433</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.2192</td>\n",
       "      <td>13.2807</td>\n",
       "      <td>4.1540</td>\n",
       "      <td>49.0317</td>\n",
       "      <td>1.0726</td>\n",
       "      <td>4.2159</td>\n",
       "      <td>50.2085</td>\n",
       "      <td>0.8637</td>\n",
       "      <td>7.3383</td>\n",
       "      <td>51.7392</td>\n",
       "      <td>0.9171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.644200</td>\n",
       "      <td>0.643867</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.2353</td>\n",
       "      <td>17.8991</td>\n",
       "      <td>3.4558</td>\n",
       "      <td>55.5673</td>\n",
       "      <td>1.0965</td>\n",
       "      <td>4.9151</td>\n",
       "      <td>51.2649</td>\n",
       "      <td>0.8452</td>\n",
       "      <td>20.4880</td>\n",
       "      <td>52.0905</td>\n",
       "      <td>0.9771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.644135</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>0.1985</td>\n",
       "      <td>20.3508</td>\n",
       "      <td>5.9392</td>\n",
       "      <td>47.9991</td>\n",
       "      <td>1.0246</td>\n",
       "      <td>4.9089</td>\n",
       "      <td>49.6367</td>\n",
       "      <td>0.8884</td>\n",
       "      <td>23.2458</td>\n",
       "      <td>51.8164</td>\n",
       "      <td>0.9636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.644800</td>\n",
       "      <td>0.643568</td>\n",
       "      <td>0.0803</td>\n",
       "      <td>0.276</td>\n",
       "      <td>15.7111</td>\n",
       "      <td>4.6707</td>\n",
       "      <td>49.0724</td>\n",
       "      <td>1.0456</td>\n",
       "      <td>4.5645</td>\n",
       "      <td>49.5441</td>\n",
       "      <td>0.8609</td>\n",
       "      <td>10.8607</td>\n",
       "      <td>52.6217</td>\n",
       "      <td>0.9535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.643425</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>14.807</td>\n",
       "      <td>4.9785</td>\n",
       "      <td>51.4051</td>\n",
       "      <td>1.0718</td>\n",
       "      <td>4.1283</td>\n",
       "      <td>49.0394</td>\n",
       "      <td>0.8197</td>\n",
       "      <td>8.7707</td>\n",
       "      <td>51.9585</td>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.642100</td>\n",
       "      <td>0.643240</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.1955</td>\n",
       "      <td>13.8591</td>\n",
       "      <td>3.8509</td>\n",
       "      <td>49.0146</td>\n",
       "      <td>1.1140</td>\n",
       "      <td>3.9437</td>\n",
       "      <td>49.8188</td>\n",
       "      <td>0.8321</td>\n",
       "      <td>8.8492</td>\n",
       "      <td>51.4795</td>\n",
       "      <td>0.9245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.643200</td>\n",
       "      <td>0.643412</td>\n",
       "      <td>0.0669</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>15.4477</td>\n",
       "      <td>3.5046</td>\n",
       "      <td>52.1223</td>\n",
       "      <td>1.1197</td>\n",
       "      <td>4.5893</td>\n",
       "      <td>49.0835</td>\n",
       "      <td>0.8773</td>\n",
       "      <td>13.1517</td>\n",
       "      <td>51.4042</td>\n",
       "      <td>0.9848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.640900</td>\n",
       "      <td>0.643112</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.2711</td>\n",
       "      <td>13.872</td>\n",
       "      <td>4.4143</td>\n",
       "      <td>44.7934</td>\n",
       "      <td>1.0211</td>\n",
       "      <td>4.194</td>\n",
       "      <td>54.4547</td>\n",
       "      <td>0.9296</td>\n",
       "      <td>7.4676</td>\n",
       "      <td>51.9547</td>\n",
       "      <td>0.9399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.644000</td>\n",
       "      <td>0.644711</td>\n",
       "      <td>0.0668</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>15.3913</td>\n",
       "      <td>3.6782</td>\n",
       "      <td>48.6106</td>\n",
       "      <td>1.0793</td>\n",
       "      <td>4.6151</td>\n",
       "      <td>51.4951</td>\n",
       "      <td>0.9141</td>\n",
       "      <td>13.4382</td>\n",
       "      <td>52.4026</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.642300</td>\n",
       "      <td>0.644015</td>\n",
       "      <td>0.0514</td>\n",
       "      <td>0.2669</td>\n",
       "      <td>14.4876</td>\n",
       "      <td>4.3549</td>\n",
       "      <td>47.9232</td>\n",
       "      <td>1.0780</td>\n",
       "      <td>4.6190</td>\n",
       "      <td>50.2437</td>\n",
       "      <td>0.8805</td>\n",
       "      <td>9.0196</td>\n",
       "      <td>52.1338</td>\n",
       "      <td>0.9474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.639500</td>\n",
       "      <td>0.644101</td>\n",
       "      <td>0.0835</td>\n",
       "      <td>0.2726</td>\n",
       "      <td>16.59</td>\n",
       "      <td>5.9002</td>\n",
       "      <td>46.8689</td>\n",
       "      <td>0.9985</td>\n",
       "      <td>4.0098</td>\n",
       "      <td>51.0410</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>10.5996</td>\n",
       "      <td>53.6899</td>\n",
       "      <td>1.0088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.642500</td>\n",
       "      <td>0.644141</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>15.2669</td>\n",
       "      <td>4.213</td>\n",
       "      <td>47.4749</td>\n",
       "      <td>1.0213</td>\n",
       "      <td>4.6476</td>\n",
       "      <td>51.7773</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>11.8482</td>\n",
       "      <td>52.0888</td>\n",
       "      <td>0.8931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.641300</td>\n",
       "      <td>0.644020</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.2278</td>\n",
       "      <td>14.3649</td>\n",
       "      <td>4.1000</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>1.046</td>\n",
       "      <td>3.9714</td>\n",
       "      <td>51.3792</td>\n",
       "      <td>0.8936</td>\n",
       "      <td>10.5267</td>\n",
       "      <td>52.1389</td>\n",
       "      <td>0.9186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.640400</td>\n",
       "      <td>0.643976</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>0.2813</td>\n",
       "      <td>15.2899</td>\n",
       "      <td>5.0379</td>\n",
       "      <td>48.4559</td>\n",
       "      <td>1.0659</td>\n",
       "      <td>4.2364</td>\n",
       "      <td>52.6171</td>\n",
       "      <td>0.8973</td>\n",
       "      <td>10.2827</td>\n",
       "      <td>51.4756</td>\n",
       "      <td>0.9287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.642400</td>\n",
       "      <td>0.643476</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>0.2839</td>\n",
       "      <td>14.0928</td>\n",
       "      <td>4.0065</td>\n",
       "      <td>54.2969</td>\n",
       "      <td>1.1136</td>\n",
       "      <td>3.9146</td>\n",
       "      <td>49.3004</td>\n",
       "      <td>0.8001</td>\n",
       "      <td>10.2486</td>\n",
       "      <td>51.5175</td>\n",
       "      <td>0.9025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.643400</td>\n",
       "      <td>0.642959</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.3146</td>\n",
       "      <td>13.8972</td>\n",
       "      <td>3.6138</td>\n",
       "      <td>54.9757</td>\n",
       "      <td>1.1029</td>\n",
       "      <td>4.2232</td>\n",
       "      <td>49.5432</td>\n",
       "      <td>0.8533</td>\n",
       "      <td>8.0482</td>\n",
       "      <td>50.2908</td>\n",
       "      <td>0.9549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.641900</td>\n",
       "      <td>0.644019</td>\n",
       "      <td>0.0514</td>\n",
       "      <td>0.2473</td>\n",
       "      <td>15.5395</td>\n",
       "      <td>5.0643</td>\n",
       "      <td>51.5436</td>\n",
       "      <td>1.0815</td>\n",
       "      <td>4.1845</td>\n",
       "      <td>49.1884</td>\n",
       "      <td>0.8248</td>\n",
       "      <td>11.6085</td>\n",
       "      <td>51.0820</td>\n",
       "      <td>0.9048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.641700</td>\n",
       "      <td>0.642713</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.2161</td>\n",
       "      <td>14.8392</td>\n",
       "      <td>4.1941</td>\n",
       "      <td>53.1592</td>\n",
       "      <td>1.1390</td>\n",
       "      <td>4.1443</td>\n",
       "      <td>49.1866</td>\n",
       "      <td>0.8008</td>\n",
       "      <td>11.4267</td>\n",
       "      <td>51.1961</td>\n",
       "      <td>0.8849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.641400</td>\n",
       "      <td>0.642021</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.2723</td>\n",
       "      <td>14.4296</td>\n",
       "      <td>3.8187</td>\n",
       "      <td>51.1080</td>\n",
       "      <td>1.1228</td>\n",
       "      <td>3.9572</td>\n",
       "      <td>51.4193</td>\n",
       "      <td>0.8407</td>\n",
       "      <td>10.1637</td>\n",
       "      <td>51.7884</td>\n",
       "      <td>0.9289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.641700</td>\n",
       "      <td>0.642624</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.2512</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>4.8025</td>\n",
       "      <td>53.0145</td>\n",
       "      <td>1.0662</td>\n",
       "      <td>4.1081</td>\n",
       "      <td>47.5167</td>\n",
       "      <td>0.7942</td>\n",
       "      <td>8.9701</td>\n",
       "      <td>50.8108</td>\n",
       "      <td>0.9276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.643400</td>\n",
       "      <td>0.642387</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.2736</td>\n",
       "      <td>14.4749</td>\n",
       "      <td>4.4677</td>\n",
       "      <td>49.8131</td>\n",
       "      <td>1.0662</td>\n",
       "      <td>4.0089</td>\n",
       "      <td>51.3489</td>\n",
       "      <td>0.8902</td>\n",
       "      <td>10.2167</td>\n",
       "      <td>51.6968</td>\n",
       "      <td>0.9201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.642600</td>\n",
       "      <td>0.642342</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.2609</td>\n",
       "      <td>14.3489</td>\n",
       "      <td>4.7428</td>\n",
       "      <td>50.2014</td>\n",
       "      <td>1.0600</td>\n",
       "      <td>3.8556</td>\n",
       "      <td>50.1755</td>\n",
       "      <td>0.8440</td>\n",
       "      <td>9.289</td>\n",
       "      <td>52.0569</td>\n",
       "      <td>0.9100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.641500</td>\n",
       "      <td>0.642893</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.2023</td>\n",
       "      <td>14.6937</td>\n",
       "      <td>4.5184</td>\n",
       "      <td>49.7858</td>\n",
       "      <td>1.1136</td>\n",
       "      <td>4.1033</td>\n",
       "      <td>49.7549</td>\n",
       "      <td>0.8431</td>\n",
       "      <td>10.2677</td>\n",
       "      <td>51.1999</td>\n",
       "      <td>0.9013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.642589</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.2977</td>\n",
       "      <td>14.5357</td>\n",
       "      <td>4.4075</td>\n",
       "      <td>47.9394</td>\n",
       "      <td>1.0778</td>\n",
       "      <td>3.961</td>\n",
       "      <td>52.3025</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>10.3618</td>\n",
       "      <td>52.1388</td>\n",
       "      <td>0.9285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.642814</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>14.6524</td>\n",
       "      <td>4.4954</td>\n",
       "      <td>50.5163</td>\n",
       "      <td>1.0787</td>\n",
       "      <td>4.1047</td>\n",
       "      <td>51.5223</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>10.3921</td>\n",
       "      <td>51.6055</td>\n",
       "      <td>0.8926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.641500</td>\n",
       "      <td>0.642034</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>0.3556</td>\n",
       "      <td>13.5324</td>\n",
       "      <td>4.1650</td>\n",
       "      <td>50.0228</td>\n",
       "      <td>1.1427</td>\n",
       "      <td>3.7998</td>\n",
       "      <td>51.9308</td>\n",
       "      <td>0.8697</td>\n",
       "      <td>8.323</td>\n",
       "      <td>51.8131</td>\n",
       "      <td>0.9516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>0.641500</td>\n",
       "      <td>0.642565</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>13.5752</td>\n",
       "      <td>3.8363</td>\n",
       "      <td>51.8729</td>\n",
       "      <td>1.1444</td>\n",
       "      <td>3.7534</td>\n",
       "      <td>51.2014</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>9.5203</td>\n",
       "      <td>51.7352</td>\n",
       "      <td>0.9182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.642900</td>\n",
       "      <td>0.642518</td>\n",
       "      <td>0.0543</td>\n",
       "      <td>0.3174</td>\n",
       "      <td>13.6567</td>\n",
       "      <td>4.4051</td>\n",
       "      <td>50.4523</td>\n",
       "      <td>1.0931</td>\n",
       "      <td>3.5795</td>\n",
       "      <td>51.9648</td>\n",
       "      <td>0.8796</td>\n",
       "      <td>8.3903</td>\n",
       "      <td>51.5935</td>\n",
       "      <td>0.9221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>0.641400</td>\n",
       "      <td>0.642241</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>0.3292</td>\n",
       "      <td>13.9708</td>\n",
       "      <td>4.4138</td>\n",
       "      <td>48.5671</td>\n",
       "      <td>1.1130</td>\n",
       "      <td>3.5372</td>\n",
       "      <td>53.6189</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>8.8552</td>\n",
       "      <td>52.0041</td>\n",
       "      <td>0.9244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.642080</td>\n",
       "      <td>0.0792</td>\n",
       "      <td>0.3620</td>\n",
       "      <td>14.3571</td>\n",
       "      <td>4.2981</td>\n",
       "      <td>49.0891</td>\n",
       "      <td>1.1129</td>\n",
       "      <td>3.7993</td>\n",
       "      <td>53.2528</td>\n",
       "      <td>0.8954</td>\n",
       "      <td>10.0540</td>\n",
       "      <td>52.1936</td>\n",
       "      <td>0.9349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>0.643300</td>\n",
       "      <td>0.642056</td>\n",
       "      <td>0.0785</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>14.1851</td>\n",
       "      <td>4.0288</td>\n",
       "      <td>49.4286</td>\n",
       "      <td>1.1089</td>\n",
       "      <td>3.8747</td>\n",
       "      <td>52.8891</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>10.1619</td>\n",
       "      <td>52.2792</td>\n",
       "      <td>0.9416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.640500</td>\n",
       "      <td>0.641688</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>0.3681</td>\n",
       "      <td>13.754</td>\n",
       "      <td>3.9777</td>\n",
       "      <td>50.0509</td>\n",
       "      <td>1.1112</td>\n",
       "      <td>3.7944</td>\n",
       "      <td>52.3519</td>\n",
       "      <td>0.8901</td>\n",
       "      <td>9.4085</td>\n",
       "      <td>52.0906</td>\n",
       "      <td>0.9533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.641795</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.3690</td>\n",
       "      <td>14.471</td>\n",
       "      <td>4.3656</td>\n",
       "      <td>50.3520</td>\n",
       "      <td>1.0895</td>\n",
       "      <td>3.8598</td>\n",
       "      <td>51.6779</td>\n",
       "      <td>0.8914</td>\n",
       "      <td>10.3906</td>\n",
       "      <td>52.1937</td>\n",
       "      <td>0.9493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.642300</td>\n",
       "      <td>0.642335</td>\n",
       "      <td>0.0674</td>\n",
       "      <td>0.3506</td>\n",
       "      <td>14.6266</td>\n",
       "      <td>4.4289</td>\n",
       "      <td>50.0271</td>\n",
       "      <td>1.0816</td>\n",
       "      <td>3.8861</td>\n",
       "      <td>51.4973</td>\n",
       "      <td>0.891</td>\n",
       "      <td>10.6217</td>\n",
       "      <td>51.8786</td>\n",
       "      <td>0.9432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>0.639500</td>\n",
       "      <td>0.641657</td>\n",
       "      <td>0.069</td>\n",
       "      <td>0.3715</td>\n",
       "      <td>13.6954</td>\n",
       "      <td>4.5205</td>\n",
       "      <td>48.9381</td>\n",
       "      <td>1.0868</td>\n",
       "      <td>3.6669</td>\n",
       "      <td>52.3681</td>\n",
       "      <td>0.9018</td>\n",
       "      <td>8.2105</td>\n",
       "      <td>52.0005</td>\n",
       "      <td>0.9432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.639900</td>\n",
       "      <td>0.641782</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.3854</td>\n",
       "      <td>13.7409</td>\n",
       "      <td>4.256</td>\n",
       "      <td>49.8425</td>\n",
       "      <td>1.1052</td>\n",
       "      <td>3.7051</td>\n",
       "      <td>52.6749</td>\n",
       "      <td>0.8930</td>\n",
       "      <td>8.8816</td>\n",
       "      <td>52.1591</td>\n",
       "      <td>0.9538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>0.642000</td>\n",
       "      <td>0.641985</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.3699</td>\n",
       "      <td>14.0048</td>\n",
       "      <td>4.2246</td>\n",
       "      <td>50.7366</td>\n",
       "      <td>1.0935</td>\n",
       "      <td>3.6732</td>\n",
       "      <td>52.6327</td>\n",
       "      <td>0.8912</td>\n",
       "      <td>9.7683</td>\n",
       "      <td>51.9774</td>\n",
       "      <td>0.9384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.640300</td>\n",
       "      <td>0.641640</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.3912</td>\n",
       "      <td>13.6532</td>\n",
       "      <td>4.0299</td>\n",
       "      <td>49.9011</td>\n",
       "      <td>1.113</td>\n",
       "      <td>3.6644</td>\n",
       "      <td>53.7368</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>9.2596</td>\n",
       "      <td>52.0484</td>\n",
       "      <td>0.9532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>0.639700</td>\n",
       "      <td>0.641732</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.3835</td>\n",
       "      <td>13.8068</td>\n",
       "      <td>4.2037</td>\n",
       "      <td>49.2522</td>\n",
       "      <td>1.1004</td>\n",
       "      <td>3.6683</td>\n",
       "      <td>53.6724</td>\n",
       "      <td>0.9084</td>\n",
       "      <td>9.2380</td>\n",
       "      <td>52.0457</td>\n",
       "      <td>0.9541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.641611</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.3827</td>\n",
       "      <td>13.8259</td>\n",
       "      <td>4.1545</td>\n",
       "      <td>49.5677</td>\n",
       "      <td>1.1090</td>\n",
       "      <td>3.6699</td>\n",
       "      <td>53.6932</td>\n",
       "      <td>0.903</td>\n",
       "      <td>9.4186</td>\n",
       "      <td>52.1931</td>\n",
       "      <td>0.9509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>0.638300</td>\n",
       "      <td>0.641648</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.3811</td>\n",
       "      <td>13.9914</td>\n",
       "      <td>4.1425</td>\n",
       "      <td>49.1068</td>\n",
       "      <td>1.104</td>\n",
       "      <td>3.7238</td>\n",
       "      <td>53.9556</td>\n",
       "      <td>0.9001</td>\n",
       "      <td>9.8017</td>\n",
       "      <td>52.2597</td>\n",
       "      <td>0.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.641700</td>\n",
       "      <td>0.641763</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>13.9414</td>\n",
       "      <td>4.1464</td>\n",
       "      <td>48.8835</td>\n",
       "      <td>1.1019</td>\n",
       "      <td>3.7139</td>\n",
       "      <td>54.0649</td>\n",
       "      <td>0.905</td>\n",
       "      <td>9.6657</td>\n",
       "      <td>52.1796</td>\n",
       "      <td>0.9504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.641777</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.3809</td>\n",
       "      <td>13.9578</td>\n",
       "      <td>4.1577</td>\n",
       "      <td>48.9671</td>\n",
       "      <td>1.1023</td>\n",
       "      <td>3.7136</td>\n",
       "      <td>54.033</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>9.7058</td>\n",
       "      <td>52.1752</td>\n",
       "      <td>0.9486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.640100</td>\n",
       "      <td>0.641730</td>\n",
       "      <td>0.0750</td>\n",
       "      <td>0.3817</td>\n",
       "      <td>13.9541</td>\n",
       "      <td>4.1634</td>\n",
       "      <td>49.0035</td>\n",
       "      <td>1.1015</td>\n",
       "      <td>3.7165</td>\n",
       "      <td>53.9668</td>\n",
       "      <td>0.9046</td>\n",
       "      <td>9.6556</td>\n",
       "      <td>52.2369</td>\n",
       "      <td>0.9493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>0.640200</td>\n",
       "      <td>0.641724</td>\n",
       "      <td>0.0752</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>13.9554</td>\n",
       "      <td>4.1717</td>\n",
       "      <td>48.9721</td>\n",
       "      <td>1.1015</td>\n",
       "      <td>3.7143</td>\n",
       "      <td>53.9777</td>\n",
       "      <td>0.9036</td>\n",
       "      <td>9.6299</td>\n",
       "      <td>52.2593</td>\n",
       "      <td>0.9512</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=87883, training_loss=0.6443798514486679, metrics={'train_runtime': 23281.003, 'train_samples_per_second': 3.775, 'train_steps_per_second': 3.775, 'total_flos': 0.0, 'train_loss': 0.6443798514486679, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 1e-4, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# .5 lq loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5651' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5651/87883 24:52 < 6:02:05, 3.79 it/s, Epoch 0.06/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.814000</td>\n",
       "      <td>0.798143</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.0532</td>\n",
       "      <td>32.3760</td>\n",
       "      <td>9.9256</td>\n",
       "      <td>43.5464</td>\n",
       "      <td>1.0251</td>\n",
       "      <td>22.2158</td>\n",
       "      <td>49.9832</td>\n",
       "      <td>0.9990</td>\n",
       "      <td>28.7764</td>\n",
       "      <td>49.6354</td>\n",
       "      <td>0.9788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.797300</td>\n",
       "      <td>0.790200</td>\n",
       "      <td>-0.0041</td>\n",
       "      <td>-0.0111</td>\n",
       "      <td>35.2848</td>\n",
       "      <td>11.0109</td>\n",
       "      <td>45.7770</td>\n",
       "      <td>0.9289</td>\n",
       "      <td>25.5915</td>\n",
       "      <td>50.7137</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>29.1164</td>\n",
       "      <td>50.2665</td>\n",
       "      <td>0.9558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.796200</td>\n",
       "      <td>0.787852</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>39.6114</td>\n",
       "      <td>15.5571</td>\n",
       "      <td>47.5843</td>\n",
       "      <td>1.0606</td>\n",
       "      <td>28.0976</td>\n",
       "      <td>51.7999</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>26.5537</td>\n",
       "      <td>51.2983</td>\n",
       "      <td>0.9612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.793100</td>\n",
       "      <td>0.795536</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>41.8831</td>\n",
       "      <td>19.3646</td>\n",
       "      <td>47.3065</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>25.9362</td>\n",
       "      <td>51.1922</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>26.1112</td>\n",
       "      <td>51.0016</td>\n",
       "      <td>1.0111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.795700</td>\n",
       "      <td>0.794261</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>43.4069</td>\n",
       "      <td>20.2464</td>\n",
       "      <td>48.7917</td>\n",
       "      <td>0.897</td>\n",
       "      <td>28.8583</td>\n",
       "      <td>51.0366</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>24.7907</td>\n",
       "      <td>50.3845</td>\n",
       "      <td>1.0113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-52d706023e8c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# .8 lq loss with conditioned kelly betting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1738\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2469\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2470\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2472\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2500\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2501\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2502\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2503\u001b[0m         \u001b[1;31m# Save past state if it exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2504\u001b[0m         \u001b[1;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Trader\\trader_models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, ohlcv, labels, future, std_future)\u001b[0m\n\u001b[0;32m    142\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mprobas\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m**\u001b[0m \u001b[1;36m.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m         \u001b[0msoft_profit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msoft_trade\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         return {\n\u001b[0;32m    146\u001b[0m             \u001b[1;34m'loss'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 1e-4, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# .8 lq loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6171' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6171/87883 27:48 < 6:08:18, 3.70 it/s, Epoch 0.07/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.167722</td>\n",
       "      <td>0.2116</td>\n",
       "      <td>0.184</td>\n",
       "      <td>88.4633</td>\n",
       "      <td>86.3415</td>\n",
       "      <td>49.2366</td>\n",
       "      <td>1.0249</td>\n",
       "      <td>6.3458</td>\n",
       "      <td>51.4701</td>\n",
       "      <td>1.0009</td>\n",
       "      <td>3.4172</td>\n",
       "      <td>51.1827</td>\n",
       "      <td>0.9617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.167500</td>\n",
       "      <td>0.164916</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>90.7208</td>\n",
       "      <td>88.4979</td>\n",
       "      <td>49.2968</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>5.6331</td>\n",
       "      <td>49.5363</td>\n",
       "      <td>0.9977</td>\n",
       "      <td>2.8251</td>\n",
       "      <td>50.1925</td>\n",
       "      <td>1.0212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.166800</td>\n",
       "      <td>0.165553</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>95.4491</td>\n",
       "      <td>94.3957</td>\n",
       "      <td>49.3368</td>\n",
       "      <td>0.9917</td>\n",
       "      <td>2.7592</td>\n",
       "      <td>50.0298</td>\n",
       "      <td>1.0105</td>\n",
       "      <td>1.3857</td>\n",
       "      <td>49.9772</td>\n",
       "      <td>0.9251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.166100</td>\n",
       "      <td>0.165610</td>\n",
       "      <td>0.2090</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>97.7005</td>\n",
       "      <td>97.1838</td>\n",
       "      <td>49.5185</td>\n",
       "      <td>1.0135</td>\n",
       "      <td>1.3853</td>\n",
       "      <td>49.0778</td>\n",
       "      <td>0.9866</td>\n",
       "      <td>0.7068</td>\n",
       "      <td>49.7674</td>\n",
       "      <td>1.0011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.166600</td>\n",
       "      <td>0.166102</td>\n",
       "      <td>-0.0475</td>\n",
       "      <td>-0.0619</td>\n",
       "      <td>98.2192</td>\n",
       "      <td>97.7893</td>\n",
       "      <td>49.5288</td>\n",
       "      <td>0.9584</td>\n",
       "      <td>1.1130</td>\n",
       "      <td>50.5512</td>\n",
       "      <td>1.0067</td>\n",
       "      <td>0.5483</td>\n",
       "      <td>50.842</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.166300</td>\n",
       "      <td>0.165361</td>\n",
       "      <td>-0.0351</td>\n",
       "      <td>-0.0466</td>\n",
       "      <td>98.6223</td>\n",
       "      <td>98.2975</td>\n",
       "      <td>49.0120</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.8092</td>\n",
       "      <td>50.0547</td>\n",
       "      <td>1.0132</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>50.073</td>\n",
       "      <td>1.0122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-d8faaf4d3520>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# decile mae loss with conditioned kelly betting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 1e-4, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# decile mae loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='14387' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [14387/43942 1:10:07 < 2:24:05, 3.42 it/s, Epoch 0.33/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.282600</td>\n",
       "      <td>2.203642</td>\n",
       "      <td>-0.004</td>\n",
       "      <td>-0.0400</td>\n",
       "      <td>5.7125</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>75.</td>\n",
       "      <td>3.4474</td>\n",
       "      <td>0.5849</td>\n",
       "      <td>50.9948</td>\n",
       "      <td>0.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.207300</td>\n",
       "      <td>2.191060</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>0.1388</td>\n",
       "      <td>5.8812</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>16.6667</td>\n",
       "      <td>3.7809</td>\n",
       "      <td>2.2022</td>\n",
       "      <td>51.9414</td>\n",
       "      <td>0.9560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.199600</td>\n",
       "      <td>2.185192</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>6.9708</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0694</td>\n",
       "      <td>56.4663</td>\n",
       "      <td>1.6494</td>\n",
       "      <td>4.3019</td>\n",
       "      <td>48.2872</td>\n",
       "      <td>0.9618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.190100</td>\n",
       "      <td>2.181487</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>7.3603</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>50.4773</td>\n",
       "      <td>1.2243</td>\n",
       "      <td>3.8489</td>\n",
       "      <td>48.646</td>\n",
       "      <td>0.9497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.193400</td>\n",
       "      <td>2.178110</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.1022</td>\n",
       "      <td>6.8534</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2355</td>\n",
       "      <td>72.3953</td>\n",
       "      <td>1.4769</td>\n",
       "      <td>4.2753</td>\n",
       "      <td>56.3182</td>\n",
       "      <td>0.9098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.179200</td>\n",
       "      <td>2.185762</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.1247</td>\n",
       "      <td>8.3268</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>57.6348</td>\n",
       "      <td>1.0444</td>\n",
       "      <td>6.8054</td>\n",
       "      <td>48.9526</td>\n",
       "      <td>0.8410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.187200</td>\n",
       "      <td>2.178262</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>8.8692</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.0209</td>\n",
       "      <td>61.8139</td>\n",
       "      <td>1.0840</td>\n",
       "      <td>7.1520</td>\n",
       "      <td>50.9471</td>\n",
       "      <td>0.9041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.186200</td>\n",
       "      <td>2.176835</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.2298</td>\n",
       "      <td>9.6417</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.9329</td>\n",
       "      <td>51.2401</td>\n",
       "      <td>1.0942</td>\n",
       "      <td>7.7159</td>\n",
       "      <td>49.7139</td>\n",
       "      <td>0.8784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.182400</td>\n",
       "      <td>2.181449</td>\n",
       "      <td>-0.0014</td>\n",
       "      <td>-0.0101</td>\n",
       "      <td>7.77</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>1.163</td>\n",
       "      <td>65.4231</td>\n",
       "      <td>1.1456</td>\n",
       "      <td>5.2088</td>\n",
       "      <td>51.6525</td>\n",
       "      <td>0.882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.181800</td>\n",
       "      <td>2.176846</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.1705</td>\n",
       "      <td>7.4033</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.6724</td>\n",
       "      <td>65.2746</td>\n",
       "      <td>1.1939</td>\n",
       "      <td>5.0035</td>\n",
       "      <td>52.6241</td>\n",
       "      <td>0.8653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.176400</td>\n",
       "      <td>2.170310</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>8.6994</td>\n",
       "      <td>0.0231</td>\n",
       "      <td>80.3279</td>\n",
       "      <td>1.0766</td>\n",
       "      <td>2.5113</td>\n",
       "      <td>60.3838</td>\n",
       "      <td>1.0611</td>\n",
       "      <td>6.9872</td>\n",
       "      <td>49.3012</td>\n",
       "      <td>0.8533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.180000</td>\n",
       "      <td>2.172916</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.1511</td>\n",
       "      <td>7.571</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>90.9091</td>\n",
       "      <td>1.1044</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>63.3721</td>\n",
       "      <td>1.1563</td>\n",
       "      <td>4.9839</td>\n",
       "      <td>51.5672</td>\n",
       "      <td>0.8585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.173500</td>\n",
       "      <td>2.169273</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.1312</td>\n",
       "      <td>7.1718</td>\n",
       "      <td>0.0558</td>\n",
       "      <td>77.7778</td>\n",
       "      <td>1.5364</td>\n",
       "      <td>1.4319</td>\n",
       "      <td>61.9788</td>\n",
       "      <td>1.0359</td>\n",
       "      <td>4.8917</td>\n",
       "      <td>50.3387</td>\n",
       "      <td>0.8823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.175200</td>\n",
       "      <td>2.180520</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.2358</td>\n",
       "      <td>8.2828</td>\n",
       "      <td>0.1079</td>\n",
       "      <td>76.6706</td>\n",
       "      <td>1.7191</td>\n",
       "      <td>2.0515</td>\n",
       "      <td>61.8079</td>\n",
       "      <td>1.0110</td>\n",
       "      <td>5.7959</td>\n",
       "      <td>52.8481</td>\n",
       "      <td>0.8707</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-114f2e243c58>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# decile ce loss with conditioned kelly betting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# decile ce loss with conditioned kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='25123' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [25123/43942 2:12:37 < 1:39:21, 3.16 it/s, Epoch 0.57/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.621500</td>\n",
       "      <td>0.602659</td>\n",
       "      <td>-0.0150</td>\n",
       "      <td>-0.0869</td>\n",
       "      <td>13.596</td>\n",
       "      <td>0.0281</td>\n",
       "      <td>54.0541</td>\n",
       "      <td>1.0283</td>\n",
       "      <td>2.5401</td>\n",
       "      <td>50.7046</td>\n",
       "      <td>0.8395</td>\n",
       "      <td>20.9168</td>\n",
       "      <td>49.0076</td>\n",
       "      <td>0.9459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.599900</td>\n",
       "      <td>0.592736</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.2372</td>\n",
       "      <td>6.7494</td>\n",
       "      <td>0.0916</td>\n",
       "      <td>64.7790</td>\n",
       "      <td>0.9707</td>\n",
       "      <td>1.2886</td>\n",
       "      <td>57.701</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>3.4573</td>\n",
       "      <td>54.1307</td>\n",
       "      <td>0.9030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.586800</td>\n",
       "      <td>0.585223</td>\n",
       "      <td>-0.0046</td>\n",
       "      <td>-0.0226</td>\n",
       "      <td>6.1348</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>73.4694</td>\n",
       "      <td>1.842</td>\n",
       "      <td>1.3646</td>\n",
       "      <td>52.8179</td>\n",
       "      <td>0.9256</td>\n",
       "      <td>6.4652</td>\n",
       "      <td>50.5116</td>\n",
       "      <td>0.8931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.592100</td>\n",
       "      <td>0.588083</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>4.8223</td>\n",
       "      <td>0.0777</td>\n",
       "      <td>84.8534</td>\n",
       "      <td>1.4857</td>\n",
       "      <td>0.6247</td>\n",
       "      <td>72.7678</td>\n",
       "      <td>1.1619</td>\n",
       "      <td>2.0517</td>\n",
       "      <td>58.0888</td>\n",
       "      <td>0.9860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.576300</td>\n",
       "      <td>0.578323</td>\n",
       "      <td>0.0328</td>\n",
       "      <td>0.3073</td>\n",
       "      <td>5.5532</td>\n",
       "      <td>0.2584</td>\n",
       "      <td>82.3299</td>\n",
       "      <td>1.2116</td>\n",
       "      <td>0.8557</td>\n",
       "      <td>66.578</td>\n",
       "      <td>1.134</td>\n",
       "      <td>2.6233</td>\n",
       "      <td>57.7897</td>\n",
       "      <td>1.0474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.579400</td>\n",
       "      <td>0.585874</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.3459</td>\n",
       "      <td>5.5252</td>\n",
       "      <td>1.0132</td>\n",
       "      <td>66.417</td>\n",
       "      <td>1.0412</td>\n",
       "      <td>1.3088</td>\n",
       "      <td>59.9111</td>\n",
       "      <td>0.9737</td>\n",
       "      <td>2.3320</td>\n",
       "      <td>51.5188</td>\n",
       "      <td>0.8607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.583800</td>\n",
       "      <td>0.577343</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>8.0124</td>\n",
       "      <td>2.0655</td>\n",
       "      <td>63.966</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>1.5414</td>\n",
       "      <td>54.0620</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>2.3683</td>\n",
       "      <td>51.3646</td>\n",
       "      <td>0.9915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.576900</td>\n",
       "      <td>0.584272</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>7.5515</td>\n",
       "      <td>3.4754</td>\n",
       "      <td>56.7753</td>\n",
       "      <td>1.0014</td>\n",
       "      <td>2.7018</td>\n",
       "      <td>50.5782</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>2.7107</td>\n",
       "      <td>47.0742</td>\n",
       "      <td>0.9392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.583400</td>\n",
       "      <td>0.577797</td>\n",
       "      <td>0.033</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>5.8502</td>\n",
       "      <td>1.7904</td>\n",
       "      <td>62.3145</td>\n",
       "      <td>1.0480</td>\n",
       "      <td>1.2310</td>\n",
       "      <td>54.8603</td>\n",
       "      <td>1.1940</td>\n",
       "      <td>1.5022</td>\n",
       "      <td>50.6399</td>\n",
       "      <td>0.9301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.578400</td>\n",
       "      <td>0.572716</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>7.7626</td>\n",
       "      <td>4.541</td>\n",
       "      <td>57.6757</td>\n",
       "      <td>1.0807</td>\n",
       "      <td>1.7181</td>\n",
       "      <td>50.1730</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>1.7346</td>\n",
       "      <td>48.5014</td>\n",
       "      <td>0.9147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.583500</td>\n",
       "      <td>0.573946</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.5074</td>\n",
       "      <td>6.6024</td>\n",
       "      <td>3.8326</td>\n",
       "      <td>58.7049</td>\n",
       "      <td>1.1966</td>\n",
       "      <td>1.4321</td>\n",
       "      <td>50.6448</td>\n",
       "      <td>0.9694</td>\n",
       "      <td>1.649</td>\n",
       "      <td>47.3151</td>\n",
       "      <td>0.8597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.576300</td>\n",
       "      <td>0.583274</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.3229</td>\n",
       "      <td>5.4544</td>\n",
       "      <td>2.8258</td>\n",
       "      <td>60.0806</td>\n",
       "      <td>1.0303</td>\n",
       "      <td>1.1871</td>\n",
       "      <td>51.9872</td>\n",
       "      <td>0.9432</td>\n",
       "      <td>1.2141</td>\n",
       "      <td>48.9685</td>\n",
       "      <td>0.9341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.582500</td>\n",
       "      <td>0.575649</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.4038</td>\n",
       "      <td>5.1418</td>\n",
       "      <td>3.0696</td>\n",
       "      <td>54.9553</td>\n",
       "      <td>1.1183</td>\n",
       "      <td>1.0901</td>\n",
       "      <td>50.1625</td>\n",
       "      <td>1.1310</td>\n",
       "      <td>1.0112</td>\n",
       "      <td>51.3635</td>\n",
       "      <td>0.9528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.578900</td>\n",
       "      <td>0.579840</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.4779</td>\n",
       "      <td>5.293</td>\n",
       "      <td>3.2650</td>\n",
       "      <td>61.0569</td>\n",
       "      <td>1.2102</td>\n",
       "      <td>1.0443</td>\n",
       "      <td>54.1667</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>1.0279</td>\n",
       "      <td>50.4922</td>\n",
       "      <td>0.9183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.578100</td>\n",
       "      <td>0.571899</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.3501</td>\n",
       "      <td>4.3238</td>\n",
       "      <td>2.191</td>\n",
       "      <td>63.3624</td>\n",
       "      <td>1.1012</td>\n",
       "      <td>0.6928</td>\n",
       "      <td>57.9332</td>\n",
       "      <td>0.9816</td>\n",
       "      <td>0.7706</td>\n",
       "      <td>51.1819</td>\n",
       "      <td>1.0418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.578800</td>\n",
       "      <td>0.575358</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.2351</td>\n",
       "      <td>6.5357</td>\n",
       "      <td>4.0013</td>\n",
       "      <td>58.5717</td>\n",
       "      <td>1.0149</td>\n",
       "      <td>1.0481</td>\n",
       "      <td>51.4603</td>\n",
       "      <td>0.9165</td>\n",
       "      <td>1.0996</td>\n",
       "      <td>49.3961</td>\n",
       "      <td>0.8671</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.575800</td>\n",
       "      <td>0.587246</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.3517</td>\n",
       "      <td>5.7497</td>\n",
       "      <td>4.0686</td>\n",
       "      <td>55.52</td>\n",
       "      <td>1.0671</td>\n",
       "      <td>0.8886</td>\n",
       "      <td>46.1068</td>\n",
       "      <td>0.9331</td>\n",
       "      <td>0.8634</td>\n",
       "      <td>46.5426</td>\n",
       "      <td>0.8914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.578000</td>\n",
       "      <td>0.572009</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.3289</td>\n",
       "      <td>6.1596</td>\n",
       "      <td>4.1192</td>\n",
       "      <td>60.8875</td>\n",
       "      <td>1.0538</td>\n",
       "      <td>1.0128</td>\n",
       "      <td>50.2186</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>0.963</td>\n",
       "      <td>48.9820</td>\n",
       "      <td>0.9515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.581800</td>\n",
       "      <td>0.577254</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.4409</td>\n",
       "      <td>5.9006</td>\n",
       "      <td>3.6243</td>\n",
       "      <td>57.8808</td>\n",
       "      <td>1.1689</td>\n",
       "      <td>1.0697</td>\n",
       "      <td>49.2373</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>45.8246</td>\n",
       "      <td>0.8777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.584600</td>\n",
       "      <td>0.574128</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.4731</td>\n",
       "      <td>5.1372</td>\n",
       "      <td>3.2407</td>\n",
       "      <td>59.8595</td>\n",
       "      <td>1.1908</td>\n",
       "      <td>0.8959</td>\n",
       "      <td>52.8448</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>0.9253</td>\n",
       "      <td>50.2392</td>\n",
       "      <td>0.8994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.577200</td>\n",
       "      <td>0.577047</td>\n",
       "      <td>0.043</td>\n",
       "      <td>0.4128</td>\n",
       "      <td>5.4842</td>\n",
       "      <td>3.5786</td>\n",
       "      <td>58.0008</td>\n",
       "      <td>1.0705</td>\n",
       "      <td>1.1766</td>\n",
       "      <td>48.4412</td>\n",
       "      <td>0.8461</td>\n",
       "      <td>1.1736</td>\n",
       "      <td>46.4432</td>\n",
       "      <td>0.8155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.579000</td>\n",
       "      <td>0.583005</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>6.5630</td>\n",
       "      <td>4.8101</td>\n",
       "      <td>60.081</td>\n",
       "      <td>1.0085</td>\n",
       "      <td>1.1432</td>\n",
       "      <td>53.087</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>1.0489</td>\n",
       "      <td>50.193</td>\n",
       "      <td>1.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.577800</td>\n",
       "      <td>0.568678</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.3934</td>\n",
       "      <td>6.7221</td>\n",
       "      <td>4.8192</td>\n",
       "      <td>60.4032</td>\n",
       "      <td>1.0385</td>\n",
       "      <td>1.0198</td>\n",
       "      <td>50.4217</td>\n",
       "      <td>0.8994</td>\n",
       "      <td>1.0366</td>\n",
       "      <td>48.1513</td>\n",
       "      <td>0.9243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.574900</td>\n",
       "      <td>0.578908</td>\n",
       "      <td>0.0553</td>\n",
       "      <td>0.4294</td>\n",
       "      <td>5.6150</td>\n",
       "      <td>4.3766</td>\n",
       "      <td>61.3353</td>\n",
       "      <td>1.0047</td>\n",
       "      <td>0.8854</td>\n",
       "      <td>49.5143</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>47.9151</td>\n",
       "      <td>0.8867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.577400</td>\n",
       "      <td>0.574869</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.2519</td>\n",
       "      <td>7.4727</td>\n",
       "      <td>5.8851</td>\n",
       "      <td>58.1988</td>\n",
       "      <td>0.9457</td>\n",
       "      <td>1.1603</td>\n",
       "      <td>47.8905</td>\n",
       "      <td>0.7823</td>\n",
       "      <td>0.9965</td>\n",
       "      <td>45.6334</td>\n",
       "      <td>0.8219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-5d7f8a85e0ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# \"LINEAR period scaled RL\" tanh trade loss with .1 multiloss auxilliary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# losses are penalized 1.5x, no trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1714\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m                 \u001b[1;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m         \u001b[1;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2227\u001b[1;33m         return self._getitem(\n\u001b[0m\u001b[0;32m   2228\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2229\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[1;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[0;32m   2210\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2212\u001b[1;33m         formatted_output = format_table(\n\u001b[0m\u001b[0;32m   2213\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2214\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"column\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mRowFormat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mColumnFormat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchFormat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"row\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"column\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mformat_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFormatter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mextract_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPythonArrowExtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseArrowExtractor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unnest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pydict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36m_unnest\u001b[1;34m(py_dict)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_unnest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_dict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[1;34m\"\"\"Return the first element of a batch (dict) as a row (dict)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpy_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub with consistent scaling\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# \"LINEAR period scaled RL\" tanh trade loss with .1 multiloss auxilliary\n",
    "# losses are penalized 1.5x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='28424' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [28424/43942 2:19:42 < 1:16:16, 3.39 it/s, Epoch 0.65/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.645998</td>\n",
       "      <td>-0.0581</td>\n",
       "      <td>-0.2661</td>\n",
       "      <td>13.0726</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>51.5734</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>2.7024</td>\n",
       "      <td>50.6834</td>\n",
       "      <td>0.7995</td>\n",
       "      <td>18.442</td>\n",
       "      <td>49.1149</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.667100</td>\n",
       "      <td>0.635797</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>7.1235</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>75.2101</td>\n",
       "      <td>1.8975</td>\n",
       "      <td>0.8268</td>\n",
       "      <td>60.6334</td>\n",
       "      <td>0.8898</td>\n",
       "      <td>3.9840</td>\n",
       "      <td>54.5911</td>\n",
       "      <td>0.9346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.660100</td>\n",
       "      <td>0.636418</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>6.9481</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>60.8602</td>\n",
       "      <td>1.0596</td>\n",
       "      <td>1.2561</td>\n",
       "      <td>60.1511</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>4.5450</td>\n",
       "      <td>51.585</td>\n",
       "      <td>0.9008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.657400</td>\n",
       "      <td>0.624942</td>\n",
       "      <td>0.0119</td>\n",
       "      <td>0.1216</td>\n",
       "      <td>4.6049</td>\n",
       "      <td>0.401</td>\n",
       "      <td>66.7823</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>1.0622</td>\n",
       "      <td>67.6908</td>\n",
       "      <td>0.9479</td>\n",
       "      <td>2.1697</td>\n",
       "      <td>55.9785</td>\n",
       "      <td>0.8211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.655500</td>\n",
       "      <td>0.628999</td>\n",
       "      <td>0.0427</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>5.2855</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>67.7197</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>0.9856</td>\n",
       "      <td>66.7094</td>\n",
       "      <td>1.1120</td>\n",
       "      <td>1.504</td>\n",
       "      <td>56.5265</td>\n",
       "      <td>1.0534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.650800</td>\n",
       "      <td>0.638701</td>\n",
       "      <td>0.0421</td>\n",
       "      <td>0.1691</td>\n",
       "      <td>9.0025</td>\n",
       "      <td>3.2122</td>\n",
       "      <td>63.5819</td>\n",
       "      <td>0.9322</td>\n",
       "      <td>1.7299</td>\n",
       "      <td>49.086</td>\n",
       "      <td>0.7695</td>\n",
       "      <td>4.0832</td>\n",
       "      <td>47.531</td>\n",
       "      <td>0.7952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.650800</td>\n",
       "      <td>0.619173</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>0.079</td>\n",
       "      <td>5.3769</td>\n",
       "      <td>1.0566</td>\n",
       "      <td>69.4840</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>0.5543</td>\n",
       "      <td>64.3998</td>\n",
       "      <td>0.8812</td>\n",
       "      <td>0.6312</td>\n",
       "      <td>62.5050</td>\n",
       "      <td>0.9512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.650900</td>\n",
       "      <td>0.628534</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.261</td>\n",
       "      <td>6.0773</td>\n",
       "      <td>1.3039</td>\n",
       "      <td>64.4645</td>\n",
       "      <td>0.9332</td>\n",
       "      <td>0.76</td>\n",
       "      <td>62.8828</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>6.4385</td>\n",
       "      <td>49.7466</td>\n",
       "      <td>0.9159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.652600</td>\n",
       "      <td>0.627779</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.3907</td>\n",
       "      <td>4.0326</td>\n",
       "      <td>1.1020</td>\n",
       "      <td>68.0785</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>0.6249</td>\n",
       "      <td>68.6235</td>\n",
       "      <td>1.0751</td>\n",
       "      <td>1.0113</td>\n",
       "      <td>55.2470</td>\n",
       "      <td>0.8713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.651300</td>\n",
       "      <td>0.616478</td>\n",
       "      <td>0.0243</td>\n",
       "      <td>0.226</td>\n",
       "      <td>4.4876</td>\n",
       "      <td>1.8324</td>\n",
       "      <td>67.0717</td>\n",
       "      <td>0.9804</td>\n",
       "      <td>0.6275</td>\n",
       "      <td>61.4191</td>\n",
       "      <td>0.8277</td>\n",
       "      <td>0.7965</td>\n",
       "      <td>54.2163</td>\n",
       "      <td>0.8876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.650900</td>\n",
       "      <td>0.617866</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.3863</td>\n",
       "      <td>5.1521</td>\n",
       "      <td>2.0383</td>\n",
       "      <td>66.5819</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>1.6837</td>\n",
       "      <td>54.2409</td>\n",
       "      <td>0.9205</td>\n",
       "      <td>2.0377</td>\n",
       "      <td>47.309</td>\n",
       "      <td>0.8822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.649400</td>\n",
       "      <td>0.630174</td>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.2708</td>\n",
       "      <td>5.5323</td>\n",
       "      <td>2.8629</td>\n",
       "      <td>63.2395</td>\n",
       "      <td>0.9138</td>\n",
       "      <td>1.0619</td>\n",
       "      <td>54.9494</td>\n",
       "      <td>0.8908</td>\n",
       "      <td>1.2688</td>\n",
       "      <td>53.4643</td>\n",
       "      <td>0.9318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.649300</td>\n",
       "      <td>0.623339</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>4.3248</td>\n",
       "      <td>1.9832</td>\n",
       "      <td>65.0657</td>\n",
       "      <td>1.0023</td>\n",
       "      <td>1.2764</td>\n",
       "      <td>55.1085</td>\n",
       "      <td>0.9264</td>\n",
       "      <td>1.4501</td>\n",
       "      <td>50.9944</td>\n",
       "      <td>0.8435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.647200</td>\n",
       "      <td>0.627728</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.4369</td>\n",
       "      <td>4.6282</td>\n",
       "      <td>2.6083</td>\n",
       "      <td>64.2774</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>1.0315</td>\n",
       "      <td>54.4083</td>\n",
       "      <td>1.0851</td>\n",
       "      <td>1.0300</td>\n",
       "      <td>51.2096</td>\n",
       "      <td>1.0607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.648800</td>\n",
       "      <td>0.614959</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.3273</td>\n",
       "      <td>3.9278</td>\n",
       "      <td>1.9219</td>\n",
       "      <td>63.7949</td>\n",
       "      <td>0.9419</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>54.4909</td>\n",
       "      <td>1.0227</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>49.0276</td>\n",
       "      <td>0.9072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.649000</td>\n",
       "      <td>0.615692</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.3101</td>\n",
       "      <td>4.2336</td>\n",
       "      <td>1.7276</td>\n",
       "      <td>67.5868</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.6360</td>\n",
       "      <td>63.4049</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>0.7364</td>\n",
       "      <td>54.7063</td>\n",
       "      <td>1.1113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.650100</td>\n",
       "      <td>0.619878</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.3863</td>\n",
       "      <td>4.9103</td>\n",
       "      <td>2.6194</td>\n",
       "      <td>58.4943</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>1.4085</td>\n",
       "      <td>47.3282</td>\n",
       "      <td>0.8817</td>\n",
       "      <td>1.2864</td>\n",
       "      <td>46.0865</td>\n",
       "      <td>0.9316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.645900</td>\n",
       "      <td>0.620394</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.4179</td>\n",
       "      <td>6.3941</td>\n",
       "      <td>4.1010</td>\n",
       "      <td>59.6866</td>\n",
       "      <td>1.0571</td>\n",
       "      <td>1.3317</td>\n",
       "      <td>48.5087</td>\n",
       "      <td>0.9571</td>\n",
       "      <td>1.3981</td>\n",
       "      <td>46.7113</td>\n",
       "      <td>0.9645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.646400</td>\n",
       "      <td>0.614236</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.3272</td>\n",
       "      <td>7.0471</td>\n",
       "      <td>4.7136</td>\n",
       "      <td>59.1858</td>\n",
       "      <td>1.0247</td>\n",
       "      <td>1.3392</td>\n",
       "      <td>45.3953</td>\n",
       "      <td>0.9307</td>\n",
       "      <td>1.1484</td>\n",
       "      <td>45.7099</td>\n",
       "      <td>0.9001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.645900</td>\n",
       "      <td>0.623530</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.3804</td>\n",
       "      <td>5.7352</td>\n",
       "      <td>3.6654</td>\n",
       "      <td>57.242</td>\n",
       "      <td>1.0385</td>\n",
       "      <td>1.2721</td>\n",
       "      <td>45.8785</td>\n",
       "      <td>0.9753</td>\n",
       "      <td>1.1155</td>\n",
       "      <td>46.0823</td>\n",
       "      <td>0.898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.645800</td>\n",
       "      <td>0.632378</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.4605</td>\n",
       "      <td>5.5886</td>\n",
       "      <td>3.4646</td>\n",
       "      <td>58.2183</td>\n",
       "      <td>1.023</td>\n",
       "      <td>1.4061</td>\n",
       "      <td>46.4556</td>\n",
       "      <td>1.0347</td>\n",
       "      <td>1.2618</td>\n",
       "      <td>48.4311</td>\n",
       "      <td>1.0179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.647600</td>\n",
       "      <td>0.625541</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.4124</td>\n",
       "      <td>5.8979</td>\n",
       "      <td>3.9459</td>\n",
       "      <td>60.2853</td>\n",
       "      <td>1.0279</td>\n",
       "      <td>1.4478</td>\n",
       "      <td>48.5235</td>\n",
       "      <td>1.0429</td>\n",
       "      <td>1.2694</td>\n",
       "      <td>44.8530</td>\n",
       "      <td>0.8934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.645600</td>\n",
       "      <td>0.608471</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.4143</td>\n",
       "      <td>6.1487</td>\n",
       "      <td>4.2608</td>\n",
       "      <td>59.1765</td>\n",
       "      <td>1.0535</td>\n",
       "      <td>1.1831</td>\n",
       "      <td>48.7330</td>\n",
       "      <td>0.8608</td>\n",
       "      <td>1.2131</td>\n",
       "      <td>46.7362</td>\n",
       "      <td>0.9127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.645300</td>\n",
       "      <td>0.623560</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.5008</td>\n",
       "      <td>4.7947</td>\n",
       "      <td>3.1708</td>\n",
       "      <td>62.2651</td>\n",
       "      <td>1.0281</td>\n",
       "      <td>1.0226</td>\n",
       "      <td>50.3464</td>\n",
       "      <td>0.9051</td>\n",
       "      <td>1.0490</td>\n",
       "      <td>46.5332</td>\n",
       "      <td>0.9357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.645500</td>\n",
       "      <td>0.610448</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.3372</td>\n",
       "      <td>8.2187</td>\n",
       "      <td>6.5180</td>\n",
       "      <td>57.9615</td>\n",
       "      <td>0.9764</td>\n",
       "      <td>1.4213</td>\n",
       "      <td>45.5856</td>\n",
       "      <td>0.8429</td>\n",
       "      <td>1.2374</td>\n",
       "      <td>44.7761</td>\n",
       "      <td>0.8933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.646400</td>\n",
       "      <td>0.631941</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.3452</td>\n",
       "      <td>6.4322</td>\n",
       "      <td>4.9667</td>\n",
       "      <td>59.6384</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>1.2043</td>\n",
       "      <td>47.0644</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>1.1542</td>\n",
       "      <td>45.8849</td>\n",
       "      <td>0.891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.644300</td>\n",
       "      <td>0.618796</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.4468</td>\n",
       "      <td>6.5938</td>\n",
       "      <td>4.9423</td>\n",
       "      <td>57.6909</td>\n",
       "      <td>1.0484</td>\n",
       "      <td>1.6239</td>\n",
       "      <td>46.9855</td>\n",
       "      <td>0.8953</td>\n",
       "      <td>1.3661</td>\n",
       "      <td>46.3333</td>\n",
       "      <td>0.9410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.648300</td>\n",
       "      <td>0.613535</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.3452</td>\n",
       "      <td>7.8467</td>\n",
       "      <td>6.1512</td>\n",
       "      <td>57.6508</td>\n",
       "      <td>0.9715</td>\n",
       "      <td>1.5939</td>\n",
       "      <td>45.671</td>\n",
       "      <td>0.9355</td>\n",
       "      <td>1.2967</td>\n",
       "      <td>43.069</td>\n",
       "      <td>0.9219</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4eeec2ccdc7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ONLY \"LINEAR period scaled RL\" tanh trade loss with .1 multiloss auxilliary\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# losses are penalized 1.5x, no trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1738\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_grad_scaling\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2480\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2481\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_apex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2482\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# \"LINEAR period scaled RL\" tanh trade loss with .1 multiloss auxilliary\n",
    "# losses are penalized 1.5x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19111' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19111/43942 1:33:12 < 2:01:07, 3.42 it/s, Epoch 0.43/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.407900</td>\n",
       "      <td>0.371141</td>\n",
       "      <td>-0.0449</td>\n",
       "      <td>-0.1973</td>\n",
       "      <td>13.7809</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>58.8785</td>\n",
       "      <td>1.0209</td>\n",
       "      <td>3.1101</td>\n",
       "      <td>51.6452</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>20.6007</td>\n",
       "      <td>49.3685</td>\n",
       "      <td>0.8931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.392800</td>\n",
       "      <td>0.370509</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>8.2638</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>70.6818</td>\n",
       "      <td>1.1735</td>\n",
       "      <td>1.2510</td>\n",
       "      <td>58.4024</td>\n",
       "      <td>0.8808</td>\n",
       "      <td>6.3822</td>\n",
       "      <td>52.5399</td>\n",
       "      <td>0.8401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.387800</td>\n",
       "      <td>0.364069</td>\n",
       "      <td>0.018</td>\n",
       "      <td>0.0624</td>\n",
       "      <td>8.6650</td>\n",
       "      <td>0.5518</td>\n",
       "      <td>64.9243</td>\n",
       "      <td>1.0536</td>\n",
       "      <td>1.8927</td>\n",
       "      <td>59.9479</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>9.1283</td>\n",
       "      <td>50.6367</td>\n",
       "      <td>0.9310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>0.358456</td>\n",
       "      <td>0.0135</td>\n",
       "      <td>0.1124</td>\n",
       "      <td>4.6841</td>\n",
       "      <td>0.4613</td>\n",
       "      <td>66.6575</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>1.3011</td>\n",
       "      <td>65.2537</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>1.9427</td>\n",
       "      <td>57.2991</td>\n",
       "      <td>0.8935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.381100</td>\n",
       "      <td>0.361533</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.3208</td>\n",
       "      <td>4.9012</td>\n",
       "      <td>0.9071</td>\n",
       "      <td>67.5080</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.9182</td>\n",
       "      <td>63.0803</td>\n",
       "      <td>1.0813</td>\n",
       "      <td>0.8803</td>\n",
       "      <td>58.8590</td>\n",
       "      <td>1.0308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>0.363481</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.2047</td>\n",
       "      <td>7.6277</td>\n",
       "      <td>3.5369</td>\n",
       "      <td>62.1473</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>1.4643</td>\n",
       "      <td>49.2225</td>\n",
       "      <td>0.7336</td>\n",
       "      <td>1.9735</td>\n",
       "      <td>50.4935</td>\n",
       "      <td>0.9198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.378200</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>5.2050</td>\n",
       "      <td>2.0343</td>\n",
       "      <td>66.8822</td>\n",
       "      <td>1.1055</td>\n",
       "      <td>0.6459</td>\n",
       "      <td>59.3811</td>\n",
       "      <td>0.9177</td>\n",
       "      <td>0.6962</td>\n",
       "      <td>52.2529</td>\n",
       "      <td>0.9267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.377700</td>\n",
       "      <td>0.352000</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.3224</td>\n",
       "      <td>5.097</td>\n",
       "      <td>2.4726</td>\n",
       "      <td>65.386</td>\n",
       "      <td>1.0598</td>\n",
       "      <td>0.8055</td>\n",
       "      <td>56.2186</td>\n",
       "      <td>0.8556</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>49.1495</td>\n",
       "      <td>0.8245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.378900</td>\n",
       "      <td>0.351881</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.4331</td>\n",
       "      <td>2.9501</td>\n",
       "      <td>0.9182</td>\n",
       "      <td>71.4975</td>\n",
       "      <td>1.0302</td>\n",
       "      <td>0.4421</td>\n",
       "      <td>62.8040</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.3905</td>\n",
       "      <td>61.6456</td>\n",
       "      <td>0.9789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.377800</td>\n",
       "      <td>0.346995</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.2152</td>\n",
       "      <td>3.9546</td>\n",
       "      <td>1.3466</td>\n",
       "      <td>69.4251</td>\n",
       "      <td>1.0384</td>\n",
       "      <td>0.4525</td>\n",
       "      <td>65.8093</td>\n",
       "      <td>0.9198</td>\n",
       "      <td>0.4765</td>\n",
       "      <td>64.9589</td>\n",
       "      <td>1.1094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.378000</td>\n",
       "      <td>0.346344</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.4068</td>\n",
       "      <td>2.6784</td>\n",
       "      <td>1.3054</td>\n",
       "      <td>70.126</td>\n",
       "      <td>1.0395</td>\n",
       "      <td>0.4235</td>\n",
       "      <td>64.3070</td>\n",
       "      <td>1.1274</td>\n",
       "      <td>0.4112</td>\n",
       "      <td>62.3193</td>\n",
       "      <td>1.1679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.376700</td>\n",
       "      <td>0.360375</td>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.4340</td>\n",
       "      <td>3.937</td>\n",
       "      <td>2.6204</td>\n",
       "      <td>67.0255</td>\n",
       "      <td>1.0372</td>\n",
       "      <td>0.5373</td>\n",
       "      <td>57.5565</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.3742</td>\n",
       "      <td>55.6119</td>\n",
       "      <td>0.9514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.377800</td>\n",
       "      <td>0.347207</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.3612</td>\n",
       "      <td>2.8616</td>\n",
       "      <td>1.7820</td>\n",
       "      <td>66.6596</td>\n",
       "      <td>1.0261</td>\n",
       "      <td>0.4647</td>\n",
       "      <td>62.7654</td>\n",
       "      <td>1.1677</td>\n",
       "      <td>0.3699</td>\n",
       "      <td>59.0629</td>\n",
       "      <td>1.0736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.375500</td>\n",
       "      <td>0.359203</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.3716</td>\n",
       "      <td>2.6088</td>\n",
       "      <td>1.7410</td>\n",
       "      <td>66.2961</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>0.4159</td>\n",
       "      <td>58.455</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>0.3821</td>\n",
       "      <td>58.8216</td>\n",
       "      <td>1.0975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.377100</td>\n",
       "      <td>0.351304</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.3550</td>\n",
       "      <td>2.6949</td>\n",
       "      <td>1.6172</td>\n",
       "      <td>67.3211</td>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.3881</td>\n",
       "      <td>63.0378</td>\n",
       "      <td>1.0345</td>\n",
       "      <td>0.3451</td>\n",
       "      <td>60.4472</td>\n",
       "      <td>1.2785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.377300</td>\n",
       "      <td>0.343939</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.3678</td>\n",
       "      <td>3.6303</td>\n",
       "      <td>2.3552</td>\n",
       "      <td>67.8393</td>\n",
       "      <td>1.0699</td>\n",
       "      <td>0.3694</td>\n",
       "      <td>60.8904</td>\n",
       "      <td>1.0301</td>\n",
       "      <td>0.2882</td>\n",
       "      <td>56.9359</td>\n",
       "      <td>0.9928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>0.354724</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.4745</td>\n",
       "      <td>1.9483</td>\n",
       "      <td>1.2099</td>\n",
       "      <td>71.0193</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>59.1996</td>\n",
       "      <td>0.8508</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>61.6735</td>\n",
       "      <td>1.0734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.374700</td>\n",
       "      <td>0.361815</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>3.1940</td>\n",
       "      <td>2.4118</td>\n",
       "      <td>65.7681</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>0.4268</td>\n",
       "      <td>57.0243</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>0.4144</td>\n",
       "      <td>52.8694</td>\n",
       "      <td>1.1365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>0.349928</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.6870</td>\n",
       "      <td>1.5517</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>75.2981</td>\n",
       "      <td>1.0014</td>\n",
       "      <td>0.2109</td>\n",
       "      <td>58.5483</td>\n",
       "      <td>1.3562</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>55.9274</td>\n",
       "      <td>1.5548</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-30cf2e26c1b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ONLY \"LINEAR period scaled RL\" tanh trade loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# losses are penalized 1.5x, no trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1714\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m                 \u001b[1;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    720\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 721\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    722\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    723\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2225\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# noqa: F811\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2226\u001b[0m         \u001b[1;34m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2227\u001b[1;33m         return self._getitem(\n\u001b[0m\u001b[0;32m   2228\u001b[0m             \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2229\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\arrow_dataset.py\u001b[0m in \u001b[0;36m_getitem\u001b[1;34m(self, key, decoded, **kwargs)\u001b[0m\n\u001b[0;32m   2210\u001b[0m         \u001b[0mformatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_formatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoded\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mformat_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m         \u001b[0mpa_subtable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mquery_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_indices\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2212\u001b[1;33m         formatted_output = format_table(\n\u001b[0m\u001b[0;32m   2213\u001b[0m             \u001b[0mpa_subtable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformatter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mformat_columns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_all_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_all_columns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2214\u001b[0m         )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mformat_table\u001b[1;34m(table, key, formatter, format_columns, output_all_columns)\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[0mpython_formatter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mformat_columns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 532\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mformatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mquery_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    533\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"column\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    534\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mformat_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, pa_table, query_type)\u001b[0m\n\u001b[0;32m    279\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mquery_type\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mRowFormat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mColumnFormat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mBatchFormat\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    280\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"row\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 281\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    282\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mquery_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"column\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mformat_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    308\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPythonFormatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFormatter\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mformat_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 310\u001b[1;33m         \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython_arrow_extractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextract_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    311\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoded\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    312\u001b[0m             \u001b[0mrow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython_features_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36mextract_row\u001b[1;34m(self, pa_table)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mPythonArrowExtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseArrowExtractor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_row\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_unnest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpa_table\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pydict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextract_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpa_table\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpa\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTable\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\datasets\\formatting\\formatting.py\u001b[0m in \u001b[0;36m_unnest\u001b[1;34m(py_dict)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0m_unnest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_dict\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mDict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m     \u001b[1;34m\"\"\"Return the first element of a batch (dict) as a row (dict)\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpy_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# ONLY \"LINEAR period scaled RL\" tanh trade loss\n",
    "# losses are penalized 1.5x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43942' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43942/43942 3:34:31, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.269000</td>\n",
       "      <td>0.245315</td>\n",
       "      <td>-0.0607</td>\n",
       "      <td>-0.2823</td>\n",
       "      <td>13.3514</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>70.9832</td>\n",
       "      <td>1.0364</td>\n",
       "      <td>2.2790</td>\n",
       "      <td>52.1729</td>\n",
       "      <td>0.7963</td>\n",
       "      <td>20.5725</td>\n",
       "      <td>48.7912</td>\n",
       "      <td>0.873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.259200</td>\n",
       "      <td>0.243479</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>8.5583</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>65.3445</td>\n",
       "      <td>1.1013</td>\n",
       "      <td>1.2802</td>\n",
       "      <td>62.2468</td>\n",
       "      <td>0.9179</td>\n",
       "      <td>6.2572</td>\n",
       "      <td>52.3682</td>\n",
       "      <td>0.8856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.256000</td>\n",
       "      <td>0.241667</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.2636</td>\n",
       "      <td>7.0222</td>\n",
       "      <td>0.3923</td>\n",
       "      <td>70.7836</td>\n",
       "      <td>1.1926</td>\n",
       "      <td>1.1346</td>\n",
       "      <td>64.1249</td>\n",
       "      <td>0.8622</td>\n",
       "      <td>2.5827</td>\n",
       "      <td>55.7400</td>\n",
       "      <td>0.8756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.254600</td>\n",
       "      <td>0.237310</td>\n",
       "      <td>-0.0021</td>\n",
       "      <td>-0.0153</td>\n",
       "      <td>5.2624</td>\n",
       "      <td>0.305</td>\n",
       "      <td>74.3260</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>0.9005</td>\n",
       "      <td>66.3998</td>\n",
       "      <td>0.9673</td>\n",
       "      <td>2.0331</td>\n",
       "      <td>57.7490</td>\n",
       "      <td>0.7755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.252300</td>\n",
       "      <td>0.236708</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.2645</td>\n",
       "      <td>4.045</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>66.0979</td>\n",
       "      <td>0.9023</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>62.5954</td>\n",
       "      <td>1.0648</td>\n",
       "      <td>0.8481</td>\n",
       "      <td>58.6428</td>\n",
       "      <td>1.0316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.249700</td>\n",
       "      <td>0.239237</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.2222</td>\n",
       "      <td>6.4796</td>\n",
       "      <td>3.8326</td>\n",
       "      <td>60.7974</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>1.0749</td>\n",
       "      <td>51.8004</td>\n",
       "      <td>0.8015</td>\n",
       "      <td>1.0078</td>\n",
       "      <td>50.5335</td>\n",
       "      <td>0.8238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.230465</td>\n",
       "      <td>0.0254</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>3.5852</td>\n",
       "      <td>1.6345</td>\n",
       "      <td>69.2695</td>\n",
       "      <td>1.0022</td>\n",
       "      <td>0.5819</td>\n",
       "      <td>61.0217</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>0.5325</td>\n",
       "      <td>57.5534</td>\n",
       "      <td>0.8715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.249400</td>\n",
       "      <td>0.232140</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>4.8578</td>\n",
       "      <td>2.7857</td>\n",
       "      <td>64.7323</td>\n",
       "      <td>0.9832</td>\n",
       "      <td>0.6908</td>\n",
       "      <td>55.6491</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>51.9442</td>\n",
       "      <td>0.7421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.250500</td>\n",
       "      <td>0.234565</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.366</td>\n",
       "      <td>3.7397</td>\n",
       "      <td>1.3837</td>\n",
       "      <td>69.2385</td>\n",
       "      <td>0.9393</td>\n",
       "      <td>0.4888</td>\n",
       "      <td>64.9327</td>\n",
       "      <td>1.0100</td>\n",
       "      <td>0.474</td>\n",
       "      <td>61.4091</td>\n",
       "      <td>0.943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.227367</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.3269</td>\n",
       "      <td>2.5913</td>\n",
       "      <td>0.9847</td>\n",
       "      <td>70.8671</td>\n",
       "      <td>0.9503</td>\n",
       "      <td>0.3715</td>\n",
       "      <td>67.6881</td>\n",
       "      <td>1.0716</td>\n",
       "      <td>0.3571</td>\n",
       "      <td>65.4977</td>\n",
       "      <td>1.0990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.250300</td>\n",
       "      <td>0.227483</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>2.8906</td>\n",
       "      <td>1.4762</td>\n",
       "      <td>69.2117</td>\n",
       "      <td>0.9798</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>66.2632</td>\n",
       "      <td>1.2169</td>\n",
       "      <td>0.4829</td>\n",
       "      <td>61.8387</td>\n",
       "      <td>1.0341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.249300</td>\n",
       "      <td>0.234350</td>\n",
       "      <td>0.0444</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>4.444</td>\n",
       "      <td>3.2912</td>\n",
       "      <td>65.4176</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.5943</td>\n",
       "      <td>54.4487</td>\n",
       "      <td>0.8169</td>\n",
       "      <td>0.4617</td>\n",
       "      <td>48.3014</td>\n",
       "      <td>0.8515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.231549</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.4084</td>\n",
       "      <td>3.2004</td>\n",
       "      <td>2.3597</td>\n",
       "      <td>67.6494</td>\n",
       "      <td>1.0644</td>\n",
       "      <td>0.5464</td>\n",
       "      <td>60.8333</td>\n",
       "      <td>0.8420</td>\n",
       "      <td>0.4318</td>\n",
       "      <td>53.8664</td>\n",
       "      <td>0.9581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.235351</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.3918</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.2150</td>\n",
       "      <td>67.8088</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.4060</td>\n",
       "      <td>61.4330</td>\n",
       "      <td>1.1038</td>\n",
       "      <td>0.3495</td>\n",
       "      <td>60.2606</td>\n",
       "      <td>1.0434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.249600</td>\n",
       "      <td>0.228729</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.4123</td>\n",
       "      <td>2.7673</td>\n",
       "      <td>1.8273</td>\n",
       "      <td>68.6141</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>0.3675</td>\n",
       "      <td>64.0275</td>\n",
       "      <td>1.0056</td>\n",
       "      <td>0.3013</td>\n",
       "      <td>62.6364</td>\n",
       "      <td>1.2259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.249700</td>\n",
       "      <td>0.227236</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.2888</td>\n",
       "      <td>4.8576</td>\n",
       "      <td>3.8408</td>\n",
       "      <td>62.9594</td>\n",
       "      <td>0.9409</td>\n",
       "      <td>0.5516</td>\n",
       "      <td>52.7173</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.3997</td>\n",
       "      <td>50.5696</td>\n",
       "      <td>0.9796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.250200</td>\n",
       "      <td>0.232192</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.3865</td>\n",
       "      <td>2.3258</td>\n",
       "      <td>1.5996</td>\n",
       "      <td>67.4601</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>0.2744</td>\n",
       "      <td>65.7446</td>\n",
       "      <td>0.8755</td>\n",
       "      <td>0.2362</td>\n",
       "      <td>61.0605</td>\n",
       "      <td>1.1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.248000</td>\n",
       "      <td>0.239278</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.3627</td>\n",
       "      <td>3.5841</td>\n",
       "      <td>2.6380</td>\n",
       "      <td>65.3896</td>\n",
       "      <td>0.9850</td>\n",
       "      <td>0.4826</td>\n",
       "      <td>58.3224</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>0.4367</td>\n",
       "      <td>51.7961</td>\n",
       "      <td>1.1371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.248300</td>\n",
       "      <td>0.226734</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.3638</td>\n",
       "      <td>3.7832</td>\n",
       "      <td>3.0051</td>\n",
       "      <td>65.6354</td>\n",
       "      <td>1.006</td>\n",
       "      <td>0.4626</td>\n",
       "      <td>59.0101</td>\n",
       "      <td>0.7791</td>\n",
       "      <td>0.4139</td>\n",
       "      <td>54.2176</td>\n",
       "      <td>0.8871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.248400</td>\n",
       "      <td>0.228814</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.3594</td>\n",
       "      <td>2.5219</td>\n",
       "      <td>1.7961</td>\n",
       "      <td>66.8639</td>\n",
       "      <td>0.9628</td>\n",
       "      <td>0.3751</td>\n",
       "      <td>62.9005</td>\n",
       "      <td>0.9623</td>\n",
       "      <td>0.317</td>\n",
       "      <td>58.8587</td>\n",
       "      <td>1.1179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.248700</td>\n",
       "      <td>0.237683</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.4496</td>\n",
       "      <td>2.6607</td>\n",
       "      <td>1.8185</td>\n",
       "      <td>68.2944</td>\n",
       "      <td>0.9933</td>\n",
       "      <td>0.3504</td>\n",
       "      <td>63.2852</td>\n",
       "      <td>1.2096</td>\n",
       "      <td>0.2856</td>\n",
       "      <td>61.3818</td>\n",
       "      <td>1.1469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.232799</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.3936</td>\n",
       "      <td>3.7626</td>\n",
       "      <td>3.144</td>\n",
       "      <td>65.9827</td>\n",
       "      <td>0.9929</td>\n",
       "      <td>0.4536</td>\n",
       "      <td>54.7685</td>\n",
       "      <td>0.8744</td>\n",
       "      <td>0.3924</td>\n",
       "      <td>50.1612</td>\n",
       "      <td>0.7847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.248100</td>\n",
       "      <td>0.225106</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>3.2839</td>\n",
       "      <td>2.5242</td>\n",
       "      <td>65.8381</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.3759</td>\n",
       "      <td>58.5128</td>\n",
       "      <td>1.0007</td>\n",
       "      <td>0.3114</td>\n",
       "      <td>57.5142</td>\n",
       "      <td>1.0331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.234776</td>\n",
       "      <td>0.0467</td>\n",
       "      <td>0.4436</td>\n",
       "      <td>3.3102</td>\n",
       "      <td>2.7577</td>\n",
       "      <td>67.4143</td>\n",
       "      <td>0.9799</td>\n",
       "      <td>0.389</td>\n",
       "      <td>56.2602</td>\n",
       "      <td>1.0496</td>\n",
       "      <td>0.3162</td>\n",
       "      <td>51.8000</td>\n",
       "      <td>0.8488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.225975</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.1905</td>\n",
       "      <td>5.0109</td>\n",
       "      <td>4.0819</td>\n",
       "      <td>60.9297</td>\n",
       "      <td>0.9106</td>\n",
       "      <td>0.4967</td>\n",
       "      <td>53.2977</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>53.7295</td>\n",
       "      <td>0.7604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.249200</td>\n",
       "      <td>0.240042</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.1807</td>\n",
       "      <td>4.9121</td>\n",
       "      <td>4.2686</td>\n",
       "      <td>60.3686</td>\n",
       "      <td>0.8873</td>\n",
       "      <td>0.6001</td>\n",
       "      <td>49.5152</td>\n",
       "      <td>0.8180</td>\n",
       "      <td>0.496</td>\n",
       "      <td>48.3295</td>\n",
       "      <td>0.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.248300</td>\n",
       "      <td>0.231516</td>\n",
       "      <td>0.047</td>\n",
       "      <td>0.4675</td>\n",
       "      <td>3.017</td>\n",
       "      <td>2.4094</td>\n",
       "      <td>68.5269</td>\n",
       "      <td>0.9914</td>\n",
       "      <td>0.4995</td>\n",
       "      <td>59.3821</td>\n",
       "      <td>1.0433</td>\n",
       "      <td>0.4427</td>\n",
       "      <td>53.9714</td>\n",
       "      <td>1.1159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.250300</td>\n",
       "      <td>0.229807</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.4726</td>\n",
       "      <td>3.4690</td>\n",
       "      <td>2.9332</td>\n",
       "      <td>67.0232</td>\n",
       "      <td>1.0380</td>\n",
       "      <td>0.4793</td>\n",
       "      <td>57.7197</td>\n",
       "      <td>1.0033</td>\n",
       "      <td>0.3881</td>\n",
       "      <td>55.1825</td>\n",
       "      <td>1.1297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.249700</td>\n",
       "      <td>0.232389</td>\n",
       "      <td>0.052</td>\n",
       "      <td>0.4703</td>\n",
       "      <td>3.2781</td>\n",
       "      <td>2.9278</td>\n",
       "      <td>68.0031</td>\n",
       "      <td>1.0298</td>\n",
       "      <td>0.3647</td>\n",
       "      <td>56.2955</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.2856</td>\n",
       "      <td>48.9814</td>\n",
       "      <td>0.9463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.249700</td>\n",
       "      <td>0.228880</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>0.4653</td>\n",
       "      <td>3.3372</td>\n",
       "      <td>2.8527</td>\n",
       "      <td>67.7856</td>\n",
       "      <td>1.0450</td>\n",
       "      <td>0.4138</td>\n",
       "      <td>58.3614</td>\n",
       "      <td>1.0630</td>\n",
       "      <td>0.3466</td>\n",
       "      <td>54.0876</td>\n",
       "      <td>1.1184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.249200</td>\n",
       "      <td>0.232955</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>5.4441</td>\n",
       "      <td>4.5403</td>\n",
       "      <td>60.4196</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>46.5431</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.8074</td>\n",
       "      <td>44.8222</td>\n",
       "      <td>0.9631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.249800</td>\n",
       "      <td>0.233520</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.3941</td>\n",
       "      <td>3.3187</td>\n",
       "      <td>2.8061</td>\n",
       "      <td>67.3143</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>0.495</td>\n",
       "      <td>55.3539</td>\n",
       "      <td>1.0066</td>\n",
       "      <td>0.4994</td>\n",
       "      <td>52.0263</td>\n",
       "      <td>0.9647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.250700</td>\n",
       "      <td>0.227332</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.3204</td>\n",
       "      <td>4.1701</td>\n",
       "      <td>3.3863</td>\n",
       "      <td>64.1142</td>\n",
       "      <td>0.9618</td>\n",
       "      <td>0.6848</td>\n",
       "      <td>49.8892</td>\n",
       "      <td>0.9298</td>\n",
       "      <td>0.6498</td>\n",
       "      <td>48.6081</td>\n",
       "      <td>0.9067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.249000</td>\n",
       "      <td>0.240278</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.4437</td>\n",
       "      <td>3.4064</td>\n",
       "      <td>2.7303</td>\n",
       "      <td>65.6011</td>\n",
       "      <td>1.0037</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>55.4966</td>\n",
       "      <td>1.1466</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>50.0241</td>\n",
       "      <td>1.0745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.249300</td>\n",
       "      <td>0.230948</td>\n",
       "      <td>0.0537</td>\n",
       "      <td>0.4365</td>\n",
       "      <td>3.6371</td>\n",
       "      <td>3.1161</td>\n",
       "      <td>65.9306</td>\n",
       "      <td>1.0266</td>\n",
       "      <td>0.5845</td>\n",
       "      <td>51.2443</td>\n",
       "      <td>1.0049</td>\n",
       "      <td>0.5055</td>\n",
       "      <td>48.8739</td>\n",
       "      <td>0.9336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.234985</td>\n",
       "      <td>0.0531</td>\n",
       "      <td>0.4099</td>\n",
       "      <td>3.8542</td>\n",
       "      <td>3.2969</td>\n",
       "      <td>64.7828</td>\n",
       "      <td>1.0162</td>\n",
       "      <td>0.6517</td>\n",
       "      <td>48.9130</td>\n",
       "      <td>0.9365</td>\n",
       "      <td>0.5387</td>\n",
       "      <td>47.8751</td>\n",
       "      <td>0.8596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.249700</td>\n",
       "      <td>0.230929</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.3816</td>\n",
       "      <td>4.2068</td>\n",
       "      <td>3.601</td>\n",
       "      <td>62.8109</td>\n",
       "      <td>1.02</td>\n",
       "      <td>0.7127</td>\n",
       "      <td>49.1835</td>\n",
       "      <td>0.9131</td>\n",
       "      <td>0.6096</td>\n",
       "      <td>46.5034</td>\n",
       "      <td>0.8769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.249100</td>\n",
       "      <td>0.236351</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.4363</td>\n",
       "      <td>3.82</td>\n",
       "      <td>3.2665</td>\n",
       "      <td>63.9483</td>\n",
       "      <td>1.0433</td>\n",
       "      <td>0.6585</td>\n",
       "      <td>51.8440</td>\n",
       "      <td>0.9442</td>\n",
       "      <td>0.5342</td>\n",
       "      <td>48.0464</td>\n",
       "      <td>0.8811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.249300</td>\n",
       "      <td>0.237518</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.4052</td>\n",
       "      <td>3.9294</td>\n",
       "      <td>3.4107</td>\n",
       "      <td>63.722</td>\n",
       "      <td>1.0247</td>\n",
       "      <td>0.6365</td>\n",
       "      <td>51.1725</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>0.4932</td>\n",
       "      <td>47.5250</td>\n",
       "      <td>0.9216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.250300</td>\n",
       "      <td>0.237121</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.4065</td>\n",
       "      <td>4.1558</td>\n",
       "      <td>3.5709</td>\n",
       "      <td>62.6497</td>\n",
       "      <td>1.0337</td>\n",
       "      <td>0.6799</td>\n",
       "      <td>50.214</td>\n",
       "      <td>0.8574</td>\n",
       "      <td>0.5571</td>\n",
       "      <td>47.7066</td>\n",
       "      <td>0.8733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.248500</td>\n",
       "      <td>0.235705</td>\n",
       "      <td>0.0526</td>\n",
       "      <td>0.4359</td>\n",
       "      <td>3.8886</td>\n",
       "      <td>3.3591</td>\n",
       "      <td>63.5337</td>\n",
       "      <td>1.0471</td>\n",
       "      <td>0.6497</td>\n",
       "      <td>51.4213</td>\n",
       "      <td>0.9054</td>\n",
       "      <td>0.5258</td>\n",
       "      <td>49.0017</td>\n",
       "      <td>0.8954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.234711</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.4355</td>\n",
       "      <td>3.9063</td>\n",
       "      <td>3.3714</td>\n",
       "      <td>63.385</td>\n",
       "      <td>1.0468</td>\n",
       "      <td>0.6593</td>\n",
       "      <td>50.4797</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.5324</td>\n",
       "      <td>49.4892</td>\n",
       "      <td>0.9169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.250800</td>\n",
       "      <td>0.235217</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.4349</td>\n",
       "      <td>3.9165</td>\n",
       "      <td>3.3843</td>\n",
       "      <td>63.3227</td>\n",
       "      <td>1.0463</td>\n",
       "      <td>0.6566</td>\n",
       "      <td>50.5490</td>\n",
       "      <td>0.8899</td>\n",
       "      <td>0.5338</td>\n",
       "      <td>49.4313</td>\n",
       "      <td>0.8996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=43942, training_loss=0.2504192406292048, metrics={'train_runtime': 12876.9061, 'train_samples_per_second': 6.825, 'train_steps_per_second': 3.412, 'total_flos': 0.0, 'train_loss': 0.2504192406292048, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# ONLY \"LINEAR period log scaled + 1 RL\" tanh trade loss\n",
    "# losses are penalized 1.5x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='20557' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [20557/43942 1:40:59 < 1:54:53, 3.39 it/s, Epoch 0.47/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.384400</td>\n",
       "      <td>0.353942</td>\n",
       "      <td>-0.0401</td>\n",
       "      <td>-0.2002</td>\n",
       "      <td>12.4448</td>\n",
       "      <td>0.007</td>\n",
       "      <td>69.0909</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>1.5924</td>\n",
       "      <td>53.3640</td>\n",
       "      <td>0.8499</td>\n",
       "      <td>18.2587</td>\n",
       "      <td>49.0980</td>\n",
       "      <td>0.8873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.378200</td>\n",
       "      <td>0.357401</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>0.1541</td>\n",
       "      <td>8.1968</td>\n",
       "      <td>0.4168</td>\n",
       "      <td>62.9439</td>\n",
       "      <td>1.0285</td>\n",
       "      <td>1.5151</td>\n",
       "      <td>60.5694</td>\n",
       "      <td>0.9399</td>\n",
       "      <td>3.9834</td>\n",
       "      <td>52.0942</td>\n",
       "      <td>0.9254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.377400</td>\n",
       "      <td>0.358263</td>\n",
       "      <td>0.0677</td>\n",
       "      <td>0.3431</td>\n",
       "      <td>9.8173</td>\n",
       "      <td>1.8293</td>\n",
       "      <td>64.1059</td>\n",
       "      <td>0.9404</td>\n",
       "      <td>1.8094</td>\n",
       "      <td>53.5584</td>\n",
       "      <td>0.8363</td>\n",
       "      <td>6.0504</td>\n",
       "      <td>51.8920</td>\n",
       "      <td>1.1763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.350831</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0045</td>\n",
       "      <td>9.9156</td>\n",
       "      <td>1.8445</td>\n",
       "      <td>65.4506</td>\n",
       "      <td>1.0105</td>\n",
       "      <td>2.3324</td>\n",
       "      <td>50.7457</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>7.9827</td>\n",
       "      <td>48.7149</td>\n",
       "      <td>0.9692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>0.359779</td>\n",
       "      <td>0.0505</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>6.6970</td>\n",
       "      <td>2.7534</td>\n",
       "      <td>65.8198</td>\n",
       "      <td>1.0443</td>\n",
       "      <td>0.7851</td>\n",
       "      <td>55.1796</td>\n",
       "      <td>0.8054</td>\n",
       "      <td>0.8008</td>\n",
       "      <td>51.8086</td>\n",
       "      <td>0.9715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.374200</td>\n",
       "      <td>0.354781</td>\n",
       "      <td>0.0438</td>\n",
       "      <td>0.2374</td>\n",
       "      <td>6.788</td>\n",
       "      <td>3.4569</td>\n",
       "      <td>62.2599</td>\n",
       "      <td>0.9814</td>\n",
       "      <td>1.1078</td>\n",
       "      <td>46.7687</td>\n",
       "      <td>0.8495</td>\n",
       "      <td>1.4143</td>\n",
       "      <td>46.4985</td>\n",
       "      <td>0.8659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.351745</td>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.3819</td>\n",
       "      <td>5.0868</td>\n",
       "      <td>2.5559</td>\n",
       "      <td>66.6287</td>\n",
       "      <td>1.0474</td>\n",
       "      <td>0.5338</td>\n",
       "      <td>57.6540</td>\n",
       "      <td>0.8039</td>\n",
       "      <td>0.644</td>\n",
       "      <td>52.1312</td>\n",
       "      <td>0.8964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.360225</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>6.6955</td>\n",
       "      <td>3.8913</td>\n",
       "      <td>61.3887</td>\n",
       "      <td>0.9476</td>\n",
       "      <td>0.7942</td>\n",
       "      <td>48.9568</td>\n",
       "      <td>0.8087</td>\n",
       "      <td>0.759</td>\n",
       "      <td>47.7</td>\n",
       "      <td>0.7865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.376500</td>\n",
       "      <td>0.353983</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.3864</td>\n",
       "      <td>4.6863</td>\n",
       "      <td>1.6426</td>\n",
       "      <td>68.2581</td>\n",
       "      <td>0.9656</td>\n",
       "      <td>0.3599</td>\n",
       "      <td>62.0035</td>\n",
       "      <td>1.0876</td>\n",
       "      <td>0.3805</td>\n",
       "      <td>60.7048</td>\n",
       "      <td>1.0486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.343361</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>4.6751</td>\n",
       "      <td>2.2804</td>\n",
       "      <td>67.1400</td>\n",
       "      <td>0.9777</td>\n",
       "      <td>0.4943</td>\n",
       "      <td>62.7175</td>\n",
       "      <td>1.0713</td>\n",
       "      <td>0.5602</td>\n",
       "      <td>56.9203</td>\n",
       "      <td>0.9763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.375900</td>\n",
       "      <td>0.350084</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.3606</td>\n",
       "      <td>4.0295</td>\n",
       "      <td>2.5702</td>\n",
       "      <td>66.2237</td>\n",
       "      <td>1.0226</td>\n",
       "      <td>0.4804</td>\n",
       "      <td>58.0569</td>\n",
       "      <td>0.9233</td>\n",
       "      <td>0.4288</td>\n",
       "      <td>52.6254</td>\n",
       "      <td>1.0216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.375300</td>\n",
       "      <td>0.357518</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.3123</td>\n",
       "      <td>5.5755</td>\n",
       "      <td>3.6739</td>\n",
       "      <td>63.2971</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>0.7125</td>\n",
       "      <td>55.7252</td>\n",
       "      <td>0.8223</td>\n",
       "      <td>0.7530</td>\n",
       "      <td>52.1586</td>\n",
       "      <td>0.8919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.375500</td>\n",
       "      <td>0.345778</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.3599</td>\n",
       "      <td>3.3439</td>\n",
       "      <td>2.0751</td>\n",
       "      <td>67.5038</td>\n",
       "      <td>1.0357</td>\n",
       "      <td>0.4344</td>\n",
       "      <td>59.2021</td>\n",
       "      <td>1.0333</td>\n",
       "      <td>0.4311</td>\n",
       "      <td>58.1573</td>\n",
       "      <td>0.9666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.374100</td>\n",
       "      <td>0.351357</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.3380</td>\n",
       "      <td>3.0311</td>\n",
       "      <td>1.9266</td>\n",
       "      <td>66.0429</td>\n",
       "      <td>0.9351</td>\n",
       "      <td>0.3172</td>\n",
       "      <td>57.7352</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>0.3219</td>\n",
       "      <td>57.1316</td>\n",
       "      <td>1.0809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.375500</td>\n",
       "      <td>0.351732</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.4356</td>\n",
       "      <td>2.9527</td>\n",
       "      <td>1.9124</td>\n",
       "      <td>67.2664</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>0.3566</td>\n",
       "      <td>64.8812</td>\n",
       "      <td>1.0998</td>\n",
       "      <td>0.3733</td>\n",
       "      <td>62.7245</td>\n",
       "      <td>1.0639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.375700</td>\n",
       "      <td>0.339125</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.2398</td>\n",
       "      <td>4.8179</td>\n",
       "      <td>2.5664</td>\n",
       "      <td>67.2630</td>\n",
       "      <td>1.0037</td>\n",
       "      <td>0.3562</td>\n",
       "      <td>62.8906</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>0.3366</td>\n",
       "      <td>58.5118</td>\n",
       "      <td>1.1342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.375800</td>\n",
       "      <td>0.358000</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.3056</td>\n",
       "      <td>3.4589</td>\n",
       "      <td>2.3321</td>\n",
       "      <td>65.0323</td>\n",
       "      <td>0.9142</td>\n",
       "      <td>0.3423</td>\n",
       "      <td>58.3149</td>\n",
       "      <td>1.0307</td>\n",
       "      <td>0.3491</td>\n",
       "      <td>52.2101</td>\n",
       "      <td>1.0161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.372900</td>\n",
       "      <td>0.358397</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>0.3509</td>\n",
       "      <td>4.8618</td>\n",
       "      <td>3.6026</td>\n",
       "      <td>64.2815</td>\n",
       "      <td>0.9473</td>\n",
       "      <td>0.5151</td>\n",
       "      <td>55.4028</td>\n",
       "      <td>0.9373</td>\n",
       "      <td>0.4681</td>\n",
       "      <td>50.7701</td>\n",
       "      <td>0.8993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.373800</td>\n",
       "      <td>0.342667</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.4075</td>\n",
       "      <td>3.8833</td>\n",
       "      <td>2.6835</td>\n",
       "      <td>67.655</td>\n",
       "      <td>0.9619</td>\n",
       "      <td>0.4498</td>\n",
       "      <td>55.3431</td>\n",
       "      <td>0.9265</td>\n",
       "      <td>0.4298</td>\n",
       "      <td>51.2066</td>\n",
       "      <td>1.0422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.373800</td>\n",
       "      <td>0.342675</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>3.9782</td>\n",
       "      <td>2.3423</td>\n",
       "      <td>64.6109</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.4568</td>\n",
       "      <td>55.9679</td>\n",
       "      <td>0.9602</td>\n",
       "      <td>0.4502</td>\n",
       "      <td>53.3015</td>\n",
       "      <td>0.8916</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-95a391ad3032>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ONLY \".1x linear + .9 square period scaled RL\" tanh trade loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# losses are penalized 1.5x, no trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub (doesn't trade all hours!!)\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# ONLY \".1x linear + .9 square period scaled RL\" tanh trade loss\n",
    "# losses are penalized 1.5x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87883' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87883/87883 5:55:17, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.393700</td>\n",
       "      <td>0.363318</td>\n",
       "      <td>-0.0035</td>\n",
       "      <td>-0.0180</td>\n",
       "      <td>7.3048</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0491</td>\n",
       "      <td>65.9794</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>4.7199</td>\n",
       "      <td>49.7990</td>\n",
       "      <td>0.8717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.381500</td>\n",
       "      <td>0.352971</td>\n",
       "      <td>-0.0012</td>\n",
       "      <td>-0.0239</td>\n",
       "      <td>2.0836</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>93.1818</td>\n",
       "      <td>6.5884</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>77.3292</td>\n",
       "      <td>1.2324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.350501</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>1.8266</td>\n",
       "      <td>0.0054</td>\n",
       "      <td>90.6977</td>\n",
       "      <td>5.2375</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>80.3136</td>\n",
       "      <td>1.5826</td>\n",
       "      <td>0.1528</td>\n",
       "      <td>73.4272</td>\n",
       "      <td>0.8534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.372400</td>\n",
       "      <td>0.357260</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>3.1248</td>\n",
       "      <td>0.8166</td>\n",
       "      <td>68.6493</td>\n",
       "      <td>1.1044</td>\n",
       "      <td>0.7001</td>\n",
       "      <td>63.9386</td>\n",
       "      <td>1.0267</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>55.4327</td>\n",
       "      <td>0.8838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.369300</td>\n",
       "      <td>0.350078</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.3991</td>\n",
       "      <td>1.6792</td>\n",
       "      <td>0.7345</td>\n",
       "      <td>75.2712</td>\n",
       "      <td>1.0757</td>\n",
       "      <td>0.3086</td>\n",
       "      <td>65.6967</td>\n",
       "      <td>0.8401</td>\n",
       "      <td>0.3997</td>\n",
       "      <td>59.7152</td>\n",
       "      <td>1.1163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.370200</td>\n",
       "      <td>0.348918</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.2337</td>\n",
       "      <td>3.4833</td>\n",
       "      <td>2.403</td>\n",
       "      <td>61.0254</td>\n",
       "      <td>1.0152</td>\n",
       "      <td>0.6274</td>\n",
       "      <td>59.9395</td>\n",
       "      <td>0.7979</td>\n",
       "      <td>0.6901</td>\n",
       "      <td>56.5249</td>\n",
       "      <td>0.9038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.368900</td>\n",
       "      <td>0.355329</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.1849</td>\n",
       "      <td>6.8242</td>\n",
       "      <td>4.11</td>\n",
       "      <td>60.7226</td>\n",
       "      <td>1.0528</td>\n",
       "      <td>1.5217</td>\n",
       "      <td>50.0998</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>2.3631</td>\n",
       "      <td>47.2969</td>\n",
       "      <td>0.8633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.366000</td>\n",
       "      <td>0.346936</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>2.5266</td>\n",
       "      <td>1.8559</td>\n",
       "      <td>61.5935</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.2185</td>\n",
       "      <td>58.6566</td>\n",
       "      <td>1.1457</td>\n",
       "      <td>0.2586</td>\n",
       "      <td>58.1213</td>\n",
       "      <td>1.3479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.364900</td>\n",
       "      <td>0.351279</td>\n",
       "      <td>0.0229</td>\n",
       "      <td>0.3263</td>\n",
       "      <td>1.9222</td>\n",
       "      <td>1.1978</td>\n",
       "      <td>67.8424</td>\n",
       "      <td>0.8306</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>59.4723</td>\n",
       "      <td>0.8646</td>\n",
       "      <td>0.3113</td>\n",
       "      <td>59.8131</td>\n",
       "      <td>0.8907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.366600</td>\n",
       "      <td>0.347412</td>\n",
       "      <td>0.031</td>\n",
       "      <td>0.1868</td>\n",
       "      <td>3.3347</td>\n",
       "      <td>2.5636</td>\n",
       "      <td>59.3477</td>\n",
       "      <td>0.9876</td>\n",
       "      <td>0.3341</td>\n",
       "      <td>58.6520</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>0.411</td>\n",
       "      <td>58.3872</td>\n",
       "      <td>1.0105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.360400</td>\n",
       "      <td>0.332520</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.1578</td>\n",
       "      <td>3.8251</td>\n",
       "      <td>3.2445</td>\n",
       "      <td>59.4737</td>\n",
       "      <td>0.9146</td>\n",
       "      <td>0.3351</td>\n",
       "      <td>54.9641</td>\n",
       "      <td>0.9177</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>54.4154</td>\n",
       "      <td>0.9275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.348390</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>5.3907</td>\n",
       "      <td>4.3335</td>\n",
       "      <td>59.6748</td>\n",
       "      <td>0.8547</td>\n",
       "      <td>0.5815</td>\n",
       "      <td>55.3187</td>\n",
       "      <td>0.8906</td>\n",
       "      <td>0.7089</td>\n",
       "      <td>51.9272</td>\n",
       "      <td>0.9931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.363000</td>\n",
       "      <td>0.333167</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.4295</td>\n",
       "      <td>1.1887</td>\n",
       "      <td>0.8273</td>\n",
       "      <td>68.7003</td>\n",
       "      <td>1.1192</td>\n",
       "      <td>0.2117</td>\n",
       "      <td>53.5842</td>\n",
       "      <td>1.2511</td>\n",
       "      <td>0.1916</td>\n",
       "      <td>46.7327</td>\n",
       "      <td>1.0993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.360800</td>\n",
       "      <td>0.339186</td>\n",
       "      <td>0.0331</td>\n",
       "      <td>0.3658</td>\n",
       "      <td>2.5510</td>\n",
       "      <td>2.0984</td>\n",
       "      <td>67.6050</td>\n",
       "      <td>0.9364</td>\n",
       "      <td>0.1672</td>\n",
       "      <td>58.2451</td>\n",
       "      <td>0.8838</td>\n",
       "      <td>0.1785</td>\n",
       "      <td>56.6974</td>\n",
       "      <td>0.9228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.358800</td>\n",
       "      <td>0.321028</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.4288</td>\n",
       "      <td>1.9824</td>\n",
       "      <td>1.6020</td>\n",
       "      <td>71.0146</td>\n",
       "      <td>0.9835</td>\n",
       "      <td>0.1734</td>\n",
       "      <td>63.8220</td>\n",
       "      <td>1.116</td>\n",
       "      <td>0.179</td>\n",
       "      <td>62.7562</td>\n",
       "      <td>0.8420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.356000</td>\n",
       "      <td>0.340556</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.2463</td>\n",
       "      <td>2.8224</td>\n",
       "      <td>2.2232</td>\n",
       "      <td>65.4358</td>\n",
       "      <td>0.8266</td>\n",
       "      <td>0.2560</td>\n",
       "      <td>59.7826</td>\n",
       "      <td>0.7271</td>\n",
       "      <td>0.3336</td>\n",
       "      <td>60.9025</td>\n",
       "      <td>0.8474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.356100</td>\n",
       "      <td>0.330574</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.3407</td>\n",
       "      <td>2.6691</td>\n",
       "      <td>2.2478</td>\n",
       "      <td>66.3872</td>\n",
       "      <td>0.951</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>60.1617</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.2577</td>\n",
       "      <td>61.6102</td>\n",
       "      <td>0.8414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.353000</td>\n",
       "      <td>0.334542</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>0.3975</td>\n",
       "      <td>3.3951</td>\n",
       "      <td>2.8093</td>\n",
       "      <td>66.1624</td>\n",
       "      <td>0.9797</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>61.2921</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.2812</td>\n",
       "      <td>58.0747</td>\n",
       "      <td>0.7586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.351600</td>\n",
       "      <td>0.333561</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.2504</td>\n",
       "      <td>4.0519</td>\n",
       "      <td>3.2937</td>\n",
       "      <td>61.0315</td>\n",
       "      <td>0.9274</td>\n",
       "      <td>0.3498</td>\n",
       "      <td>56.9620</td>\n",
       "      <td>0.8326</td>\n",
       "      <td>0.4416</td>\n",
       "      <td>53.7955</td>\n",
       "      <td>1.0139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.352400</td>\n",
       "      <td>0.319525</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.3033</td>\n",
       "      <td>4.0186</td>\n",
       "      <td>3.4923</td>\n",
       "      <td>62.2804</td>\n",
       "      <td>0.9779</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>57.7337</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>0.3742</td>\n",
       "      <td>57.0656</td>\n",
       "      <td>1.0286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.345600</td>\n",
       "      <td>0.314563</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>3.3409</td>\n",
       "      <td>3.0118</td>\n",
       "      <td>64.0067</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.2321</td>\n",
       "      <td>57.4387</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.2577</td>\n",
       "      <td>56.2592</td>\n",
       "      <td>1.0281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.9447</td>\n",
       "      <td>65.</td>\n",
       "      <td>0.919</td>\n",
       "      <td>0.2660</td>\n",
       "      <td>57.1564</td>\n",
       "      <td>0.7791</td>\n",
       "      <td>0.3319</td>\n",
       "      <td>57.6982</td>\n",
       "      <td>0.9243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.348200</td>\n",
       "      <td>0.307489</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>2.813</td>\n",
       "      <td>2.3310</td>\n",
       "      <td>63.7454</td>\n",
       "      <td>0.8176</td>\n",
       "      <td>0.2307</td>\n",
       "      <td>61.4035</td>\n",
       "      <td>0.7063</td>\n",
       "      <td>0.3466</td>\n",
       "      <td>57.1168</td>\n",
       "      <td>0.9242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.349300</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>3.0819</td>\n",
       "      <td>64.7020</td>\n",
       "      <td>0.8901</td>\n",
       "      <td>0.2484</td>\n",
       "      <td>57.2811</td>\n",
       "      <td>0.7423</td>\n",
       "      <td>0.3157</td>\n",
       "      <td>57.2917</td>\n",
       "      <td>0.9483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.346500</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.2566</td>\n",
       "      <td>66.6984</td>\n",
       "      <td>0.9634</td>\n",
       "      <td>0.2086</td>\n",
       "      <td>60.3396</td>\n",
       "      <td>0.8370</td>\n",
       "      <td>0.2456</td>\n",
       "      <td>58.9598</td>\n",
       "      <td>0.9312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.350400</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.2554</td>\n",
       "      <td>66.6966</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.2091</td>\n",
       "      <td>60.3146</td>\n",
       "      <td>0.8503</td>\n",
       "      <td>0.2464</td>\n",
       "      <td>58.9836</td>\n",
       "      <td>0.9318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.348700</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.2541</td>\n",
       "      <td>66.6891</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>0.2082</td>\n",
       "      <td>60.3281</td>\n",
       "      <td>0.8614</td>\n",
       "      <td>0.2468</td>\n",
       "      <td>59.1492</td>\n",
       "      <td>0.9222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.350100</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .7) & (abs_trade >= .4)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:25: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade accuracy': (soft_profit[(abs_trade < .4) & (abs_trade >= .2)] > 0).mean() * 100,\n",
      "<ipython-input-2-bb1c47517fd0>:26: RuntimeWarning: Mean of empty slice.\n",
      "  'small trade g/l': soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-bb1c47517fd0>:27: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .4) & (abs_trade >= .2) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=87883, training_loss=0.11481778573356675, metrics={'train_runtime': 21321.1291, 'train_samples_per_second': 4.122, 'train_steps_per_second': 4.122, 'total_flos': 0.0, 'train_loss': 0.11481778573356675, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OANDA finnhub (diverges, fixes implemented were eps term on standardizing and using tanh rather than exotic elu function)\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# ONLY \"LINEAR period scaled RL\" elu softmax trade loss\n",
    "# losses are penalized 1.5x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5141' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5141/43942 25:32 < 3:12:47, 3.35 it/s, Epoch 0.12/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.386800</td>\n",
       "      <td>0.354672</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.146</td>\n",
       "      <td>8.3711</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.7258</td>\n",
       "      <td>57.4939</td>\n",
       "      <td>0.9224</td>\n",
       "      <td>6.9711</td>\n",
       "      <td>50.6178</td>\n",
       "      <td>0.8656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.381300</td>\n",
       "      <td>0.359246</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>0.1883</td>\n",
       "      <td>4.3257</td>\n",
       "      <td>0.2683</td>\n",
       "      <td>66.8081</td>\n",
       "      <td>1.1604</td>\n",
       "      <td>0.8341</td>\n",
       "      <td>64.2705</td>\n",
       "      <td>0.8782</td>\n",
       "      <td>1.724</td>\n",
       "      <td>60.7088</td>\n",
       "      <td>0.9900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>0.357398</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>6.4927</td>\n",
       "      <td>2.7321</td>\n",
       "      <td>61.0862</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>1.2763</td>\n",
       "      <td>57.7007</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>1.2559</td>\n",
       "      <td>51.5963</td>\n",
       "      <td>0.9796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.377900</td>\n",
       "      <td>0.350481</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.3666</td>\n",
       "      <td>3.1494</td>\n",
       "      <td>1.5923</td>\n",
       "      <td>67.5008</td>\n",
       "      <td>0.9248</td>\n",
       "      <td>0.6475</td>\n",
       "      <td>63.0006</td>\n",
       "      <td>1.0738</td>\n",
       "      <td>0.6499</td>\n",
       "      <td>56.2086</td>\n",
       "      <td>1.0500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.375200</td>\n",
       "      <td>0.350531</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.3217</td>\n",
       "      <td>3.5236</td>\n",
       "      <td>2.0078</td>\n",
       "      <td>67.618</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>0.4922</td>\n",
       "      <td>61.2696</td>\n",
       "      <td>0.8353</td>\n",
       "      <td>0.4808</td>\n",
       "      <td>56.4325</td>\n",
       "      <td>0.9129</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e49443c80eb5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ONLY \"LINEAR period scaled RL\" elu softmax trade loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# losses are penalized 1.3x, no trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, NO dropout, weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# ONLY \"LINEAR period scaled RL\" elu softmax trade loss\n",
    "# losses are penalized 1.3x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='15624' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [15624/43942 1:18:52 < 2:22:59, 3.30 it/s, Epoch 0.36/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.388300</td>\n",
       "      <td>0.356211</td>\n",
       "      <td>-0.0175</td>\n",
       "      <td>-0.1079</td>\n",
       "      <td>9.1742</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.5902</td>\n",
       "      <td>55.2079</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>9.4995</td>\n",
       "      <td>50.4973</td>\n",
       "      <td>0.9154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.381000</td>\n",
       "      <td>0.357616</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>3.3176</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>73.2323</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>0.5313</td>\n",
       "      <td>64.5476</td>\n",
       "      <td>0.929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.378600</td>\n",
       "      <td>0.361916</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.2447</td>\n",
       "      <td>4.7388</td>\n",
       "      <td>0.4797</td>\n",
       "      <td>61.8935</td>\n",
       "      <td>1.0431</td>\n",
       "      <td>1.0428</td>\n",
       "      <td>63.0277</td>\n",
       "      <td>0.8643</td>\n",
       "      <td>1.6674</td>\n",
       "      <td>56.9868</td>\n",
       "      <td>0.8307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.378800</td>\n",
       "      <td>0.359277</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.2873</td>\n",
       "      <td>3.6762</td>\n",
       "      <td>1.5972</td>\n",
       "      <td>63.9661</td>\n",
       "      <td>1.0251</td>\n",
       "      <td>0.804</td>\n",
       "      <td>54.012</td>\n",
       "      <td>1.1753</td>\n",
       "      <td>0.9032</td>\n",
       "      <td>59.0336</td>\n",
       "      <td>0.9827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>0.351894</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>4.0004</td>\n",
       "      <td>2.4681</td>\n",
       "      <td>63.4789</td>\n",
       "      <td>1.0381</td>\n",
       "      <td>0.5443</td>\n",
       "      <td>59.5863</td>\n",
       "      <td>1.1410</td>\n",
       "      <td>0.5940</td>\n",
       "      <td>57.73</td>\n",
       "      <td>1.0913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.371500</td>\n",
       "      <td>0.348755</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>6.4342</td>\n",
       "      <td>4.6152</td>\n",
       "      <td>59.9627</td>\n",
       "      <td>0.9063</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>54.9918</td>\n",
       "      <td>0.8496</td>\n",
       "      <td>0.8748</td>\n",
       "      <td>52.4725</td>\n",
       "      <td>0.9126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.339335</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.33</td>\n",
       "      <td>3.6657</td>\n",
       "      <td>2.5760</td>\n",
       "      <td>65.5831</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.3764</td>\n",
       "      <td>61.8616</td>\n",
       "      <td>0.9667</td>\n",
       "      <td>0.4488</td>\n",
       "      <td>59.3856</td>\n",
       "      <td>1.0758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.372200</td>\n",
       "      <td>0.359813</td>\n",
       "      <td>0.0373</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>5.2174</td>\n",
       "      <td>3.62</td>\n",
       "      <td>61.6081</td>\n",
       "      <td>0.8993</td>\n",
       "      <td>0.4836</td>\n",
       "      <td>52.655</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>0.4878</td>\n",
       "      <td>49.1183</td>\n",
       "      <td>0.9006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.374400</td>\n",
       "      <td>0.345298</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.3018</td>\n",
       "      <td>5.0414</td>\n",
       "      <td>3.8283</td>\n",
       "      <td>64.2062</td>\n",
       "      <td>0.9674</td>\n",
       "      <td>0.3754</td>\n",
       "      <td>51.5836</td>\n",
       "      <td>0.9116</td>\n",
       "      <td>0.4057</td>\n",
       "      <td>44.8706</td>\n",
       "      <td>0.7389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.374100</td>\n",
       "      <td>0.342355</td>\n",
       "      <td>0.0381</td>\n",
       "      <td>0.3632</td>\n",
       "      <td>3.8266</td>\n",
       "      <td>2.8035</td>\n",
       "      <td>64.8874</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>0.41</td>\n",
       "      <td>56.4641</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.4542</td>\n",
       "      <td>53.7176</td>\n",
       "      <td>0.9369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.373600</td>\n",
       "      <td>0.343126</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>5.9267</td>\n",
       "      <td>4.9857</td>\n",
       "      <td>59.4215</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>0.4680</td>\n",
       "      <td>51.2973</td>\n",
       "      <td>0.7962</td>\n",
       "      <td>0.5124</td>\n",
       "      <td>50.0617</td>\n",
       "      <td>0.8870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.361525</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.1998</td>\n",
       "      <td>6.5338</td>\n",
       "      <td>5.062</td>\n",
       "      <td>60.2704</td>\n",
       "      <td>0.8647</td>\n",
       "      <td>0.654</td>\n",
       "      <td>49.9033</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.7783</td>\n",
       "      <td>47.1315</td>\n",
       "      <td>0.8615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.371200</td>\n",
       "      <td>0.338511</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>3.1136</td>\n",
       "      <td>2.3273</td>\n",
       "      <td>63.3513</td>\n",
       "      <td>0.8505</td>\n",
       "      <td>0.4364</td>\n",
       "      <td>52.2029</td>\n",
       "      <td>0.9739</td>\n",
       "      <td>0.379</td>\n",
       "      <td>52.47</td>\n",
       "      <td>0.9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.370500</td>\n",
       "      <td>0.339561</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.3306</td>\n",
       "      <td>4.3865</td>\n",
       "      <td>3.6609</td>\n",
       "      <td>63.1573</td>\n",
       "      <td>0.9497</td>\n",
       "      <td>0.4324</td>\n",
       "      <td>51.931</td>\n",
       "      <td>0.8808</td>\n",
       "      <td>0.4082</td>\n",
       "      <td>50.6972</td>\n",
       "      <td>0.9722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.371100</td>\n",
       "      <td>0.338001</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.2484</td>\n",
       "      <td>5.5715</td>\n",
       "      <td>4.4766</td>\n",
       "      <td>60.0537</td>\n",
       "      <td>0.9269</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>50.7944</td>\n",
       "      <td>0.8239</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>50.6953</td>\n",
       "      <td>0.9224</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-738357500999>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ONLY \"LINEAR period scaled RL\" elu softmax trade loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# losses are penalized 1.3x, no trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, .1 dropout weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# ONLY \"LINEAR period scaled RL\" elu softmax trade loss\n",
    "# losses are penalized 1.3x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13114' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13114/43942 1:05:04 < 2:33:00, 3.36 it/s, Epoch 0.30/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.395600</td>\n",
       "      <td>0.356608</td>\n",
       "      <td>-0.0104</td>\n",
       "      <td>-0.1803</td>\n",
       "      <td>4.6307</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>37.1429</td>\n",
       "      <td>1.2537</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>54.3694</td>\n",
       "      <td>0.8257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.379100</td>\n",
       "      <td>0.355630</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>1.598</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>67.3228</td>\n",
       "      <td>1.0029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.374000</td>\n",
       "      <td>0.348646</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>1.1692</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>66.6667</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>80.</td>\n",
       "      <td>0.8821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.341946</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>1.1859</td>\n",
       "      <td>0.0574</td>\n",
       "      <td>85.6828</td>\n",
       "      <td>1.4205</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>82.2018</td>\n",
       "      <td>1.0291</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>67.6316</td>\n",
       "      <td>0.9444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.372000</td>\n",
       "      <td>0.354999</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.2457</td>\n",
       "      <td>2.3065</td>\n",
       "      <td>1.1214</td>\n",
       "      <td>63.8127</td>\n",
       "      <td>0.9207</td>\n",
       "      <td>0.4101</td>\n",
       "      <td>60.6416</td>\n",
       "      <td>1.0103</td>\n",
       "      <td>0.5358</td>\n",
       "      <td>59.7262</td>\n",
       "      <td>0.9797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.365600</td>\n",
       "      <td>0.349378</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.1701</td>\n",
       "      <td>5.7283</td>\n",
       "      <td>4.8588</td>\n",
       "      <td>59.2081</td>\n",
       "      <td>0.9344</td>\n",
       "      <td>0.5573</td>\n",
       "      <td>50.2497</td>\n",
       "      <td>0.8888</td>\n",
       "      <td>0.6032</td>\n",
       "      <td>50.9121</td>\n",
       "      <td>0.9091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.366700</td>\n",
       "      <td>0.330631</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.3924</td>\n",
       "      <td>2.8108</td>\n",
       "      <td>2.0570</td>\n",
       "      <td>67.3103</td>\n",
       "      <td>1.0792</td>\n",
       "      <td>0.3529</td>\n",
       "      <td>65.1971</td>\n",
       "      <td>0.8474</td>\n",
       "      <td>0.3494</td>\n",
       "      <td>62.2375</td>\n",
       "      <td>1.0488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.365200</td>\n",
       "      <td>0.348894</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.1297</td>\n",
       "      <td>6.0388</td>\n",
       "      <td>4.7307</td>\n",
       "      <td>57.6539</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>50.4868</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>0.6753</td>\n",
       "      <td>50.7960</td>\n",
       "      <td>0.9401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.366800</td>\n",
       "      <td>0.347121</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.3418</td>\n",
       "      <td>1.6402</td>\n",
       "      <td>1.0398</td>\n",
       "      <td>67.9805</td>\n",
       "      <td>0.9315</td>\n",
       "      <td>0.2358</td>\n",
       "      <td>62.2318</td>\n",
       "      <td>0.7849</td>\n",
       "      <td>0.2599</td>\n",
       "      <td>59.5134</td>\n",
       "      <td>0.8321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.364800</td>\n",
       "      <td>0.331296</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.35</td>\n",
       "      <td>2.0329</td>\n",
       "      <td>1.4347</td>\n",
       "      <td>67.2192</td>\n",
       "      <td>1.0039</td>\n",
       "      <td>0.2162</td>\n",
       "      <td>65.2428</td>\n",
       "      <td>1.2319</td>\n",
       "      <td>0.2317</td>\n",
       "      <td>63.3734</td>\n",
       "      <td>1.1644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.365400</td>\n",
       "      <td>0.337449</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.3699</td>\n",
       "      <td>2.2894</td>\n",
       "      <td>1.6763</td>\n",
       "      <td>67.1521</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>63.9489</td>\n",
       "      <td>1.0543</td>\n",
       "      <td>0.3242</td>\n",
       "      <td>60.7491</td>\n",
       "      <td>0.9945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.365200</td>\n",
       "      <td>0.352316</td>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.2097</td>\n",
       "      <td>4.6291</td>\n",
       "      <td>3.8661</td>\n",
       "      <td>61.0718</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>0.5003</td>\n",
       "      <td>55.4741</td>\n",
       "      <td>0.9281</td>\n",
       "      <td>0.5777</td>\n",
       "      <td>52.3538</td>\n",
       "      <td>0.8716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.365200</td>\n",
       "      <td>0.335882</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>2.6565</td>\n",
       "      <td>2.1704</td>\n",
       "      <td>65.2407</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>60.3435</td>\n",
       "      <td>0.9689</td>\n",
       "      <td>0.317</td>\n",
       "      <td>57.7813</td>\n",
       "      <td>0.8875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .7) & (abs_trade >= .4) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f312215437b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ONLY \"LINEAR period scaled RL\" elu softmax trade loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# losses are penalized 1.5x, no trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1738\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_grad_scaling\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2480\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2481\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_apex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2482\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, .1 dropout weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# ONLY \"LINEAR period scaled RL\" elu softmax trade loss\n",
    "# losses are penalized 1.5x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8001' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8001/87883 36:05 < 6:00:26, 3.69 it/s, Epoch 0.09/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.397900</td>\n",
       "      <td>0.362663</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.0320</td>\n",
       "      <td>7.7494</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>57.9853</td>\n",
       "      <td>1.4070</td>\n",
       "      <td>3.7644</td>\n",
       "      <td>52.3152</td>\n",
       "      <td>0.9905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.383800</td>\n",
       "      <td>0.353472</td>\n",
       "      <td>-0.0036</td>\n",
       "      <td>-0.0714</td>\n",
       "      <td>2.2539</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>83.3333</td>\n",
       "      <td>7.6488</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>74.7440</td>\n",
       "      <td>1.0284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.377200</td>\n",
       "      <td>0.364714</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>1.7569</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>75.</td>\n",
       "      <td>4.8847</td>\n",
       "      <td>0.019</td>\n",
       "      <td>82.</td>\n",
       "      <td>1.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.374300</td>\n",
       "      <td>0.364919</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.199</td>\n",
       "      <td>2.0313</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>80.4651</td>\n",
       "      <td>1.2504</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>77.4876</td>\n",
       "      <td>1.3696</td>\n",
       "      <td>0.2758</td>\n",
       "      <td>69.7706</td>\n",
       "      <td>1.0749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.371300</td>\n",
       "      <td>0.356807</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.4667</td>\n",
       "      <td>1.4342</td>\n",
       "      <td>0.3223</td>\n",
       "      <td>80.6907</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.1761</td>\n",
       "      <td>68.75</td>\n",
       "      <td>1.0194</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>67.6836</td>\n",
       "      <td>1.1733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.371600</td>\n",
       "      <td>0.352305</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.3032</td>\n",
       "      <td>2.0234</td>\n",
       "      <td>0.8141</td>\n",
       "      <td>69.0180</td>\n",
       "      <td>0.9992</td>\n",
       "      <td>0.4011</td>\n",
       "      <td>61.9678</td>\n",
       "      <td>0.904</td>\n",
       "      <td>0.6070</td>\n",
       "      <td>61.1586</td>\n",
       "      <td>0.8697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.372300</td>\n",
       "      <td>0.362459</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>6.8731</td>\n",
       "      <td>5.6824</td>\n",
       "      <td>54.3486</td>\n",
       "      <td>0.9729</td>\n",
       "      <td>0.6216</td>\n",
       "      <td>51.7298</td>\n",
       "      <td>0.9094</td>\n",
       "      <td>0.72</td>\n",
       "      <td>51.2122</td>\n",
       "      <td>0.9566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [39/61 00:04 < 00:02, 9.16 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, rotary embeddings, .1 dropout weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# ONLY \"LINEAR period scaled RL\" elu softmax trade loss\n",
    "# losses are penalized 1.5x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3225' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3225/43942 16:29 < 3:28:23, 3.26 it/s, Epoch 0.07/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>-0.292400</td>\n",
       "      <td>-0.308482</td>\n",
       "      <td>-0.1379</td>\n",
       "      <td>-0.1938</td>\n",
       "      <td>98.3911</td>\n",
       "      <td>98.3927</td>\n",
       "      <td>48.6395</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>0.8418</td>\n",
       "      <td>49.5868</td>\n",
       "      <td>0.9280</td>\n",
       "      <td>0.4024</td>\n",
       "      <td>47.3750</td>\n",
       "      <td>1.1046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>-0.307500</td>\n",
       "      <td>-0.308091</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>-0.1951</td>\n",
       "      <td>99.5546</td>\n",
       "      <td>99.4945</td>\n",
       "      <td>48.6983</td>\n",
       "      <td>0.9717</td>\n",
       "      <td>0.2716</td>\n",
       "      <td>46.5766</td>\n",
       "      <td>1.0808</td>\n",
       "      <td>0.1284</td>\n",
       "      <td>47.0936</td>\n",
       "      <td>1.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>-0.306600</td>\n",
       "      <td>-0.309098</td>\n",
       "      <td>-0.1411</td>\n",
       "      <td>-0.1598</td>\n",
       "      <td>99.9915</td>\n",
       "      <td>99.9948</td>\n",
       "      <td>48.6528</td>\n",
       "      <td>0.9754</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>57.1429</td>\n",
       "      <td>1.2127</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>66.6667</td>\n",
       "      <td>1.294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-71c6f02f8b6c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# ONLY two-sided log RL + e elu softmax trade loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# losses are penalized 1.5x, no trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1738\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2469\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2470\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2472\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2500\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2501\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2502\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2503\u001b[0m         \u001b[1;31m# Save past state if it exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2504\u001b[0m         \u001b[1;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Trader\\trader_models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, ohlcv, labels, future)\u001b[0m\n\u001b[0;32m    116\u001b[0m         \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtriu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mohlcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdiagonal\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m10000.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    117\u001b[0m         hidden = torch.permute(\n\u001b[1;32m--> 118\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msru\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattn_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    119\u001b[0m         )\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\micha\\desktop\\sru\\sru\\modules.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, c0, mask_pad, attn_mask, memory, memory_mask_pad)\u001b[0m\n\u001b[0;32m   1222\u001b[0m             \u001b[0mprev_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m             \u001b[0mmemory_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmemory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmemory\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1224\u001b[1;33m             h, c = rnn(x, c0_[i],\n\u001b[0m\u001b[0;32m   1225\u001b[0m                        \u001b[0mmask_pad\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmask_pad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m                        \u001b[0mattn_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\micha\\desktop\\sru\\sru\\modules.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, c0, mask_pad, attn_mask, memory, memory_mask_pad)\u001b[0m\n\u001b[0;32m    928\u001b[0m         \u001b[1;31m#   U is (length, batch_size, output_size * num_matrices)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    929\u001b[0m         \u001b[0mtransform_module\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform_module\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 930\u001b[1;33m         U = transform_module(input, mask_pad=mask_pad,\n\u001b[0m\u001b[0;32m    931\u001b[0m                              \u001b[0mattn_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    932\u001b[0m                              \u001b[0mmemory\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemory\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\micha\\desktop\\sru\\sru\\modules.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, mask_pad, attn_mask, memory, memory_mask_pad)\u001b[0m\n\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m         \u001b[1;31m# query, key, value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 822\u001b[1;33m         \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    823\u001b[0m         \u001b[0mq\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtgt_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    824\u001b[0m         \u001b[0mk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhead_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 2 hidden size 320, 10 layers,\n",
    "# fp16, rotary embeddings, .1 dropout weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# ONLY two-sided log RL + e elu softmax trade loss\n",
    "# losses are penalized 1.5x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='13055' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [13055/87883 59:57 < 5:43:41, 3.63 it/s, Epoch 0.15/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.229700</td>\n",
       "      <td>3.093594</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.1344</td>\n",
       "      <td>11.6969</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.951</td>\n",
       "      <td>50.4123</td>\n",
       "      <td>1.0906</td>\n",
       "      <td>16.4523</td>\n",
       "      <td>50.7885</td>\n",
       "      <td>0.9946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.152100</td>\n",
       "      <td>3.044600</td>\n",
       "      <td>-0.0021</td>\n",
       "      <td>-0.0486</td>\n",
       "      <td>3.5903</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>80.</td>\n",
       "      <td>2.3599</td>\n",
       "      <td>0.57</td>\n",
       "      <td>58.3444</td>\n",
       "      <td>1.0977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.120200</td>\n",
       "      <td>3.038877</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.3424</td>\n",
       "      <td>2.7888</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>83.3333</td>\n",
       "      <td>4.1985</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>61.5830</td>\n",
       "      <td>1.1118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.111100</td>\n",
       "      <td>3.041095</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.2019</td>\n",
       "      <td>4.2980</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>89.2857</td>\n",
       "      <td>1.2617</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>69.2115</td>\n",
       "      <td>1.3348</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>59.9124</td>\n",
       "      <td>0.8797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.105200</td>\n",
       "      <td>3.034074</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.3717</td>\n",
       "      <td>2.0918</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>90.3226</td>\n",
       "      <td>3.8296</td>\n",
       "      <td>0.0872</td>\n",
       "      <td>78.3745</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>0.2873</td>\n",
       "      <td>72.303</td>\n",
       "      <td>1.111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.103300</td>\n",
       "      <td>3.064079</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1479</td>\n",
       "      <td>3.3036</td>\n",
       "      <td>0.155</td>\n",
       "      <td>72.0816</td>\n",
       "      <td>1.2831</td>\n",
       "      <td>0.4991</td>\n",
       "      <td>67.7141</td>\n",
       "      <td>1.0617</td>\n",
       "      <td>1.0203</td>\n",
       "      <td>61.1579</td>\n",
       "      <td>0.8429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.096400</td>\n",
       "      <td>3.015548</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.1665</td>\n",
       "      <td>3.3744</td>\n",
       "      <td>0.3651</td>\n",
       "      <td>58.6625</td>\n",
       "      <td>1.0049</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>67.8334</td>\n",
       "      <td>1.0504</td>\n",
       "      <td>1.3721</td>\n",
       "      <td>57.8685</td>\n",
       "      <td>0.7117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.096100</td>\n",
       "      <td>3.040261</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.2426</td>\n",
       "      <td>4.3712</td>\n",
       "      <td>1.4235</td>\n",
       "      <td>66.6519</td>\n",
       "      <td>1.0266</td>\n",
       "      <td>1.2004</td>\n",
       "      <td>60.2424</td>\n",
       "      <td>0.8075</td>\n",
       "      <td>1.4774</td>\n",
       "      <td>56.0017</td>\n",
       "      <td>0.8098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.090300</td>\n",
       "      <td>3.049189</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.3096</td>\n",
       "      <td>4.2206</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>68.0457</td>\n",
       "      <td>0.9871</td>\n",
       "      <td>0.8657</td>\n",
       "      <td>65.0351</td>\n",
       "      <td>0.8574</td>\n",
       "      <td>1.0472</td>\n",
       "      <td>58.0626</td>\n",
       "      <td>0.7485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.091300</td>\n",
       "      <td>2.995134</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>2.8335</td>\n",
       "      <td>0.8347</td>\n",
       "      <td>66.1009</td>\n",
       "      <td>0.9621</td>\n",
       "      <td>0.7022</td>\n",
       "      <td>65.3396</td>\n",
       "      <td>1.1299</td>\n",
       "      <td>0.9357</td>\n",
       "      <td>60.7544</td>\n",
       "      <td>0.9206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.076900</td>\n",
       "      <td>3.009329</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>2.9875</td>\n",
       "      <td>1.0710</td>\n",
       "      <td>66.4698</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>0.7237</td>\n",
       "      <td>62.7862</td>\n",
       "      <td>0.8298</td>\n",
       "      <td>0.8314</td>\n",
       "      <td>59.1206</td>\n",
       "      <td>0.8129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.076800</td>\n",
       "      <td>3.031163</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>4.9427</td>\n",
       "      <td>1.9443</td>\n",
       "      <td>62.3772</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>1.1634</td>\n",
       "      <td>60.2588</td>\n",
       "      <td>0.8304</td>\n",
       "      <td>1.3297</td>\n",
       "      <td>54.8135</td>\n",
       "      <td>0.8568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.075300</td>\n",
       "      <td>3.018914</td>\n",
       "      <td>0.0160</td>\n",
       "      <td>0.3671</td>\n",
       "      <td>2.4948</td>\n",
       "      <td>0.3595</td>\n",
       "      <td>72.4842</td>\n",
       "      <td>1.0324</td>\n",
       "      <td>0.476</td>\n",
       "      <td>64.7356</td>\n",
       "      <td>0.9769</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>64.0316</td>\n",
       "      <td>1.0573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9147f4d395b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with \"LINEAR period scaled RL\" elu softmax trade loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# losses are penalized 1.5x, no trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1800\u001b[0m                     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_grad_scaling\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1801\u001b[0m                         \u001b[0mscale_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1802\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1803\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m                         \u001b[0mscale_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stage\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\optimization.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    359\u001b[0m                 \u001b[1;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    360\u001b[0m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 361\u001b[1;33m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    362\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eps\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, rotary embeddings, .1 dropout weight decay, head size of 64\n",
    "# NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with \"LINEAR period scaled RL\" elu softmax trade loss\n",
    "# losses are penalized 1.5x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3317' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3317/87883 15:00 < 6:22:47, 3.68 it/s, Epoch 0.04/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.359900</td>\n",
       "      <td>3.255566</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2197</td>\n",
       "      <td>31.9716</td>\n",
       "      <td>5.0638</td>\n",
       "      <td>53.762</td>\n",
       "      <td>1.0721</td>\n",
       "      <td>29.8332</td>\n",
       "      <td>50.8101</td>\n",
       "      <td>1.0410</td>\n",
       "      <td>29.3039</td>\n",
       "      <td>49.7516</td>\n",
       "      <td>1.0222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.313500</td>\n",
       "      <td>3.240958</td>\n",
       "      <td>0.2581</td>\n",
       "      <td>0.1749</td>\n",
       "      <td>53.4494</td>\n",
       "      <td>34.6891</td>\n",
       "      <td>51.1454</td>\n",
       "      <td>1.0185</td>\n",
       "      <td>31.9849</td>\n",
       "      <td>49.9185</td>\n",
       "      <td>1.0115</td>\n",
       "      <td>17.3311</td>\n",
       "      <td>48.9202</td>\n",
       "      <td>1.0136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.286800</td>\n",
       "      <td>3.226113</td>\n",
       "      <td>0.3299</td>\n",
       "      <td>0.2779</td>\n",
       "      <td>56.7405</td>\n",
       "      <td>41.0795</td>\n",
       "      <td>52.0865</td>\n",
       "      <td>1.0252</td>\n",
       "      <td>27.8740</td>\n",
       "      <td>50.2426</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>15.4953</td>\n",
       "      <td>49.7331</td>\n",
       "      <td>0.9746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-55e09b48f394>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with \"squared period scaled RL\" elu softmax trade loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# losses are penalized 1.1x, no trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with \"squared period scaled RL\" elu softmax trade loss\n",
    "# losses are penalized 1.1x, no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7020' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 7020/87883 31:53 < 6:07:31, 3.67 it/s, Epoch 0.08/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.353500</td>\n",
       "      <td>3.248688</td>\n",
       "      <td>0.1836</td>\n",
       "      <td>0.2009</td>\n",
       "      <td>24.2354</td>\n",
       "      <td>1.8746</td>\n",
       "      <td>54.6491</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>18.261</td>\n",
       "      <td>51.7594</td>\n",
       "      <td>1.0614</td>\n",
       "      <td>29.849</td>\n",
       "      <td>49.7402</td>\n",
       "      <td>1.0165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.303900</td>\n",
       "      <td>3.230324</td>\n",
       "      <td>0.1534</td>\n",
       "      <td>0.1367</td>\n",
       "      <td>33.3401</td>\n",
       "      <td>8.4419</td>\n",
       "      <td>51.6857</td>\n",
       "      <td>0.9741</td>\n",
       "      <td>27.9019</td>\n",
       "      <td>50.7904</td>\n",
       "      <td>1.0219</td>\n",
       "      <td>28.0458</td>\n",
       "      <td>49.7995</td>\n",
       "      <td>1.0344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.281500</td>\n",
       "      <td>3.210099</td>\n",
       "      <td>0.2713</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>34.3598</td>\n",
       "      <td>10.854</td>\n",
       "      <td>54.5398</td>\n",
       "      <td>1.0372</td>\n",
       "      <td>27.2145</td>\n",
       "      <td>51.8287</td>\n",
       "      <td>1.0152</td>\n",
       "      <td>25.7678</td>\n",
       "      <td>49.9440</td>\n",
       "      <td>0.9746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.272500</td>\n",
       "      <td>3.201935</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>0.2652</td>\n",
       "      <td>27.8839</td>\n",
       "      <td>6.8158</td>\n",
       "      <td>54.4365</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>19.7569</td>\n",
       "      <td>52.4918</td>\n",
       "      <td>1.0096</td>\n",
       "      <td>25.9783</td>\n",
       "      <td>50.6174</td>\n",
       "      <td>0.9999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.266100</td>\n",
       "      <td>3.210654</td>\n",
       "      <td>0.2495</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>35.6385</td>\n",
       "      <td>14.2762</td>\n",
       "      <td>53.1277</td>\n",
       "      <td>0.9829</td>\n",
       "      <td>24.013</td>\n",
       "      <td>52.2137</td>\n",
       "      <td>1.0268</td>\n",
       "      <td>25.0010</td>\n",
       "      <td>50.3946</td>\n",
       "      <td>0.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.263400</td>\n",
       "      <td>3.236413</td>\n",
       "      <td>0.2612</td>\n",
       "      <td>0.2607</td>\n",
       "      <td>34.1572</td>\n",
       "      <td>14.9656</td>\n",
       "      <td>54.4983</td>\n",
       "      <td>1.0161</td>\n",
       "      <td>19.8512</td>\n",
       "      <td>51.8364</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>24.4212</td>\n",
       "      <td>49.2049</td>\n",
       "      <td>0.9737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.254100</td>\n",
       "      <td>3.190062</td>\n",
       "      <td>0.0729</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>32.9850</td>\n",
       "      <td>14.0571</td>\n",
       "      <td>51.4434</td>\n",
       "      <td>0.9534</td>\n",
       "      <td>18.9000</td>\n",
       "      <td>51.4844</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>24.3564</td>\n",
       "      <td>49.53</td>\n",
       "      <td>0.9758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-11dce1f55dab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with \"squared period scaled RL\" elu softmax trade loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# with .1 trade penalty sqaured\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1802\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1803\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1804\u001b[1;33m                         \u001b[0mscale_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1805\u001b[0m                         \u001b[0moptimizer_was_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale_before\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mscale_after\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1806\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mget_scale\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \"\"\"\n\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_scale\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scale\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_scale_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with \"squared period scaled RL\" elu softmax trade loss\n",
    "# with .1 trade penalty sqaured\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10222' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10222/87883 46:28 < 5:53:09, 3.67 it/s, Epoch 0.12/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.361700</td>\n",
       "      <td>3.254481</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2674</td>\n",
       "      <td>18.9847</td>\n",
       "      <td>0.3566</td>\n",
       "      <td>59.7375</td>\n",
       "      <td>1.0843</td>\n",
       "      <td>10.0855</td>\n",
       "      <td>53.5055</td>\n",
       "      <td>1.0845</td>\n",
       "      <td>28.4821</td>\n",
       "      <td>50.6844</td>\n",
       "      <td>1.0357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.305200</td>\n",
       "      <td>3.221562</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.1115</td>\n",
       "      <td>18.6483</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>52.7935</td>\n",
       "      <td>1.072</td>\n",
       "      <td>9.6514</td>\n",
       "      <td>52.1389</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>28.5243</td>\n",
       "      <td>50.3552</td>\n",
       "      <td>0.9824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.280300</td>\n",
       "      <td>3.209769</td>\n",
       "      <td>0.1694</td>\n",
       "      <td>0.318</td>\n",
       "      <td>18.2812</td>\n",
       "      <td>0.3947</td>\n",
       "      <td>56.8269</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>9.8552</td>\n",
       "      <td>54.5584</td>\n",
       "      <td>1.0277</td>\n",
       "      <td>26.3017</td>\n",
       "      <td>52.2120</td>\n",
       "      <td>1.0485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.271500</td>\n",
       "      <td>3.201888</td>\n",
       "      <td>0.0907</td>\n",
       "      <td>0.2753</td>\n",
       "      <td>14.006</td>\n",
       "      <td>0.286</td>\n",
       "      <td>53.3392</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>4.5053</td>\n",
       "      <td>55.1029</td>\n",
       "      <td>0.9651</td>\n",
       "      <td>18.8636</td>\n",
       "      <td>52.5609</td>\n",
       "      <td>1.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.264300</td>\n",
       "      <td>3.206804</td>\n",
       "      <td>0.1253</td>\n",
       "      <td>0.2354</td>\n",
       "      <td>17.8565</td>\n",
       "      <td>1.5618</td>\n",
       "      <td>52.8225</td>\n",
       "      <td>0.9351</td>\n",
       "      <td>7.5159</td>\n",
       "      <td>54.1671</td>\n",
       "      <td>0.9488</td>\n",
       "      <td>24.5831</td>\n",
       "      <td>52.6988</td>\n",
       "      <td>1.0241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.265200</td>\n",
       "      <td>3.233707</td>\n",
       "      <td>0.1585</td>\n",
       "      <td>0.2851</td>\n",
       "      <td>17.7203</td>\n",
       "      <td>1.8976</td>\n",
       "      <td>58.4989</td>\n",
       "      <td>1.0044</td>\n",
       "      <td>8.7671</td>\n",
       "      <td>55.8585</td>\n",
       "      <td>0.9745</td>\n",
       "      <td>21.4110</td>\n",
       "      <td>51.8524</td>\n",
       "      <td>1.0126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.252000</td>\n",
       "      <td>3.182875</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>17.4529</td>\n",
       "      <td>2.5359</td>\n",
       "      <td>52.0401</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>7.5204</td>\n",
       "      <td>52.0445</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>19.9397</td>\n",
       "      <td>50.2852</td>\n",
       "      <td>0.9567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.254200</td>\n",
       "      <td>3.203644</td>\n",
       "      <td>0.1377</td>\n",
       "      <td>0.3698</td>\n",
       "      <td>17.3585</td>\n",
       "      <td>1.4153</td>\n",
       "      <td>55.0273</td>\n",
       "      <td>0.9149</td>\n",
       "      <td>5.3141</td>\n",
       "      <td>56.0401</td>\n",
       "      <td>1.0242</td>\n",
       "      <td>24.9462</td>\n",
       "      <td>51.5934</td>\n",
       "      <td>1.0306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.249500</td>\n",
       "      <td>3.229805</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.1808</td>\n",
       "      <td>22.3144</td>\n",
       "      <td>4.1679</td>\n",
       "      <td>52.9590</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>11.7181</td>\n",
       "      <td>52.4347</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>26.5634</td>\n",
       "      <td>50.0786</td>\n",
       "      <td>1.0292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.247800</td>\n",
       "      <td>3.179603</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>17.8648</td>\n",
       "      <td>2.9441</td>\n",
       "      <td>51.4157</td>\n",
       "      <td>0.9227</td>\n",
       "      <td>8.2354</td>\n",
       "      <td>52.0766</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>19.7833</td>\n",
       "      <td>50.8859</td>\n",
       "      <td>0.9787</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-9adf244a6768>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with \"squared period scaled RL\" elu softmax trade loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;31m# with .2 trade penalty sqaure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with \"squared period scaled RL\" elu softmax trade loss\n",
    "# with .2 trade penalty sqaured\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4588' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4588/87883 20:44 < 6:16:52, 3.68 it/s, Epoch 0.05/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.383700</td>\n",
       "      <td>3.265529</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.2009</td>\n",
       "      <td>13.1739</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>58.0645</td>\n",
       "      <td>0.9971</td>\n",
       "      <td>3.2667</td>\n",
       "      <td>54.1955</td>\n",
       "      <td>1.0606</td>\n",
       "      <td>18.8643</td>\n",
       "      <td>51.1024</td>\n",
       "      <td>1.0328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.309900</td>\n",
       "      <td>3.213760</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>0.0246</td>\n",
       "      <td>4.6102</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>53.3333</td>\n",
       "      <td>1.0342</td>\n",
       "      <td>0.7034</td>\n",
       "      <td>53.4616</td>\n",
       "      <td>1.0013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.279000</td>\n",
       "      <td>3.211110</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>3.4362</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>50.</td>\n",
       "      <td>0.9306</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>57.5275</td>\n",
       "      <td>0.9872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.268400</td>\n",
       "      <td>3.217199</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.2503</td>\n",
       "      <td>4.0597</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>72.7273</td>\n",
       "      <td>0.7073</td>\n",
       "      <td>0.146</td>\n",
       "      <td>70.364</td>\n",
       "      <td>1.029</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4913c707d3d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with \"squared period scaled RL\" elu softmax trade loss with .2 trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1738\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2469\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2470\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2472\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2500\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2501\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2502\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2503\u001b[0m         \u001b[1;31m# Save past state if it exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2504\u001b[0m         \u001b[1;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Trader\\trader_models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, ohlcv, labels, future)\u001b[0m\n\u001b[0;32m    119\u001b[0m         )\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mlogits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m \u001b[1;31m#         soft_trade = torch.tanh(self.trade(hidden))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\linear.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 114\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with \"squared period scaled RL\" elu softmax trade loss\n",
    "# with .2 trade penalty sqaure\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6391' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 6391/87883 28:57 < 6:09:26, 3.68 it/s, Epoch 0.07/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.368000</td>\n",
       "      <td>3.264107</td>\n",
       "      <td>0.1591</td>\n",
       "      <td>0.2225</td>\n",
       "      <td>21.1191</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>53.4984</td>\n",
       "      <td>1.0536</td>\n",
       "      <td>13.0324</td>\n",
       "      <td>52.4066</td>\n",
       "      <td>1.0653</td>\n",
       "      <td>30.2379</td>\n",
       "      <td>50.2186</td>\n",
       "      <td>1.036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.316400</td>\n",
       "      <td>3.242608</td>\n",
       "      <td>0.1210</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>26.6383</td>\n",
       "      <td>7.7692</td>\n",
       "      <td>50.3745</td>\n",
       "      <td>0.9777</td>\n",
       "      <td>17.1836</td>\n",
       "      <td>51.4233</td>\n",
       "      <td>1.0329</td>\n",
       "      <td>22.593</td>\n",
       "      <td>50.3099</td>\n",
       "      <td>1.0107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.292600</td>\n",
       "      <td>3.220262</td>\n",
       "      <td>0.2697</td>\n",
       "      <td>0.2870</td>\n",
       "      <td>28.4510</td>\n",
       "      <td>9.3687</td>\n",
       "      <td>54.9018</td>\n",
       "      <td>1.0368</td>\n",
       "      <td>18.6062</td>\n",
       "      <td>51.8067</td>\n",
       "      <td>1.0198</td>\n",
       "      <td>22.5717</td>\n",
       "      <td>50.48</td>\n",
       "      <td>0.9964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.283900</td>\n",
       "      <td>3.211118</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.2914</td>\n",
       "      <td>22.8199</td>\n",
       "      <td>7.4655</td>\n",
       "      <td>54.3096</td>\n",
       "      <td>1.0141</td>\n",
       "      <td>12.4279</td>\n",
       "      <td>52.3288</td>\n",
       "      <td>1.0021</td>\n",
       "      <td>18.2275</td>\n",
       "      <td>51.0212</td>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.276400</td>\n",
       "      <td>3.218227</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>27.3499</td>\n",
       "      <td>13.1411</td>\n",
       "      <td>53.0677</td>\n",
       "      <td>1.0095</td>\n",
       "      <td>12.7204</td>\n",
       "      <td>51.9490</td>\n",
       "      <td>1.0309</td>\n",
       "      <td>16.6424</td>\n",
       "      <td>51.9116</td>\n",
       "      <td>0.9914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.275600</td>\n",
       "      <td>3.242948</td>\n",
       "      <td>0.2721</td>\n",
       "      <td>0.247</td>\n",
       "      <td>31.7306</td>\n",
       "      <td>17.6079</td>\n",
       "      <td>53.7403</td>\n",
       "      <td>1.0231</td>\n",
       "      <td>13.8564</td>\n",
       "      <td>51.2977</td>\n",
       "      <td>0.9633</td>\n",
       "      <td>17.1249</td>\n",
       "      <td>50.6637</td>\n",
       "      <td>0.9667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4a4ab70cc034>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with \"squared period scaled RL\" elu softmax trade loss with .1 trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1800\u001b[0m                     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_grad_scaling\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1801\u001b[0m                         \u001b[0mscale_before\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1802\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1803\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1804\u001b[0m                         \u001b[0mscale_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stage\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    284\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 285\u001b[1;33m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    111\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\optimization.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    358\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m                 \u001b[1;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 360\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eps\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with \"squared period scaled RL\" elu softmax trade loss with .1 trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19304' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19304/87883 1:27:51 < 5:12:09, 3.66 it/s, Epoch 0.22/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.209400</td>\n",
       "      <td>3.082837</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.1880</td>\n",
       "      <td>13.4375</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.2265</td>\n",
       "      <td>53.2439</td>\n",
       "      <td>1.0351</td>\n",
       "      <td>21.2553</td>\n",
       "      <td>51.5651</td>\n",
       "      <td>1.0206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.147100</td>\n",
       "      <td>3.045227</td>\n",
       "      <td>-0.0041</td>\n",
       "      <td>-0.0208</td>\n",
       "      <td>6.5017</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>69.0226</td>\n",
       "      <td>1.2735</td>\n",
       "      <td>4.2116</td>\n",
       "      <td>51.0527</td>\n",
       "      <td>0.8605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.120200</td>\n",
       "      <td>3.038511</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.3577</td>\n",
       "      <td>4.0448</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>71.4286</td>\n",
       "      <td>2.0017</td>\n",
       "      <td>0.1949</td>\n",
       "      <td>60.2855</td>\n",
       "      <td>0.8924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.111200</td>\n",
       "      <td>3.037176</td>\n",
       "      <td>0.0343</td>\n",
       "      <td>0.2446</td>\n",
       "      <td>4.7747</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1889</td>\n",
       "      <td>66.8453</td>\n",
       "      <td>1.1065</td>\n",
       "      <td>0.897</td>\n",
       "      <td>63.0659</td>\n",
       "      <td>0.9857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.107200</td>\n",
       "      <td>3.038388</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>3.5726</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>77.9221</td>\n",
       "      <td>2.5915</td>\n",
       "      <td>0.1079</td>\n",
       "      <td>81.1254</td>\n",
       "      <td>1.0399</td>\n",
       "      <td>0.5687</td>\n",
       "      <td>65.1913</td>\n",
       "      <td>0.8142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.106800</td>\n",
       "      <td>3.065441</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.2094</td>\n",
       "      <td>5.1021</td>\n",
       "      <td>0.2191</td>\n",
       "      <td>69.1686</td>\n",
       "      <td>1.2359</td>\n",
       "      <td>0.7086</td>\n",
       "      <td>64.5127</td>\n",
       "      <td>0.8801</td>\n",
       "      <td>2.1478</td>\n",
       "      <td>56.119</td>\n",
       "      <td>0.7835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.099800</td>\n",
       "      <td>3.013932</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>4.8731</td>\n",
       "      <td>0.6832</td>\n",
       "      <td>62.5255</td>\n",
       "      <td>1.0219</td>\n",
       "      <td>1.1969</td>\n",
       "      <td>62.1222</td>\n",
       "      <td>0.8088</td>\n",
       "      <td>2.0923</td>\n",
       "      <td>55.7826</td>\n",
       "      <td>0.7445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.100600</td>\n",
       "      <td>3.040005</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>4.9585</td>\n",
       "      <td>1.1589</td>\n",
       "      <td>64.9858</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>1.0152</td>\n",
       "      <td>62.5592</td>\n",
       "      <td>0.8007</td>\n",
       "      <td>1.5743</td>\n",
       "      <td>54.7485</td>\n",
       "      <td>0.8091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.092600</td>\n",
       "      <td>3.057435</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1946</td>\n",
       "      <td>4.6551</td>\n",
       "      <td>0.5609</td>\n",
       "      <td>63.9603</td>\n",
       "      <td>0.8218</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>63.4022</td>\n",
       "      <td>0.7856</td>\n",
       "      <td>1.6664</td>\n",
       "      <td>58.2966</td>\n",
       "      <td>0.7489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.093300</td>\n",
       "      <td>3.013521</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.1432</td>\n",
       "      <td>5.2168</td>\n",
       "      <td>1.291</td>\n",
       "      <td>62.5514</td>\n",
       "      <td>0.8812</td>\n",
       "      <td>1.0600</td>\n",
       "      <td>62.7804</td>\n",
       "      <td>0.8226</td>\n",
       "      <td>2.1533</td>\n",
       "      <td>53.4101</td>\n",
       "      <td>0.8654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.080600</td>\n",
       "      <td>3.016708</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>5.0235</td>\n",
       "      <td>1.1244</td>\n",
       "      <td>63.708</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.8935</td>\n",
       "      <td>61.6506</td>\n",
       "      <td>0.7755</td>\n",
       "      <td>1.7510</td>\n",
       "      <td>53.8756</td>\n",
       "      <td>0.8148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>3.080100</td>\n",
       "      <td>3.042273</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.1613</td>\n",
       "      <td>8.1214</td>\n",
       "      <td>2.4683</td>\n",
       "      <td>62.6557</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>2.0465</td>\n",
       "      <td>55.8255</td>\n",
       "      <td>0.8389</td>\n",
       "      <td>3.983</td>\n",
       "      <td>50.6225</td>\n",
       "      <td>0.8435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>3.080100</td>\n",
       "      <td>3.019863</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.2998</td>\n",
       "      <td>4.2290</td>\n",
       "      <td>0.5026</td>\n",
       "      <td>61.1377</td>\n",
       "      <td>0.8317</td>\n",
       "      <td>0.6678</td>\n",
       "      <td>59.3673</td>\n",
       "      <td>0.8177</td>\n",
       "      <td>1.3149</td>\n",
       "      <td>59.8268</td>\n",
       "      <td>0.7664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>3.084500</td>\n",
       "      <td>3.014462</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.2763</td>\n",
       "      <td>3.8381</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>67.1304</td>\n",
       "      <td>0.9523</td>\n",
       "      <td>0.8184</td>\n",
       "      <td>65.7496</td>\n",
       "      <td>0.839</td>\n",
       "      <td>0.9925</td>\n",
       "      <td>57.9276</td>\n",
       "      <td>0.8194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>3.084600</td>\n",
       "      <td>3.024405</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.2003</td>\n",
       "      <td>3.5749</td>\n",
       "      <td>0.3921</td>\n",
       "      <td>69.0645</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>0.4358</td>\n",
       "      <td>60.2322</td>\n",
       "      <td>0.7386</td>\n",
       "      <td>0.8521</td>\n",
       "      <td>54.5724</td>\n",
       "      <td>0.7456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>3.072800</td>\n",
       "      <td>3.021866</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.2941</td>\n",
       "      <td>4.8395</td>\n",
       "      <td>1.4605</td>\n",
       "      <td>67.2267</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>59.7611</td>\n",
       "      <td>0.8088</td>\n",
       "      <td>1.174</td>\n",
       "      <td>54.3153</td>\n",
       "      <td>0.7799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>3.076000</td>\n",
       "      <td>3.027513</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.203</td>\n",
       "      <td>5.9508</td>\n",
       "      <td>2.3888</td>\n",
       "      <td>63.7225</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>1.4065</td>\n",
       "      <td>57.5232</td>\n",
       "      <td>0.7733</td>\n",
       "      <td>1.9199</td>\n",
       "      <td>53.3931</td>\n",
       "      <td>0.8004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>3.081300</td>\n",
       "      <td>3.027431</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>0.1228</td>\n",
       "      <td>7.8476</td>\n",
       "      <td>3.2612</td>\n",
       "      <td>59.4678</td>\n",
       "      <td>0.7997</td>\n",
       "      <td>2.4466</td>\n",
       "      <td>55.258</td>\n",
       "      <td>0.8394</td>\n",
       "      <td>3.2849</td>\n",
       "      <td>52.6281</td>\n",
       "      <td>0.8479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>3.071900</td>\n",
       "      <td>3.018674</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.2758</td>\n",
       "      <td>5.6967</td>\n",
       "      <td>1.9622</td>\n",
       "      <td>62.3195</td>\n",
       "      <td>0.8041</td>\n",
       "      <td>1.2439</td>\n",
       "      <td>57.7283</td>\n",
       "      <td>0.768</td>\n",
       "      <td>1.7097</td>\n",
       "      <td>55.1125</td>\n",
       "      <td>0.8288</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ecbbe74bf0d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with \"period scaled RL\" elu softmax trade loss with .1 trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with \"period scaled RL\" elu softmax trade loss with .1 trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4176' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4176/87883 18:54 < 6:19:14, 3.68 it/s, Epoch 0.05/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.193900</td>\n",
       "      <td>3.064785</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>49.285</td>\n",
       "      <td>26.2809</td>\n",
       "      <td>51.0801</td>\n",
       "      <td>1.0439</td>\n",
       "      <td>37.7578</td>\n",
       "      <td>50.0881</td>\n",
       "      <td>1.0298</td>\n",
       "      <td>18.8477</td>\n",
       "      <td>49.8570</td>\n",
       "      <td>0.9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.130800</td>\n",
       "      <td>3.038849</td>\n",
       "      <td>0.3404</td>\n",
       "      <td>0.1839</td>\n",
       "      <td>74.1110</td>\n",
       "      <td>69.6529</td>\n",
       "      <td>50.6772</td>\n",
       "      <td>1.0234</td>\n",
       "      <td>17.6376</td>\n",
       "      <td>49.1953</td>\n",
       "      <td>1.0313</td>\n",
       "      <td>6.8397</td>\n",
       "      <td>49.1659</td>\n",
       "      <td>1.0197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.102900</td>\n",
       "      <td>3.025126</td>\n",
       "      <td>0.362</td>\n",
       "      <td>0.2439</td>\n",
       "      <td>76.5785</td>\n",
       "      <td>71.6191</td>\n",
       "      <td>51.2964</td>\n",
       "      <td>1.0095</td>\n",
       "      <td>14.8262</td>\n",
       "      <td>49.0683</td>\n",
       "      <td>1.0163</td>\n",
       "      <td>7.0837</td>\n",
       "      <td>48.6134</td>\n",
       "      <td>0.9979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.093200</td>\n",
       "      <td>3.017827</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.2612</td>\n",
       "      <td>80.7614</td>\n",
       "      <td>77.1439</td>\n",
       "      <td>51.111</td>\n",
       "      <td>0.9929</td>\n",
       "      <td>11.8992</td>\n",
       "      <td>49.6109</td>\n",
       "      <td>1.0018</td>\n",
       "      <td>5.7057</td>\n",
       "      <td>48.8195</td>\n",
       "      <td>0.9942</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-cfd47f9bb9f1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with \"period scaled RL\" elu softmax trade loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1802\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1803\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1804\u001b[1;33m                         \u001b[0mscale_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1805\u001b[0m                         \u001b[0moptimizer_was_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale_before\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mscale_after\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1806\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mget_scale\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \"\"\"\n\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_scale\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scale\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_scale_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with \"period scaled RL\" elu softmax trade loss\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4376' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 4376/87883 20:12 < 6:25:53, 3.61 it/s, Epoch 0.05/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.193600</td>\n",
       "      <td>3.067668</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>63.0429</td>\n",
       "      <td>51.2587</td>\n",
       "      <td>50.8248</td>\n",
       "      <td>1.0350</td>\n",
       "      <td>24.6811</td>\n",
       "      <td>49.9731</td>\n",
       "      <td>1.0228</td>\n",
       "      <td>12.5352</td>\n",
       "      <td>49.5388</td>\n",
       "      <td>1.0253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.128900</td>\n",
       "      <td>3.037128</td>\n",
       "      <td>0.3783</td>\n",
       "      <td>0.1946</td>\n",
       "      <td>81.8872</td>\n",
       "      <td>78.3256</td>\n",
       "      <td>50.6696</td>\n",
       "      <td>1.0251</td>\n",
       "      <td>11.5643</td>\n",
       "      <td>48.7448</td>\n",
       "      <td>1.0271</td>\n",
       "      <td>5.3543</td>\n",
       "      <td>47.9104</td>\n",
       "      <td>1.0164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.100500</td>\n",
       "      <td>3.023889</td>\n",
       "      <td>0.3389</td>\n",
       "      <td>0.2228</td>\n",
       "      <td>80.5289</td>\n",
       "      <td>75.6156</td>\n",
       "      <td>51.0173</td>\n",
       "      <td>1.0070</td>\n",
       "      <td>12.6002</td>\n",
       "      <td>48.6899</td>\n",
       "      <td>1.0131</td>\n",
       "      <td>6.1787</td>\n",
       "      <td>48.3765</td>\n",
       "      <td>1.0227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.091500</td>\n",
       "      <td>3.016654</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.2613</td>\n",
       "      <td>82.7889</td>\n",
       "      <td>78.6281</td>\n",
       "      <td>51.0763</td>\n",
       "      <td>0.9974</td>\n",
       "      <td>10.9847</td>\n",
       "      <td>49.8946</td>\n",
       "      <td>0.9877</td>\n",
       "      <td>5.4422</td>\n",
       "      <td>49.4143</td>\n",
       "      <td>1.0116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-70afd2c4505a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with \"period scaled RL\" tanh trade loss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with \"period scaled RL\" tanh trade loss\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='87883' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [87883/87883 6:33:11, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.204700</td>\n",
       "      <td>2.965885</td>\n",
       "      <td>0.1548</td>\n",
       "      <td>0.2841</td>\n",
       "      <td>17.5812</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>62.8341</td>\n",
       "      <td>1.2366</td>\n",
       "      <td>8.3469</td>\n",
       "      <td>52.1679</td>\n",
       "      <td>1.0543</td>\n",
       "      <td>24.7519</td>\n",
       "      <td>51.1118</td>\n",
       "      <td>1.0467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.048000</td>\n",
       "      <td>2.878618</td>\n",
       "      <td>0.1519</td>\n",
       "      <td>0.2383</td>\n",
       "      <td>15.5162</td>\n",
       "      <td>2.0623</td>\n",
       "      <td>56.0599</td>\n",
       "      <td>1.2438</td>\n",
       "      <td>7.3931</td>\n",
       "      <td>50.6510</td>\n",
       "      <td>0.9716</td>\n",
       "      <td>15.2629</td>\n",
       "      <td>51.0782</td>\n",
       "      <td>1.018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.919600</td>\n",
       "      <td>2.732516</td>\n",
       "      <td>0.2787</td>\n",
       "      <td>0.3608</td>\n",
       "      <td>20.0982</td>\n",
       "      <td>11.481</td>\n",
       "      <td>52.9670</td>\n",
       "      <td>1.1071</td>\n",
       "      <td>4.6547</td>\n",
       "      <td>51.5245</td>\n",
       "      <td>1.0904</td>\n",
       "      <td>8.2128</td>\n",
       "      <td>50.9018</td>\n",
       "      <td>0.9565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.905900</td>\n",
       "      <td>2.645647</td>\n",
       "      <td>0.2061</td>\n",
       "      <td>0.4080</td>\n",
       "      <td>13.8305</td>\n",
       "      <td>7.3240</td>\n",
       "      <td>53.1079</td>\n",
       "      <td>1.1047</td>\n",
       "      <td>3.3834</td>\n",
       "      <td>55.3574</td>\n",
       "      <td>1.0505</td>\n",
       "      <td>5.8755</td>\n",
       "      <td>50.9397</td>\n",
       "      <td>1.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.897000</td>\n",
       "      <td>3.200021</td>\n",
       "      <td>0.1981</td>\n",
       "      <td>0.1335</td>\n",
       "      <td>42.7592</td>\n",
       "      <td>34.7700</td>\n",
       "      <td>51.4141</td>\n",
       "      <td>0.9559</td>\n",
       "      <td>8.3755</td>\n",
       "      <td>51.4325</td>\n",
       "      <td>1.0601</td>\n",
       "      <td>9.4834</td>\n",
       "      <td>50.7149</td>\n",
       "      <td>1.0817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.821100</td>\n",
       "      <td>2.791667</td>\n",
       "      <td>0.3181</td>\n",
       "      <td>0.4223</td>\n",
       "      <td>27.8906</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>52.0778</td>\n",
       "      <td>1.1031</td>\n",
       "      <td>2.7486</td>\n",
       "      <td>52.9431</td>\n",
       "      <td>1.0472</td>\n",
       "      <td>3.7672</td>\n",
       "      <td>50.7824</td>\n",
       "      <td>0.9533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.773400</td>\n",
       "      <td>2.686381</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.1655</td>\n",
       "      <td>17.1745</td>\n",
       "      <td>12.5731</td>\n",
       "      <td>48.3813</td>\n",
       "      <td>0.9389</td>\n",
       "      <td>2.3134</td>\n",
       "      <td>53.6333</td>\n",
       "      <td>0.9244</td>\n",
       "      <td>3.7442</td>\n",
       "      <td>51.7432</td>\n",
       "      <td>0.9219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.820600</td>\n",
       "      <td>2.825948</td>\n",
       "      <td>0.2041</td>\n",
       "      <td>0.205</td>\n",
       "      <td>28.833</td>\n",
       "      <td>22.3798</td>\n",
       "      <td>49.8937</td>\n",
       "      <td>0.9809</td>\n",
       "      <td>5.0829</td>\n",
       "      <td>53.5226</td>\n",
       "      <td>1.0363</td>\n",
       "      <td>7.2581</td>\n",
       "      <td>52.8808</td>\n",
       "      <td>1.0217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.764000</td>\n",
       "      <td>3.001836</td>\n",
       "      <td>0.1574</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>32.3675</td>\n",
       "      <td>26.0906</td>\n",
       "      <td>50.9711</td>\n",
       "      <td>0.954</td>\n",
       "      <td>5.3772</td>\n",
       "      <td>50.5599</td>\n",
       "      <td>1.0699</td>\n",
       "      <td>6.9233</td>\n",
       "      <td>50.8267</td>\n",
       "      <td>1.0757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.750200</td>\n",
       "      <td>2.712169</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.1736</td>\n",
       "      <td>19.4213</td>\n",
       "      <td>15.1381</td>\n",
       "      <td>51.4840</td>\n",
       "      <td>0.9077</td>\n",
       "      <td>2.6016</td>\n",
       "      <td>53.0072</td>\n",
       "      <td>0.9427</td>\n",
       "      <td>3.7595</td>\n",
       "      <td>52.9659</td>\n",
       "      <td>0.9604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.730800</td>\n",
       "      <td>2.611049</td>\n",
       "      <td>0.241</td>\n",
       "      <td>0.389</td>\n",
       "      <td>20.5796</td>\n",
       "      <td>17.3915</td>\n",
       "      <td>51.6576</td>\n",
       "      <td>1.0668</td>\n",
       "      <td>2.0869</td>\n",
       "      <td>53.7883</td>\n",
       "      <td>1.0251</td>\n",
       "      <td>2.5722</td>\n",
       "      <td>52.2154</td>\n",
       "      <td>1.0535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.654100</td>\n",
       "      <td>3.010829</td>\n",
       "      <td>0.1701</td>\n",
       "      <td>0.14</td>\n",
       "      <td>35.0835</td>\n",
       "      <td>30.8096</td>\n",
       "      <td>50.4721</td>\n",
       "      <td>0.9654</td>\n",
       "      <td>3.4565</td>\n",
       "      <td>51.5553</td>\n",
       "      <td>1.0433</td>\n",
       "      <td>4.5532</td>\n",
       "      <td>51.7919</td>\n",
       "      <td>1.0755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.680200</td>\n",
       "      <td>2.690825</td>\n",
       "      <td>0.1834</td>\n",
       "      <td>0.2886</td>\n",
       "      <td>25.9225</td>\n",
       "      <td>21.9009</td>\n",
       "      <td>50.1606</td>\n",
       "      <td>1.0050</td>\n",
       "      <td>2.7650</td>\n",
       "      <td>52.4681</td>\n",
       "      <td>0.9686</td>\n",
       "      <td>3.7556</td>\n",
       "      <td>52.2297</td>\n",
       "      <td>1.0087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.747100</td>\n",
       "      <td>2.722267</td>\n",
       "      <td>0.1666</td>\n",
       "      <td>0.2588</td>\n",
       "      <td>27.0137</td>\n",
       "      <td>23.4999</td>\n",
       "      <td>51.0935</td>\n",
       "      <td>0.9643</td>\n",
       "      <td>2.5729</td>\n",
       "      <td>52.8269</td>\n",
       "      <td>0.9733</td>\n",
       "      <td>3.121</td>\n",
       "      <td>50.9504</td>\n",
       "      <td>0.9839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.718500</td>\n",
       "      <td>2.623040</td>\n",
       "      <td>0.1380</td>\n",
       "      <td>0.4937</td>\n",
       "      <td>14.9766</td>\n",
       "      <td>11.6645</td>\n",
       "      <td>51.0806</td>\n",
       "      <td>1.0207</td>\n",
       "      <td>1.5431</td>\n",
       "      <td>51.6026</td>\n",
       "      <td>1.0654</td>\n",
       "      <td>1.8373</td>\n",
       "      <td>53.3907</td>\n",
       "      <td>1.0417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.643300</td>\n",
       "      <td>2.744661</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>26.9895</td>\n",
       "      <td>24.0755</td>\n",
       "      <td>50.2183</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>2.3539</td>\n",
       "      <td>51.2709</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>2.8179</td>\n",
       "      <td>50.6487</td>\n",
       "      <td>0.9919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.645400</td>\n",
       "      <td>2.653019</td>\n",
       "      <td>0.1757</td>\n",
       "      <td>0.25</td>\n",
       "      <td>26.8576</td>\n",
       "      <td>24.2367</td>\n",
       "      <td>51.4499</td>\n",
       "      <td>0.9489</td>\n",
       "      <td>2.1554</td>\n",
       "      <td>54.5599</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>2.4679</td>\n",
       "      <td>53.2752</td>\n",
       "      <td>1.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.696500</td>\n",
       "      <td>2.700664</td>\n",
       "      <td>0.1338</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>23.6693</td>\n",
       "      <td>20.3818</td>\n",
       "      <td>51.3027</td>\n",
       "      <td>0.9189</td>\n",
       "      <td>2.2884</td>\n",
       "      <td>52.7002</td>\n",
       "      <td>0.9481</td>\n",
       "      <td>2.8683</td>\n",
       "      <td>51.5258</td>\n",
       "      <td>1.0309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.679100</td>\n",
       "      <td>2.590946</td>\n",
       "      <td>0.172</td>\n",
       "      <td>0.3179</td>\n",
       "      <td>19.3715</td>\n",
       "      <td>16.7806</td>\n",
       "      <td>51.012</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>1.7833</td>\n",
       "      <td>54.4262</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>2.3115</td>\n",
       "      <td>53.1903</td>\n",
       "      <td>0.9790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.657500</td>\n",
       "      <td>2.597267</td>\n",
       "      <td>0.2677</td>\n",
       "      <td>0.3782</td>\n",
       "      <td>27.7872</td>\n",
       "      <td>24.795</td>\n",
       "      <td>52.0062</td>\n",
       "      <td>1.0124</td>\n",
       "      <td>2.0034</td>\n",
       "      <td>53.8515</td>\n",
       "      <td>1.0036</td>\n",
       "      <td>2.5923</td>\n",
       "      <td>53.5864</td>\n",
       "      <td>1.0258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.694900</td>\n",
       "      <td>2.613653</td>\n",
       "      <td>0.2936</td>\n",
       "      <td>0.4135</td>\n",
       "      <td>26.7087</td>\n",
       "      <td>23.0244</td>\n",
       "      <td>52.2124</td>\n",
       "      <td>1.0316</td>\n",
       "      <td>2.6610</td>\n",
       "      <td>54.3281</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>3.4493</td>\n",
       "      <td>52.3488</td>\n",
       "      <td>1.0104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>2.657300</td>\n",
       "      <td>2.561768</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>0.5254</td>\n",
       "      <td>25.9756</td>\n",
       "      <td>23.3545</td>\n",
       "      <td>52.2735</td>\n",
       "      <td>1.0446</td>\n",
       "      <td>2.0585</td>\n",
       "      <td>53.0294</td>\n",
       "      <td>1.0345</td>\n",
       "      <td>2.4555</td>\n",
       "      <td>52.6324</td>\n",
       "      <td>1.0772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>2.626200</td>\n",
       "      <td>2.588413</td>\n",
       "      <td>0.2224</td>\n",
       "      <td>0.3745</td>\n",
       "      <td>23.5395</td>\n",
       "      <td>20.7974</td>\n",
       "      <td>51.981</td>\n",
       "      <td>1.0005</td>\n",
       "      <td>2.0397</td>\n",
       "      <td>52.1736</td>\n",
       "      <td>0.9785</td>\n",
       "      <td>2.3251</td>\n",
       "      <td>51.7436</td>\n",
       "      <td>0.9964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>2.663700</td>\n",
       "      <td>2.631225</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>0.3283</td>\n",
       "      <td>19.6888</td>\n",
       "      <td>16.7354</td>\n",
       "      <td>50.4070</td>\n",
       "      <td>0.9796</td>\n",
       "      <td>1.9562</td>\n",
       "      <td>52.1177</td>\n",
       "      <td>0.9848</td>\n",
       "      <td>2.4158</td>\n",
       "      <td>52.1573</td>\n",
       "      <td>0.9401</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>2.653500</td>\n",
       "      <td>2.698042</td>\n",
       "      <td>0.1498</td>\n",
       "      <td>0.2866</td>\n",
       "      <td>24.5825</td>\n",
       "      <td>21.6192</td>\n",
       "      <td>51.6362</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>2.0322</td>\n",
       "      <td>51.6245</td>\n",
       "      <td>0.9386</td>\n",
       "      <td>2.4787</td>\n",
       "      <td>50.9441</td>\n",
       "      <td>0.9307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>2.644100</td>\n",
       "      <td>2.710591</td>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.1425</td>\n",
       "      <td>20.0914</td>\n",
       "      <td>17.4139</td>\n",
       "      <td>50.4972</td>\n",
       "      <td>0.9482</td>\n",
       "      <td>2.0317</td>\n",
       "      <td>51.0584</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>2.563</td>\n",
       "      <td>51.8063</td>\n",
       "      <td>0.9971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>2.638800</td>\n",
       "      <td>2.886166</td>\n",
       "      <td>0.1916</td>\n",
       "      <td>0.1749</td>\n",
       "      <td>35.128</td>\n",
       "      <td>31.9967</td>\n",
       "      <td>51.1142</td>\n",
       "      <td>0.9645</td>\n",
       "      <td>2.7502</td>\n",
       "      <td>52.0329</td>\n",
       "      <td>0.9627</td>\n",
       "      <td>3.3731</td>\n",
       "      <td>51.3200</td>\n",
       "      <td>1.0176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>2.669000</td>\n",
       "      <td>2.556612</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.4308</td>\n",
       "      <td>16.8003</td>\n",
       "      <td>14.3367</td>\n",
       "      <td>51.6552</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>1.7782</td>\n",
       "      <td>52.7031</td>\n",
       "      <td>0.9957</td>\n",
       "      <td>2.3619</td>\n",
       "      <td>52.4904</td>\n",
       "      <td>0.9123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>2.617200</td>\n",
       "      <td>2.571460</td>\n",
       "      <td>0.3228</td>\n",
       "      <td>0.456</td>\n",
       "      <td>28.8314</td>\n",
       "      <td>26.2105</td>\n",
       "      <td>52.7875</td>\n",
       "      <td>1.0268</td>\n",
       "      <td>2.1852</td>\n",
       "      <td>51.7279</td>\n",
       "      <td>0.9756</td>\n",
       "      <td>2.6023</td>\n",
       "      <td>51.2954</td>\n",
       "      <td>1.0204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>2.652300</td>\n",
       "      <td>2.704922</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>0.2323</td>\n",
       "      <td>25.4196</td>\n",
       "      <td>22.4852</td>\n",
       "      <td>50.9448</td>\n",
       "      <td>0.9823</td>\n",
       "      <td>2.3461</td>\n",
       "      <td>52.6392</td>\n",
       "      <td>0.9675</td>\n",
       "      <td>2.9583</td>\n",
       "      <td>52.1315</td>\n",
       "      <td>0.9371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>2.625300</td>\n",
       "      <td>2.674834</td>\n",
       "      <td>0.2541</td>\n",
       "      <td>0.2954</td>\n",
       "      <td>27.4515</td>\n",
       "      <td>24.3148</td>\n",
       "      <td>51.4985</td>\n",
       "      <td>1.0093</td>\n",
       "      <td>2.6915</td>\n",
       "      <td>52.2606</td>\n",
       "      <td>1.0014</td>\n",
       "      <td>3.2691</td>\n",
       "      <td>51.9656</td>\n",
       "      <td>0.9862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>2.599200</td>\n",
       "      <td>2.860470</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>32.2085</td>\n",
       "      <td>28.6623</td>\n",
       "      <td>51.5020</td>\n",
       "      <td>0.9825</td>\n",
       "      <td>3.1012</td>\n",
       "      <td>51.2665</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>3.8923</td>\n",
       "      <td>50.9376</td>\n",
       "      <td>1.0060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>2.592000</td>\n",
       "      <td>2.612188</td>\n",
       "      <td>0.2657</td>\n",
       "      <td>0.3494</td>\n",
       "      <td>26.0452</td>\n",
       "      <td>23.3918</td>\n",
       "      <td>52.0706</td>\n",
       "      <td>1.0035</td>\n",
       "      <td>2.2245</td>\n",
       "      <td>51.8367</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>2.7813</td>\n",
       "      <td>52.0466</td>\n",
       "      <td>0.9810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>2.576800</td>\n",
       "      <td>2.661168</td>\n",
       "      <td>0.3219</td>\n",
       "      <td>0.3464</td>\n",
       "      <td>27.0014</td>\n",
       "      <td>24.3725</td>\n",
       "      <td>52.7894</td>\n",
       "      <td>1.0272</td>\n",
       "      <td>2.2248</td>\n",
       "      <td>51.5465</td>\n",
       "      <td>0.9969</td>\n",
       "      <td>2.7093</td>\n",
       "      <td>51.6971</td>\n",
       "      <td>1.0102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>2.685100</td>\n",
       "      <td>2.819467</td>\n",
       "      <td>0.2299</td>\n",
       "      <td>0.2062</td>\n",
       "      <td>33.0414</td>\n",
       "      <td>29.9374</td>\n",
       "      <td>51.1241</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>2.7303</td>\n",
       "      <td>52.6894</td>\n",
       "      <td>1.0403</td>\n",
       "      <td>3.3742</td>\n",
       "      <td>52.2024</td>\n",
       "      <td>1.0214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>2.644500</td>\n",
       "      <td>2.956750</td>\n",
       "      <td>0.1436</td>\n",
       "      <td>0.1198</td>\n",
       "      <td>35.1227</td>\n",
       "      <td>32.2029</td>\n",
       "      <td>50.9468</td>\n",
       "      <td>0.9427</td>\n",
       "      <td>2.5533</td>\n",
       "      <td>50.6465</td>\n",
       "      <td>1.0479</td>\n",
       "      <td>3.0841</td>\n",
       "      <td>50.9146</td>\n",
       "      <td>1.0828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>2.633000</td>\n",
       "      <td>2.582810</td>\n",
       "      <td>0.3292</td>\n",
       "      <td>0.3862</td>\n",
       "      <td>24.3475</td>\n",
       "      <td>21.3942</td>\n",
       "      <td>52.3419</td>\n",
       "      <td>1.0641</td>\n",
       "      <td>2.2373</td>\n",
       "      <td>53.2199</td>\n",
       "      <td>1.0028</td>\n",
       "      <td>2.8423</td>\n",
       "      <td>53.2710</td>\n",
       "      <td>1.0038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>2.621200</td>\n",
       "      <td>2.730464</td>\n",
       "      <td>0.1877</td>\n",
       "      <td>0.1968</td>\n",
       "      <td>26.0910</td>\n",
       "      <td>22.9866</td>\n",
       "      <td>51.1592</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>2.2473</td>\n",
       "      <td>51.5366</td>\n",
       "      <td>0.951</td>\n",
       "      <td>2.923</td>\n",
       "      <td>51.6358</td>\n",
       "      <td>0.9946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>2.579100</td>\n",
       "      <td>2.608117</td>\n",
       "      <td>0.2953</td>\n",
       "      <td>0.2934</td>\n",
       "      <td>27.37</td>\n",
       "      <td>24.4974</td>\n",
       "      <td>52.3858</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>2.5445</td>\n",
       "      <td>52.0382</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>3.0963</td>\n",
       "      <td>50.3064</td>\n",
       "      <td>0.9732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>2.621200</td>\n",
       "      <td>2.725726</td>\n",
       "      <td>0.3161</td>\n",
       "      <td>0.2952</td>\n",
       "      <td>32.5366</td>\n",
       "      <td>29.2035</td>\n",
       "      <td>52.1018</td>\n",
       "      <td>0.9966</td>\n",
       "      <td>3.0237</td>\n",
       "      <td>52.2465</td>\n",
       "      <td>1.0114</td>\n",
       "      <td>3.6558</td>\n",
       "      <td>51.7595</td>\n",
       "      <td>1.0246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>2.581600</td>\n",
       "      <td>2.527718</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.4239</td>\n",
       "      <td>25.9685</td>\n",
       "      <td>23.3106</td>\n",
       "      <td>52.9509</td>\n",
       "      <td>1.0467</td>\n",
       "      <td>2.2351</td>\n",
       "      <td>53.8314</td>\n",
       "      <td>1.0025</td>\n",
       "      <td>2.8043</td>\n",
       "      <td>53.1484</td>\n",
       "      <td>0.9603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>2.587500</td>\n",
       "      <td>2.588955</td>\n",
       "      <td>0.3616</td>\n",
       "      <td>0.3759</td>\n",
       "      <td>31.2373</td>\n",
       "      <td>28.1756</td>\n",
       "      <td>52.5516</td>\n",
       "      <td>1.0192</td>\n",
       "      <td>2.6241</td>\n",
       "      <td>51.5739</td>\n",
       "      <td>1.0049</td>\n",
       "      <td>3.2948</td>\n",
       "      <td>52.3630</td>\n",
       "      <td>0.9816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>2.608500</td>\n",
       "      <td>2.571924</td>\n",
       "      <td>0.2001</td>\n",
       "      <td>0.2863</td>\n",
       "      <td>21.4845</td>\n",
       "      <td>19.0369</td>\n",
       "      <td>51.5675</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>2.0415</td>\n",
       "      <td>51.9673</td>\n",
       "      <td>0.9519</td>\n",
       "      <td>2.5501</td>\n",
       "      <td>52.8671</td>\n",
       "      <td>0.9769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44000</td>\n",
       "      <td>2.627800</td>\n",
       "      <td>2.549681</td>\n",
       "      <td>0.3554</td>\n",
       "      <td>0.4145</td>\n",
       "      <td>27.9145</td>\n",
       "      <td>25.0558</td>\n",
       "      <td>52.6169</td>\n",
       "      <td>1.0313</td>\n",
       "      <td>2.6122</td>\n",
       "      <td>52.5447</td>\n",
       "      <td>1.0131</td>\n",
       "      <td>3.0518</td>\n",
       "      <td>52.9636</td>\n",
       "      <td>1.0218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45000</td>\n",
       "      <td>2.599700</td>\n",
       "      <td>2.546716</td>\n",
       "      <td>0.4003</td>\n",
       "      <td>0.3948</td>\n",
       "      <td>28.3770</td>\n",
       "      <td>25.5968</td>\n",
       "      <td>52.5317</td>\n",
       "      <td>1.0574</td>\n",
       "      <td>2.2724</td>\n",
       "      <td>51.3276</td>\n",
       "      <td>1.0211</td>\n",
       "      <td>2.8432</td>\n",
       "      <td>51.6572</td>\n",
       "      <td>1.0065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46000</td>\n",
       "      <td>2.640200</td>\n",
       "      <td>2.580394</td>\n",
       "      <td>0.3245</td>\n",
       "      <td>0.3287</td>\n",
       "      <td>24.5760</td>\n",
       "      <td>21.5007</td>\n",
       "      <td>52.5009</td>\n",
       "      <td>1.0186</td>\n",
       "      <td>2.4188</td>\n",
       "      <td>51.8879</td>\n",
       "      <td>1.0198</td>\n",
       "      <td>3.0997</td>\n",
       "      <td>51.818</td>\n",
       "      <td>1.0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47000</td>\n",
       "      <td>2.576000</td>\n",
       "      <td>2.540564</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.3298</td>\n",
       "      <td>20.9608</td>\n",
       "      <td>18.4793</td>\n",
       "      <td>51.5662</td>\n",
       "      <td>1.0315</td>\n",
       "      <td>1.641</td>\n",
       "      <td>53.5188</td>\n",
       "      <td>1.0546</td>\n",
       "      <td>2.0580</td>\n",
       "      <td>53.0854</td>\n",
       "      <td>1.0864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48000</td>\n",
       "      <td>2.595200</td>\n",
       "      <td>2.536397</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.3499</td>\n",
       "      <td>18.2720</td>\n",
       "      <td>16.0657</td>\n",
       "      <td>52.1932</td>\n",
       "      <td>1.0034</td>\n",
       "      <td>1.7078</td>\n",
       "      <td>52.2776</td>\n",
       "      <td>0.9669</td>\n",
       "      <td>2.2536</td>\n",
       "      <td>52.2115</td>\n",
       "      <td>1.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49000</td>\n",
       "      <td>2.577700</td>\n",
       "      <td>2.533137</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.3658</td>\n",
       "      <td>22.1748</td>\n",
       "      <td>19.5015</td>\n",
       "      <td>52.0468</td>\n",
       "      <td>1.0381</td>\n",
       "      <td>2.2791</td>\n",
       "      <td>53.4466</td>\n",
       "      <td>1.0023</td>\n",
       "      <td>2.878</td>\n",
       "      <td>53.0854</td>\n",
       "      <td>1.0534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50000</td>\n",
       "      <td>2.543600</td>\n",
       "      <td>2.679728</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>21.5091</td>\n",
       "      <td>19.3618</td>\n",
       "      <td>51.4154</td>\n",
       "      <td>0.933</td>\n",
       "      <td>1.8030</td>\n",
       "      <td>50.7296</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>2.2387</td>\n",
       "      <td>50.2995</td>\n",
       "      <td>0.9882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51000</td>\n",
       "      <td>2.568600</td>\n",
       "      <td>2.592918</td>\n",
       "      <td>0.3500</td>\n",
       "      <td>0.351</td>\n",
       "      <td>27.8040</td>\n",
       "      <td>25.0842</td>\n",
       "      <td>52.3317</td>\n",
       "      <td>1.0255</td>\n",
       "      <td>2.446</td>\n",
       "      <td>52.4745</td>\n",
       "      <td>1.0177</td>\n",
       "      <td>2.9401</td>\n",
       "      <td>51.9038</td>\n",
       "      <td>1.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52000</td>\n",
       "      <td>2.613800</td>\n",
       "      <td>2.652657</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>0.2141</td>\n",
       "      <td>20.9215</td>\n",
       "      <td>18.5178</td>\n",
       "      <td>51.5588</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>1.9825</td>\n",
       "      <td>51.9939</td>\n",
       "      <td>1.0823</td>\n",
       "      <td>2.551</td>\n",
       "      <td>52.2487</td>\n",
       "      <td>1.0367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53000</td>\n",
       "      <td>2.583900</td>\n",
       "      <td>2.566105</td>\n",
       "      <td>0.4185</td>\n",
       "      <td>0.3972</td>\n",
       "      <td>28.7002</td>\n",
       "      <td>25.7224</td>\n",
       "      <td>52.2997</td>\n",
       "      <td>1.0703</td>\n",
       "      <td>2.4946</td>\n",
       "      <td>52.6089</td>\n",
       "      <td>1.0272</td>\n",
       "      <td>3.1062</td>\n",
       "      <td>52.3212</td>\n",
       "      <td>0.9734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54000</td>\n",
       "      <td>2.553300</td>\n",
       "      <td>2.575952</td>\n",
       "      <td>0.2689</td>\n",
       "      <td>0.3811</td>\n",
       "      <td>23.7072</td>\n",
       "      <td>21.3549</td>\n",
       "      <td>51.6618</td>\n",
       "      <td>1.0319</td>\n",
       "      <td>2.0392</td>\n",
       "      <td>52.4719</td>\n",
       "      <td>1.0854</td>\n",
       "      <td>2.4733</td>\n",
       "      <td>53.153</td>\n",
       "      <td>1.0478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55000</td>\n",
       "      <td>2.581600</td>\n",
       "      <td>2.541865</td>\n",
       "      <td>0.2293</td>\n",
       "      <td>0.3352</td>\n",
       "      <td>19.5606</td>\n",
       "      <td>17.2192</td>\n",
       "      <td>52.2905</td>\n",
       "      <td>0.9894</td>\n",
       "      <td>1.8852</td>\n",
       "      <td>52.6906</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>2.4145</td>\n",
       "      <td>53.2481</td>\n",
       "      <td>0.9921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56000</td>\n",
       "      <td>2.539900</td>\n",
       "      <td>2.626608</td>\n",
       "      <td>0.3429</td>\n",
       "      <td>0.3257</td>\n",
       "      <td>31.1258</td>\n",
       "      <td>28.4097</td>\n",
       "      <td>52.1848</td>\n",
       "      <td>1.0014</td>\n",
       "      <td>2.4949</td>\n",
       "      <td>51.5362</td>\n",
       "      <td>1.0323</td>\n",
       "      <td>3.0137</td>\n",
       "      <td>51.1857</td>\n",
       "      <td>1.0467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57000</td>\n",
       "      <td>2.588500</td>\n",
       "      <td>2.631548</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>24.7125</td>\n",
       "      <td>22.2444</td>\n",
       "      <td>51.7591</td>\n",
       "      <td>0.9836</td>\n",
       "      <td>2.0754</td>\n",
       "      <td>51.6487</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>2.6014</td>\n",
       "      <td>51.3274</td>\n",
       "      <td>1.0122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58000</td>\n",
       "      <td>2.563300</td>\n",
       "      <td>2.487612</td>\n",
       "      <td>0.3401</td>\n",
       "      <td>0.3757</td>\n",
       "      <td>24.8949</td>\n",
       "      <td>22.4227</td>\n",
       "      <td>52.8339</td>\n",
       "      <td>1.0094</td>\n",
       "      <td>2.0539</td>\n",
       "      <td>52.0663</td>\n",
       "      <td>0.9177</td>\n",
       "      <td>2.5578</td>\n",
       "      <td>51.5059</td>\n",
       "      <td>0.9713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59000</td>\n",
       "      <td>2.548500</td>\n",
       "      <td>2.607841</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>0.2616</td>\n",
       "      <td>25.1996</td>\n",
       "      <td>22.7912</td>\n",
       "      <td>51.6384</td>\n",
       "      <td>0.9598</td>\n",
       "      <td>2.1637</td>\n",
       "      <td>52.7624</td>\n",
       "      <td>0.9710</td>\n",
       "      <td>2.6737</td>\n",
       "      <td>51.8380</td>\n",
       "      <td>0.9398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60000</td>\n",
       "      <td>2.523600</td>\n",
       "      <td>2.652594</td>\n",
       "      <td>0.2237</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>26.1123</td>\n",
       "      <td>23.5675</td>\n",
       "      <td>51.5391</td>\n",
       "      <td>0.9701</td>\n",
       "      <td>2.2821</td>\n",
       "      <td>52.6523</td>\n",
       "      <td>0.9934</td>\n",
       "      <td>2.8336</td>\n",
       "      <td>52.0512</td>\n",
       "      <td>1.0152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61000</td>\n",
       "      <td>2.570800</td>\n",
       "      <td>2.625710</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.2389</td>\n",
       "      <td>27.9041</td>\n",
       "      <td>25.1672</td>\n",
       "      <td>51.7637</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>2.4523</td>\n",
       "      <td>51.8234</td>\n",
       "      <td>0.9399</td>\n",
       "      <td>2.9937</td>\n",
       "      <td>51.7514</td>\n",
       "      <td>0.9945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62000</td>\n",
       "      <td>2.516400</td>\n",
       "      <td>2.593751</td>\n",
       "      <td>0.2481</td>\n",
       "      <td>0.2819</td>\n",
       "      <td>26.5380</td>\n",
       "      <td>24.0784</td>\n",
       "      <td>51.8623</td>\n",
       "      <td>0.977</td>\n",
       "      <td>2.2089</td>\n",
       "      <td>52.4767</td>\n",
       "      <td>0.9834</td>\n",
       "      <td>2.7172</td>\n",
       "      <td>52.4557</td>\n",
       "      <td>0.9695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63000</td>\n",
       "      <td>2.558800</td>\n",
       "      <td>2.561649</td>\n",
       "      <td>0.2696</td>\n",
       "      <td>0.299</td>\n",
       "      <td>24.5735</td>\n",
       "      <td>21.9136</td>\n",
       "      <td>52.1906</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2.2657</td>\n",
       "      <td>53.0985</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>2.8008</td>\n",
       "      <td>51.5310</td>\n",
       "      <td>0.9848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64000</td>\n",
       "      <td>2.601900</td>\n",
       "      <td>2.689623</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.1229</td>\n",
       "      <td>22.1372</td>\n",
       "      <td>19.7475</td>\n",
       "      <td>50.2966</td>\n",
       "      <td>0.9056</td>\n",
       "      <td>2.0636</td>\n",
       "      <td>51.8144</td>\n",
       "      <td>1.0315</td>\n",
       "      <td>2.5977</td>\n",
       "      <td>52.4932</td>\n",
       "      <td>0.9976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65000</td>\n",
       "      <td>2.542600</td>\n",
       "      <td>2.622332</td>\n",
       "      <td>0.1489</td>\n",
       "      <td>0.2049</td>\n",
       "      <td>21.3248</td>\n",
       "      <td>19.0029</td>\n",
       "      <td>51.0254</td>\n",
       "      <td>0.9332</td>\n",
       "      <td>1.9899</td>\n",
       "      <td>52.8256</td>\n",
       "      <td>1.0164</td>\n",
       "      <td>2.5256</td>\n",
       "      <td>52.2989</td>\n",
       "      <td>0.9955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66000</td>\n",
       "      <td>2.484500</td>\n",
       "      <td>2.648216</td>\n",
       "      <td>0.2312</td>\n",
       "      <td>0.2523</td>\n",
       "      <td>27.2813</td>\n",
       "      <td>24.7685</td>\n",
       "      <td>51.5561</td>\n",
       "      <td>0.9705</td>\n",
       "      <td>2.2976</td>\n",
       "      <td>52.7857</td>\n",
       "      <td>0.9845</td>\n",
       "      <td>2.8155</td>\n",
       "      <td>52.4710</td>\n",
       "      <td>1.0024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67000</td>\n",
       "      <td>2.527400</td>\n",
       "      <td>2.663642</td>\n",
       "      <td>0.1689</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>24.8242</td>\n",
       "      <td>22.2800</td>\n",
       "      <td>51.2624</td>\n",
       "      <td>0.9446</td>\n",
       "      <td>2.2346</td>\n",
       "      <td>52.9718</td>\n",
       "      <td>1.0083</td>\n",
       "      <td>2.8327</td>\n",
       "      <td>51.7237</td>\n",
       "      <td>0.9738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68000</td>\n",
       "      <td>2.544700</td>\n",
       "      <td>2.523105</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.3511</td>\n",
       "      <td>20.8421</td>\n",
       "      <td>18.3367</td>\n",
       "      <td>52.1078</td>\n",
       "      <td>1.0124</td>\n",
       "      <td>1.9949</td>\n",
       "      <td>52.7551</td>\n",
       "      <td>0.9655</td>\n",
       "      <td>2.5581</td>\n",
       "      <td>53.1227</td>\n",
       "      <td>0.9978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69000</td>\n",
       "      <td>2.482200</td>\n",
       "      <td>2.621174</td>\n",
       "      <td>0.2511</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>26.5431</td>\n",
       "      <td>23.9548</td>\n",
       "      <td>52.0412</td>\n",
       "      <td>0.9712</td>\n",
       "      <td>2.3448</td>\n",
       "      <td>51.7991</td>\n",
       "      <td>1.0248</td>\n",
       "      <td>2.9231</td>\n",
       "      <td>51.9754</td>\n",
       "      <td>0.9964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70000</td>\n",
       "      <td>2.558600</td>\n",
       "      <td>2.649759</td>\n",
       "      <td>0.1993</td>\n",
       "      <td>0.2230</td>\n",
       "      <td>24.5946</td>\n",
       "      <td>22.0948</td>\n",
       "      <td>51.4533</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>2.2578</td>\n",
       "      <td>52.0029</td>\n",
       "      <td>1.0079</td>\n",
       "      <td>2.8196</td>\n",
       "      <td>51.5948</td>\n",
       "      <td>1.0005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71000</td>\n",
       "      <td>2.544400</td>\n",
       "      <td>2.516620</td>\n",
       "      <td>0.2439</td>\n",
       "      <td>0.3397</td>\n",
       "      <td>20.1613</td>\n",
       "      <td>17.9687</td>\n",
       "      <td>52.2995</td>\n",
       "      <td>0.9946</td>\n",
       "      <td>1.8801</td>\n",
       "      <td>53.502</td>\n",
       "      <td>1.0038</td>\n",
       "      <td>2.391</td>\n",
       "      <td>53.7615</td>\n",
       "      <td>0.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72000</td>\n",
       "      <td>2.468500</td>\n",
       "      <td>2.554528</td>\n",
       "      <td>0.2893</td>\n",
       "      <td>0.3394</td>\n",
       "      <td>25.0440</td>\n",
       "      <td>22.5573</td>\n",
       "      <td>52.2887</td>\n",
       "      <td>1.0017</td>\n",
       "      <td>2.2127</td>\n",
       "      <td>52.5296</td>\n",
       "      <td>1.013</td>\n",
       "      <td>2.7898</td>\n",
       "      <td>52.8769</td>\n",
       "      <td>1.0285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73000</td>\n",
       "      <td>2.530900</td>\n",
       "      <td>2.519002</td>\n",
       "      <td>0.2837</td>\n",
       "      <td>0.3552</td>\n",
       "      <td>22.6841</td>\n",
       "      <td>20.3099</td>\n",
       "      <td>52.3387</td>\n",
       "      <td>1.0029</td>\n",
       "      <td>2.0528</td>\n",
       "      <td>53.3366</td>\n",
       "      <td>1.0137</td>\n",
       "      <td>2.5816</td>\n",
       "      <td>53.4176</td>\n",
       "      <td>1.0447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74000</td>\n",
       "      <td>2.468200</td>\n",
       "      <td>2.542752</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.3157</td>\n",
       "      <td>22.029</td>\n",
       "      <td>19.7936</td>\n",
       "      <td>52.1146</td>\n",
       "      <td>0.9828</td>\n",
       "      <td>1.9639</td>\n",
       "      <td>53.1109</td>\n",
       "      <td>1.0098</td>\n",
       "      <td>2.4634</td>\n",
       "      <td>53.5969</td>\n",
       "      <td>1.0123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75000</td>\n",
       "      <td>2.469800</td>\n",
       "      <td>2.563503</td>\n",
       "      <td>0.2787</td>\n",
       "      <td>0.3183</td>\n",
       "      <td>25.3966</td>\n",
       "      <td>23.019</td>\n",
       "      <td>52.2187</td>\n",
       "      <td>0.9893</td>\n",
       "      <td>2.1566</td>\n",
       "      <td>53.1468</td>\n",
       "      <td>1.0079</td>\n",
       "      <td>2.6666</td>\n",
       "      <td>53.1853</td>\n",
       "      <td>1.0255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76000</td>\n",
       "      <td>2.538100</td>\n",
       "      <td>2.564493</td>\n",
       "      <td>0.2351</td>\n",
       "      <td>0.2868</td>\n",
       "      <td>23.1333</td>\n",
       "      <td>20.8513</td>\n",
       "      <td>52.062</td>\n",
       "      <td>0.9695</td>\n",
       "      <td>2.0412</td>\n",
       "      <td>52.9343</td>\n",
       "      <td>0.9994</td>\n",
       "      <td>2.5539</td>\n",
       "      <td>53.3482</td>\n",
       "      <td>1.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77000</td>\n",
       "      <td>2.525500</td>\n",
       "      <td>2.546195</td>\n",
       "      <td>0.2327</td>\n",
       "      <td>0.2996</td>\n",
       "      <td>21.9741</td>\n",
       "      <td>19.7580</td>\n",
       "      <td>51.8614</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>1.9224</td>\n",
       "      <td>53.3031</td>\n",
       "      <td>1.0252</td>\n",
       "      <td>2.457</td>\n",
       "      <td>53.2949</td>\n",
       "      <td>0.9987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78000</td>\n",
       "      <td>2.494700</td>\n",
       "      <td>2.541990</td>\n",
       "      <td>0.2602</td>\n",
       "      <td>0.3137</td>\n",
       "      <td>23.2285</td>\n",
       "      <td>20.919</td>\n",
       "      <td>52.0858</td>\n",
       "      <td>0.9858</td>\n",
       "      <td>2.0663</td>\n",
       "      <td>52.9905</td>\n",
       "      <td>1.0190</td>\n",
       "      <td>2.5789</td>\n",
       "      <td>53.9288</td>\n",
       "      <td>0.9941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79000</td>\n",
       "      <td>2.456500</td>\n",
       "      <td>2.573285</td>\n",
       "      <td>0.2541</td>\n",
       "      <td>0.2895</td>\n",
       "      <td>24.1369</td>\n",
       "      <td>21.7718</td>\n",
       "      <td>52.132</td>\n",
       "      <td>0.9760</td>\n",
       "      <td>2.1199</td>\n",
       "      <td>53.2371</td>\n",
       "      <td>1.0128</td>\n",
       "      <td>2.6983</td>\n",
       "      <td>52.7002</td>\n",
       "      <td>1.0087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80000</td>\n",
       "      <td>2.505700</td>\n",
       "      <td>2.575916</td>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.2867</td>\n",
       "      <td>24.2987</td>\n",
       "      <td>21.9135</td>\n",
       "      <td>52.0778</td>\n",
       "      <td>0.9748</td>\n",
       "      <td>2.1585</td>\n",
       "      <td>53.5689</td>\n",
       "      <td>1.0212</td>\n",
       "      <td>2.6805</td>\n",
       "      <td>52.6922</td>\n",
       "      <td>1.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81000</td>\n",
       "      <td>2.524900</td>\n",
       "      <td>2.556640</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.2996</td>\n",
       "      <td>23.4693</td>\n",
       "      <td>21.1783</td>\n",
       "      <td>52.1278</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>2.0571</td>\n",
       "      <td>53.2559</td>\n",
       "      <td>1.0183</td>\n",
       "      <td>2.6032</td>\n",
       "      <td>53.3576</td>\n",
       "      <td>1.0184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82000</td>\n",
       "      <td>2.553900</td>\n",
       "      <td>2.559607</td>\n",
       "      <td>0.2504</td>\n",
       "      <td>0.2981</td>\n",
       "      <td>23.3414</td>\n",
       "      <td>21.0537</td>\n",
       "      <td>52.1112</td>\n",
       "      <td>0.9762</td>\n",
       "      <td>2.0606</td>\n",
       "      <td>53.3149</td>\n",
       "      <td>1.0066</td>\n",
       "      <td>2.6075</td>\n",
       "      <td>53.4734</td>\n",
       "      <td>1.0307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83000</td>\n",
       "      <td>2.570000</td>\n",
       "      <td>2.555478</td>\n",
       "      <td>0.2538</td>\n",
       "      <td>0.3019</td>\n",
       "      <td>23.2777</td>\n",
       "      <td>21.0008</td>\n",
       "      <td>52.1340</td>\n",
       "      <td>0.9771</td>\n",
       "      <td>2.0654</td>\n",
       "      <td>53.4909</td>\n",
       "      <td>1.0236</td>\n",
       "      <td>2.5764</td>\n",
       "      <td>53.5595</td>\n",
       "      <td>1.0247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84000</td>\n",
       "      <td>2.527600</td>\n",
       "      <td>2.559017</td>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.2995</td>\n",
       "      <td>23.4489</td>\n",
       "      <td>21.1546</td>\n",
       "      <td>52.1119</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>2.0849</td>\n",
       "      <td>53.7920</td>\n",
       "      <td>1.0313</td>\n",
       "      <td>2.6032</td>\n",
       "      <td>53.2945</td>\n",
       "      <td>1.0129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85000</td>\n",
       "      <td>2.529100</td>\n",
       "      <td>2.560240</td>\n",
       "      <td>0.2529</td>\n",
       "      <td>0.2979</td>\n",
       "      <td>23.4379</td>\n",
       "      <td>21.1480</td>\n",
       "      <td>52.1263</td>\n",
       "      <td>0.9766</td>\n",
       "      <td>2.0866</td>\n",
       "      <td>53.5524</td>\n",
       "      <td>1.0078</td>\n",
       "      <td>2.5978</td>\n",
       "      <td>53.3914</td>\n",
       "      <td>1.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86000</td>\n",
       "      <td>2.507600</td>\n",
       "      <td>2.556304</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.302</td>\n",
       "      <td>23.4109</td>\n",
       "      <td>21.1168</td>\n",
       "      <td>52.1615</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>2.0918</td>\n",
       "      <td>53.5466</td>\n",
       "      <td>1.0035</td>\n",
       "      <td>2.5958</td>\n",
       "      <td>53.399</td>\n",
       "      <td>1.0292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87000</td>\n",
       "      <td>2.488000</td>\n",
       "      <td>2.556866</td>\n",
       "      <td>0.2557</td>\n",
       "      <td>0.3016</td>\n",
       "      <td>23.4286</td>\n",
       "      <td>21.1350</td>\n",
       "      <td>52.1519</td>\n",
       "      <td>0.9780</td>\n",
       "      <td>2.0936</td>\n",
       "      <td>53.6282</td>\n",
       "      <td>1.01</td>\n",
       "      <td>2.5995</td>\n",
       "      <td>53.3745</td>\n",
       "      <td>1.0261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=87883, training_loss=2.6218227993601935, metrics={'train_runtime': 23594.285, 'train_samples_per_second': 3.725, 'train_steps_per_second': 3.725, 'total_flos': 0.0, 'train_loss': 2.6218227993601935, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with a 10x linear elu softmax smoothed trade loss with .2x trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.215977281332016\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3100' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 3100/87883 13:57 < 6:22:08, 3.70 it/s, Epoch 0.04/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.991500</td>\n",
       "      <td>2.854110</td>\n",
       "      <td>0.2338</td>\n",
       "      <td>0.2818</td>\n",
       "      <td>34.6562</td>\n",
       "      <td>9.4086</td>\n",
       "      <td>52.4314</td>\n",
       "      <td>1.0752</td>\n",
       "      <td>29.6405</td>\n",
       "      <td>50.9948</td>\n",
       "      <td>1.0499</td>\n",
       "      <td>27.4986</td>\n",
       "      <td>50.0766</td>\n",
       "      <td>1.0124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.890400</td>\n",
       "      <td>2.864523</td>\n",
       "      <td>0.2448</td>\n",
       "      <td>0.1922</td>\n",
       "      <td>45.8752</td>\n",
       "      <td>27.5925</td>\n",
       "      <td>51.2142</td>\n",
       "      <td>1.0119</td>\n",
       "      <td>25.2252</td>\n",
       "      <td>50.5035</td>\n",
       "      <td>1.0132</td>\n",
       "      <td>21.0515</td>\n",
       "      <td>49.8495</td>\n",
       "      <td>1.0143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.765700</td>\n",
       "      <td>2.667029</td>\n",
       "      <td>0.3353</td>\n",
       "      <td>0.3343</td>\n",
       "      <td>47.9214</td>\n",
       "      <td>31.1736</td>\n",
       "      <td>51.5358</td>\n",
       "      <td>1.0172</td>\n",
       "      <td>21.2411</td>\n",
       "      <td>51.1303</td>\n",
       "      <td>1.0374</td>\n",
       "      <td>21.0633</td>\n",
       "      <td>50.4252</td>\n",
       "      <td>1.0501</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07118606567382812853\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-937b63ae1da0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with a 10x linear elu softmax smoothed trade loss with .1x trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, WITH rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with a 1x linear elu softmax smoothed trade loss with .15x trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21036' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21036/87883 1:01:23 < 3:15:06, 5.71 it/s, Epoch 0.24/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.796500</td>\n",
       "      <td>3.489376</td>\n",
       "      <td>0.0626</td>\n",
       "      <td>0.1073</td>\n",
       "      <td>18.1236</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>50.</td>\n",
       "      <td>2.0279</td>\n",
       "      <td>2.7741</td>\n",
       "      <td>49.7105</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>35.0006</td>\n",
       "      <td>50.4241</td>\n",
       "      <td>1.0237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.526800</td>\n",
       "      <td>3.136360</td>\n",
       "      <td>0.0396</td>\n",
       "      <td>0.1825</td>\n",
       "      <td>10.6912</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1321</td>\n",
       "      <td>58.2375</td>\n",
       "      <td>1.1473</td>\n",
       "      <td>13.4411</td>\n",
       "      <td>51.5914</td>\n",
       "      <td>1.0252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.358000</td>\n",
       "      <td>3.068443</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.2841</td>\n",
       "      <td>11.0408</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.7084</td>\n",
       "      <td>60.9643</td>\n",
       "      <td>1.1416</td>\n",
       "      <td>13.2256</td>\n",
       "      <td>52.1166</td>\n",
       "      <td>1.0439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.304200</td>\n",
       "      <td>2.993170</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.382</td>\n",
       "      <td>10.1165</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>84.2105</td>\n",
       "      <td>1.5985</td>\n",
       "      <td>1.5022</td>\n",
       "      <td>61.157</td>\n",
       "      <td>1.1886</td>\n",
       "      <td>10.0817</td>\n",
       "      <td>54.2182</td>\n",
       "      <td>1.0434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.252200</td>\n",
       "      <td>3.092469</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>0.3033</td>\n",
       "      <td>12.4274</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>50.</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>1.4203</td>\n",
       "      <td>60.3580</td>\n",
       "      <td>1.2185</td>\n",
       "      <td>17.8996</td>\n",
       "      <td>52.6405</td>\n",
       "      <td>0.9993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.189300</td>\n",
       "      <td>3.161190</td>\n",
       "      <td>0.1325</td>\n",
       "      <td>0.2240</td>\n",
       "      <td>13.1352</td>\n",
       "      <td>0.029</td>\n",
       "      <td>52.8384</td>\n",
       "      <td>1.0090</td>\n",
       "      <td>4.1339</td>\n",
       "      <td>52.7493</td>\n",
       "      <td>1.0873</td>\n",
       "      <td>15.5247</td>\n",
       "      <td>51.8870</td>\n",
       "      <td>1.0320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.148500</td>\n",
       "      <td>3.071625</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>9.8557</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>40.7407</td>\n",
       "      <td>0.5164</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>47.216</td>\n",
       "      <td>0.7768</td>\n",
       "      <td>12.5326</td>\n",
       "      <td>50.9306</td>\n",
       "      <td>1.0384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.094100</td>\n",
       "      <td>2.922786</td>\n",
       "      <td>0.0766</td>\n",
       "      <td>0.3011</td>\n",
       "      <td>7.2765</td>\n",
       "      <td>0.0186</td>\n",
       "      <td>52.381</td>\n",
       "      <td>0.6589</td>\n",
       "      <td>0.3726</td>\n",
       "      <td>52.8853</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>5.9091</td>\n",
       "      <td>56.6520</td>\n",
       "      <td>1.0703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>3.082300</td>\n",
       "      <td>2.913904</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.2933</td>\n",
       "      <td>7.4524</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>56.7073</td>\n",
       "      <td>0.6248</td>\n",
       "      <td>0.5205</td>\n",
       "      <td>61.9441</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>7.0126</td>\n",
       "      <td>54.5753</td>\n",
       "      <td>1.0557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>3.029800</td>\n",
       "      <td>2.971884</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.1468</td>\n",
       "      <td>7.5281</td>\n",
       "      <td>0.1818</td>\n",
       "      <td>44.5372</td>\n",
       "      <td>0.6604</td>\n",
       "      <td>0.5835</td>\n",
       "      <td>53.3709</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>6.6156</td>\n",
       "      <td>52.7380</td>\n",
       "      <td>0.9822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>3.008200</td>\n",
       "      <td>2.958387</td>\n",
       "      <td>0.0661</td>\n",
       "      <td>0.167</td>\n",
       "      <td>7.672</td>\n",
       "      <td>0.3379</td>\n",
       "      <td>46.5743</td>\n",
       "      <td>0.8343</td>\n",
       "      <td>1.7856</td>\n",
       "      <td>50.7509</td>\n",
       "      <td>1.0144</td>\n",
       "      <td>6.7982</td>\n",
       "      <td>53.7995</td>\n",
       "      <td>1.0494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.970400</td>\n",
       "      <td>2.966703</td>\n",
       "      <td>0.0799</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>7.9051</td>\n",
       "      <td>0.178</td>\n",
       "      <td>59.3461</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>58.2514</td>\n",
       "      <td>0.9865</td>\n",
       "      <td>7.9044</td>\n",
       "      <td>53.6830</td>\n",
       "      <td>1.0294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.993000</td>\n",
       "      <td>2.891730</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.3134</td>\n",
       "      <td>6.8551</td>\n",
       "      <td>0.0486</td>\n",
       "      <td>65.8854</td>\n",
       "      <td>0.6871</td>\n",
       "      <td>0.2859</td>\n",
       "      <td>64.9115</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>5.4398</td>\n",
       "      <td>55.5517</td>\n",
       "      <td>1.0720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.958200</td>\n",
       "      <td>2.876262</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>4.992</td>\n",
       "      <td>0.2916</td>\n",
       "      <td>51.6269</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.453</td>\n",
       "      <td>63.6973</td>\n",
       "      <td>0.9370</td>\n",
       "      <td>2.7907</td>\n",
       "      <td>56.2415</td>\n",
       "      <td>0.9209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.945100</td>\n",
       "      <td>2.907201</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.2839</td>\n",
       "      <td>6.7503</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>68.8047</td>\n",
       "      <td>0.5398</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>61.849</td>\n",
       "      <td>0.7085</td>\n",
       "      <td>7.7248</td>\n",
       "      <td>50.6558</td>\n",
       "      <td>1.0836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.910500</td>\n",
       "      <td>2.860235</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>4.5729</td>\n",
       "      <td>0.3446</td>\n",
       "      <td>50.514</td>\n",
       "      <td>0.8383</td>\n",
       "      <td>0.5437</td>\n",
       "      <td>59.9349</td>\n",
       "      <td>0.8436</td>\n",
       "      <td>2.2269</td>\n",
       "      <td>54.3596</td>\n",
       "      <td>0.9163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.910500</td>\n",
       "      <td>2.895900</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>5.6131</td>\n",
       "      <td>0.3837</td>\n",
       "      <td>51.9947</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.5963</td>\n",
       "      <td>54.7942</td>\n",
       "      <td>0.8598</td>\n",
       "      <td>4.3621</td>\n",
       "      <td>50.7641</td>\n",
       "      <td>0.9487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.913600</td>\n",
       "      <td>2.876387</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.3078</td>\n",
       "      <td>6.0455</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>60.0563</td>\n",
       "      <td>0.7534</td>\n",
       "      <td>0.5368</td>\n",
       "      <td>62.017</td>\n",
       "      <td>1.1896</td>\n",
       "      <td>5.3752</td>\n",
       "      <td>52.6145</td>\n",
       "      <td>1.0973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.898800</td>\n",
       "      <td>2.818080</td>\n",
       "      <td>0.0448</td>\n",
       "      <td>0.2858</td>\n",
       "      <td>4.0842</td>\n",
       "      <td>0.2682</td>\n",
       "      <td>51.7453</td>\n",
       "      <td>0.8034</td>\n",
       "      <td>0.3347</td>\n",
       "      <td>54.0060</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>1.9914</td>\n",
       "      <td>60.7445</td>\n",
       "      <td>1.0389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.870100</td>\n",
       "      <td>2.803051</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.2516</td>\n",
       "      <td>3.6128</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>59.8464</td>\n",
       "      <td>0.8227</td>\n",
       "      <td>0.2759</td>\n",
       "      <td>57.7717</td>\n",
       "      <td>0.7245</td>\n",
       "      <td>1.5344</td>\n",
       "      <td>61.2531</td>\n",
       "      <td>0.9978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.859500</td>\n",
       "      <td>2.786829</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.3568</td>\n",
       "      <td>3.7229</td>\n",
       "      <td>0.1777</td>\n",
       "      <td>59.0036</td>\n",
       "      <td>0.5965</td>\n",
       "      <td>0.2634</td>\n",
       "      <td>62.0557</td>\n",
       "      <td>0.7903</td>\n",
       "      <td>1.8522</td>\n",
       "      <td>61.8931</td>\n",
       "      <td>1.0755</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-ffa187d375a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with a 20x linear tanh trade loss with .2x trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1712\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1713\u001b[0m             \u001b[0mstep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1714\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1716\u001b[0m                 \u001b[1;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    721\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 723\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    724\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    725\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[1;34m(data, device)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;31m# The mapping type may not support `__init__(iterable)`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     53\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;31m# The mapping type may not support `__init__(iterable)`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\utils\\data\\_utils\\pin_memory.py\u001b[0m in \u001b[0;36mpin_memory\u001b[1;34m(data, device)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 50\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     51\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512 only 6 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, no rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with a 20x linear tanh trade loss with .2x trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='5340' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 5340/87883 24:26 < 6:18:04, 3.64 it/s, Epoch 0.06/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.823800</td>\n",
       "      <td>3.717109</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>14.9906</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>33.3333</td>\n",
       "      <td>0.273</td>\n",
       "      <td>2.5204</td>\n",
       "      <td>51.0163</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>27.2833</td>\n",
       "      <td>49.3614</td>\n",
       "      <td>0.9980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.765800</td>\n",
       "      <td>3.701881</td>\n",
       "      <td>-0.02</td>\n",
       "      <td>-0.0640</td>\n",
       "      <td>11.7054</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>2.1587</td>\n",
       "      <td>50.0469</td>\n",
       "      <td>0.7787</td>\n",
       "      <td>15.0424</td>\n",
       "      <td>49.6615</td>\n",
       "      <td>0.9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.749100</td>\n",
       "      <td>3.686124</td>\n",
       "      <td>0.048</td>\n",
       "      <td>0.3476</td>\n",
       "      <td>8.7783</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1305</td>\n",
       "      <td>68.314</td>\n",
       "      <td>0.8931</td>\n",
       "      <td>7.5831</td>\n",
       "      <td>54.0526</td>\n",
       "      <td>0.9394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.740600</td>\n",
       "      <td>3.678648</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1991</td>\n",
       "      <td>13.8625</td>\n",
       "      <td>0.1398</td>\n",
       "      <td>65.1584</td>\n",
       "      <td>0.8976</td>\n",
       "      <td>4.7256</td>\n",
       "      <td>55.4137</td>\n",
       "      <td>0.916</td>\n",
       "      <td>17.2118</td>\n",
       "      <td>50.8136</td>\n",
       "      <td>1.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.732900</td>\n",
       "      <td>3.676281</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>12.6683</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>76.8473</td>\n",
       "      <td>1.3697</td>\n",
       "      <td>2.6427</td>\n",
       "      <td>59.2763</td>\n",
       "      <td>0.9344</td>\n",
       "      <td>16.8217</td>\n",
       "      <td>50.9264</td>\n",
       "      <td>0.8818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='61' max='61' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [61/61 00:06]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-bb1c47517fd0>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .7] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .7) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-bb1c47517fd0>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .7) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a6884a9cbbc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with a elu softmax exponentiated trade loss / 3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1802\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1803\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1804\u001b[1;33m                         \u001b[0mscale_after\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_scale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1805\u001b[0m                         \u001b[0moptimizer_was_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscale_before\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mscale_after\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1806\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mget_scale\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    412\u001b[0m         \"\"\"\n\u001b[0;32m    413\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_enabled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 414\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_scale\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_scale\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_scale_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    415\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    416\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512, 10 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, no rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with a elu softmax exponentiated trade loss / 3\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8024' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8024/87883 23:22 < 3:52:41, 5.72 it/s, Epoch 0.09/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.829200</td>\n",
       "      <td>3.721771</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.1961</td>\n",
       "      <td>11.5417</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>56.8245</td>\n",
       "      <td>1.0471</td>\n",
       "      <td>15.8679</td>\n",
       "      <td>50.796</td>\n",
       "      <td>1.0209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>3.765700</td>\n",
       "      <td>3.703897</td>\n",
       "      <td>-0.0165</td>\n",
       "      <td>-0.0905</td>\n",
       "      <td>8.8218</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0076</td>\n",
       "      <td>76.6667</td>\n",
       "      <td>1.2119</td>\n",
       "      <td>7.5194</td>\n",
       "      <td>50.9227</td>\n",
       "      <td>0.8675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>3.750100</td>\n",
       "      <td>3.690236</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.4002</td>\n",
       "      <td>6.5708</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>78.9474</td>\n",
       "      <td>2.3739</td>\n",
       "      <td>2.0881</td>\n",
       "      <td>55.9305</td>\n",
       "      <td>0.9048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>3.740800</td>\n",
       "      <td>3.681097</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.1966</td>\n",
       "      <td>8.8766</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.4270</td>\n",
       "      <td>64.5735</td>\n",
       "      <td>0.8331</td>\n",
       "      <td>8.6437</td>\n",
       "      <td>52.2873</td>\n",
       "      <td>0.9746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>3.733200</td>\n",
       "      <td>3.681600</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>8.6883</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1378</td>\n",
       "      <td>82.5528</td>\n",
       "      <td>1.3111</td>\n",
       "      <td>8.3073</td>\n",
       "      <td>53.8310</td>\n",
       "      <td>0.9057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>3.727800</td>\n",
       "      <td>3.699143</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.3781</td>\n",
       "      <td>9.6601</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>60.</td>\n",
       "      <td>1.3369</td>\n",
       "      <td>0.4929</td>\n",
       "      <td>67.6418</td>\n",
       "      <td>1.1447</td>\n",
       "      <td>10.1747</td>\n",
       "      <td>53.1609</td>\n",
       "      <td>0.947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>3.721200</td>\n",
       "      <td>3.660487</td>\n",
       "      <td>-0.0058</td>\n",
       "      <td>-0.0355</td>\n",
       "      <td>8.2306</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>44.6809</td>\n",
       "      <td>0.6512</td>\n",
       "      <td>0.3740</td>\n",
       "      <td>63.578</td>\n",
       "      <td>1.0201</td>\n",
       "      <td>6.4039</td>\n",
       "      <td>52.9461</td>\n",
       "      <td>0.8424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>3.723600</td>\n",
       "      <td>3.672066</td>\n",
       "      <td>0.0410</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>8.9116</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>47.7612</td>\n",
       "      <td>0.9073</td>\n",
       "      <td>0.5881</td>\n",
       "      <td>62.8307</td>\n",
       "      <td>0.9997</td>\n",
       "      <td>7.8938</td>\n",
       "      <td>51.6321</td>\n",
       "      <td>0.8809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-052f7281f59f>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-052f7281f59f>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-052f7281f59f>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-052f7281f59f>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-052f7281f59f>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-052f7281f59f>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-052f7281f59f>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-052f7281f59f>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-052f7281f59f>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-052f7281f59f>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-052f7281f59f>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-052f7281f59f>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-052f7281f59f>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-afea174d74a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# multiloss as an auxillary with a elu softmax exponentiated trade loss / 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512 only 6 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, no rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with a elu softmax exponentiated trade loss / 2\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='21278' max='87883' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [21278/87883 1:01:49 < 3:13:31, 5.74 it/s, Epoch 0.24/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.823300</td>\n",
       "      <td>2.717968</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.1729</td>\n",
       "      <td>10.4889</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>50.5618</td>\n",
       "      <td>0.9721</td>\n",
       "      <td>1.1999</td>\n",
       "      <td>50.5376</td>\n",
       "      <td>1.0524</td>\n",
       "      <td>10.3327</td>\n",
       "      <td>50.7676</td>\n",
       "      <td>1.0307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.764100</td>\n",
       "      <td>2.702410</td>\n",
       "      <td>-0.0114</td>\n",
       "      <td>-0.0698</td>\n",
       "      <td>9.4035</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>54.1667</td>\n",
       "      <td>1.3401</td>\n",
       "      <td>0.3942</td>\n",
       "      <td>52.7599</td>\n",
       "      <td>0.8110</td>\n",
       "      <td>7.3860</td>\n",
       "      <td>50.7116</td>\n",
       "      <td>0.8769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.750400</td>\n",
       "      <td>2.689411</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.3932</td>\n",
       "      <td>8.6593</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>71.6216</td>\n",
       "      <td>0.8777</td>\n",
       "      <td>0.2919</td>\n",
       "      <td>57.539</td>\n",
       "      <td>0.8386</td>\n",
       "      <td>4.808</td>\n",
       "      <td>52.8835</td>\n",
       "      <td>0.9515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.741900</td>\n",
       "      <td>2.680125</td>\n",
       "      <td>0.0579</td>\n",
       "      <td>0.1693</td>\n",
       "      <td>12.3134</td>\n",
       "      <td>0.4875</td>\n",
       "      <td>60.0156</td>\n",
       "      <td>0.9353</td>\n",
       "      <td>2.4593</td>\n",
       "      <td>53.6467</td>\n",
       "      <td>0.9232</td>\n",
       "      <td>14.8640</td>\n",
       "      <td>52.0956</td>\n",
       "      <td>0.9773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.733900</td>\n",
       "      <td>2.677560</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>11.1442</td>\n",
       "      <td>0.2765</td>\n",
       "      <td>68.893</td>\n",
       "      <td>1.0045</td>\n",
       "      <td>2.3094</td>\n",
       "      <td>56.3893</td>\n",
       "      <td>0.8732</td>\n",
       "      <td>11.9542</td>\n",
       "      <td>50.8407</td>\n",
       "      <td>0.8564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.729200</td>\n",
       "      <td>2.694258</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.1696</td>\n",
       "      <td>12.4095</td>\n",
       "      <td>1.9868</td>\n",
       "      <td>39.3137</td>\n",
       "      <td>0.762</td>\n",
       "      <td>4.3668</td>\n",
       "      <td>47.9694</td>\n",
       "      <td>0.8998</td>\n",
       "      <td>12.5137</td>\n",
       "      <td>52.2471</td>\n",
       "      <td>0.9316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.723200</td>\n",
       "      <td>2.664954</td>\n",
       "      <td>-0.0111</td>\n",
       "      <td>-0.0601</td>\n",
       "      <td>10.8717</td>\n",
       "      <td>0.6508</td>\n",
       "      <td>41.2245</td>\n",
       "      <td>0.8803</td>\n",
       "      <td>3.4606</td>\n",
       "      <td>46.8711</td>\n",
       "      <td>0.7999</td>\n",
       "      <td>10.6105</td>\n",
       "      <td>49.8915</td>\n",
       "      <td>0.8818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.724600</td>\n",
       "      <td>2.671627</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.1639</td>\n",
       "      <td>10.2411</td>\n",
       "      <td>1.0694</td>\n",
       "      <td>40.9747</td>\n",
       "      <td>0.982</td>\n",
       "      <td>3.3639</td>\n",
       "      <td>45.3185</td>\n",
       "      <td>0.8299</td>\n",
       "      <td>7.9449</td>\n",
       "      <td>49.6075</td>\n",
       "      <td>0.9073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.716900</td>\n",
       "      <td>2.688622</td>\n",
       "      <td>-0.0058</td>\n",
       "      <td>-0.0219</td>\n",
       "      <td>11.4434</td>\n",
       "      <td>0.611</td>\n",
       "      <td>54.1822</td>\n",
       "      <td>0.8534</td>\n",
       "      <td>2.8400</td>\n",
       "      <td>48.3164</td>\n",
       "      <td>0.7736</td>\n",
       "      <td>11.8283</td>\n",
       "      <td>49.8129</td>\n",
       "      <td>0.8456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.716200</td>\n",
       "      <td>2.655124</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>10.5203</td>\n",
       "      <td>1.2791</td>\n",
       "      <td>44.5115</td>\n",
       "      <td>0.8638</td>\n",
       "      <td>3.7992</td>\n",
       "      <td>46.5091</td>\n",
       "      <td>0.8610</td>\n",
       "      <td>8.5114</td>\n",
       "      <td>48.9374</td>\n",
       "      <td>0.8728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.706100</td>\n",
       "      <td>2.673156</td>\n",
       "      <td>-0.0336</td>\n",
       "      <td>-0.0912</td>\n",
       "      <td>13.308</td>\n",
       "      <td>1.3774</td>\n",
       "      <td>46.8914</td>\n",
       "      <td>0.8241</td>\n",
       "      <td>4.8478</td>\n",
       "      <td>48.3079</td>\n",
       "      <td>0.9139</td>\n",
       "      <td>16.4778</td>\n",
       "      <td>48.6631</td>\n",
       "      <td>0.9559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.705000</td>\n",
       "      <td>2.672554</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>0.1165</td>\n",
       "      <td>13.1222</td>\n",
       "      <td>3.5369</td>\n",
       "      <td>41.4685</td>\n",
       "      <td>0.8038</td>\n",
       "      <td>4.8478</td>\n",
       "      <td>48.7802</td>\n",
       "      <td>0.841</td>\n",
       "      <td>12.2118</td>\n",
       "      <td>52.0064</td>\n",
       "      <td>0.8968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.704000</td>\n",
       "      <td>2.659808</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.1354</td>\n",
       "      <td>13.4052</td>\n",
       "      <td>4.0355</td>\n",
       "      <td>40.1216</td>\n",
       "      <td>0.7605</td>\n",
       "      <td>4.3104</td>\n",
       "      <td>46.8394</td>\n",
       "      <td>0.9118</td>\n",
       "      <td>12.4182</td>\n",
       "      <td>52.2252</td>\n",
       "      <td>0.9665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.704900</td>\n",
       "      <td>2.658555</td>\n",
       "      <td>-0.0079</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>11.2349</td>\n",
       "      <td>1.9833</td>\n",
       "      <td>43.6699</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>2.9009</td>\n",
       "      <td>46.601</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>8.7825</td>\n",
       "      <td>49.9503</td>\n",
       "      <td>0.8560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.705700</td>\n",
       "      <td>2.655120</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>11.555</td>\n",
       "      <td>1.6588</td>\n",
       "      <td>41.1621</td>\n",
       "      <td>0.7610</td>\n",
       "      <td>3.3489</td>\n",
       "      <td>45.6959</td>\n",
       "      <td>0.8369</td>\n",
       "      <td>10.3396</td>\n",
       "      <td>51.7598</td>\n",
       "      <td>0.9399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.698200</td>\n",
       "      <td>2.655776</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.1756</td>\n",
       "      <td>17.7075</td>\n",
       "      <td>6.2312</td>\n",
       "      <td>43.1234</td>\n",
       "      <td>0.7853</td>\n",
       "      <td>8.4193</td>\n",
       "      <td>51.1929</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>20.8944</td>\n",
       "      <td>51.8134</td>\n",
       "      <td>1.0625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.697300</td>\n",
       "      <td>2.656991</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>12.6574</td>\n",
       "      <td>3.0071</td>\n",
       "      <td>49.022</td>\n",
       "      <td>0.8483</td>\n",
       "      <td>4.1860</td>\n",
       "      <td>47.9618</td>\n",
       "      <td>0.7979</td>\n",
       "      <td>11.2109</td>\n",
       "      <td>51.2891</td>\n",
       "      <td>0.9107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.700200</td>\n",
       "      <td>2.655782</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>14.1669</td>\n",
       "      <td>6.7520</td>\n",
       "      <td>42.5729</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>4.0303</td>\n",
       "      <td>52.0338</td>\n",
       "      <td>0.923</td>\n",
       "      <td>10.7115</td>\n",
       "      <td>53.2150</td>\n",
       "      <td>0.9382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.692000</td>\n",
       "      <td>2.647761</td>\n",
       "      <td>0.0476</td>\n",
       "      <td>0.18</td>\n",
       "      <td>13.3206</td>\n",
       "      <td>4.4967</td>\n",
       "      <td>43.1489</td>\n",
       "      <td>0.843</td>\n",
       "      <td>4.4723</td>\n",
       "      <td>48.2549</td>\n",
       "      <td>0.8475</td>\n",
       "      <td>11.4309</td>\n",
       "      <td>53.6075</td>\n",
       "      <td>1.0374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.697600</td>\n",
       "      <td>2.648925</td>\n",
       "      <td>-0.0059</td>\n",
       "      <td>-0.0273</td>\n",
       "      <td>11.6818</td>\n",
       "      <td>2.0561</td>\n",
       "      <td>49.5601</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>3.3189</td>\n",
       "      <td>48.2811</td>\n",
       "      <td>0.8012</td>\n",
       "      <td>10.3356</td>\n",
       "      <td>50.0851</td>\n",
       "      <td>0.8599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.687800</td>\n",
       "      <td>2.651047</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>12.5283</td>\n",
       "      <td>3.421</td>\n",
       "      <td>47.2509</td>\n",
       "      <td>0.8540</td>\n",
       "      <td>4.2719</td>\n",
       "      <td>47.2137</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>10.5760</td>\n",
       "      <td>51.9148</td>\n",
       "      <td>0.9349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-8f2f048d2455>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# kelly betting with fixed overnight labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 2e-5, batch size 1 hidden size 512 only 6 layers,\n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, no rotary embed on conv embed\n",
    "\n",
    "# kelly betting with fixed overnight labels\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='33373' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33373/43942 2:20:37 < 44:32, 3.96 it/s, Epoch 0.76/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.457200</td>\n",
       "      <td>2.384042</td>\n",
       "      <td>-0.0048</td>\n",
       "      <td>-0.0161</td>\n",
       "      <td>12.0932</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>60.3291</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>18.7222</td>\n",
       "      <td>49.2818</td>\n",
       "      <td>0.9395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.400000</td>\n",
       "      <td>2.360933</td>\n",
       "      <td>-0.0228</td>\n",
       "      <td>-0.162</td>\n",
       "      <td>7.0774</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>76.4706</td>\n",
       "      <td>1.3106</td>\n",
       "      <td>2.9561</td>\n",
       "      <td>52.1523</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.385700</td>\n",
       "      <td>2.354809</td>\n",
       "      <td>0.0551</td>\n",
       "      <td>0.203</td>\n",
       "      <td>9.0370</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.007</td>\n",
       "      <td>89.0909</td>\n",
       "      <td>2.5061</td>\n",
       "      <td>5.8879</td>\n",
       "      <td>53.084</td>\n",
       "      <td>0.9571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.380200</td>\n",
       "      <td>2.351374</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.1537</td>\n",
       "      <td>9.2599</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>84.2491</td>\n",
       "      <td>1.4755</td>\n",
       "      <td>7.4314</td>\n",
       "      <td>52.9157</td>\n",
       "      <td>0.9558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.377200</td>\n",
       "      <td>2.354240</td>\n",
       "      <td>0.0153</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>5.4428</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>92.8571</td>\n",
       "      <td>1.1823</td>\n",
       "      <td>0.6153</td>\n",
       "      <td>65.1316</td>\n",
       "      <td>1.0054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.374600</td>\n",
       "      <td>2.366419</td>\n",
       "      <td>0.009</td>\n",
       "      <td>0.0466</td>\n",
       "      <td>6.9713</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>83.4646</td>\n",
       "      <td>1.5051</td>\n",
       "      <td>3.3934</td>\n",
       "      <td>55.761</td>\n",
       "      <td>0.7888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.372200</td>\n",
       "      <td>2.347787</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>5.9032</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0257</td>\n",
       "      <td>66.9951</td>\n",
       "      <td>0.4784</td>\n",
       "      <td>2.4484</td>\n",
       "      <td>58.1628</td>\n",
       "      <td>0.9073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.369900</td>\n",
       "      <td>2.350269</td>\n",
       "      <td>-0.013</td>\n",
       "      <td>-0.0913</td>\n",
       "      <td>6.7157</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>75.4286</td>\n",
       "      <td>0.699</td>\n",
       "      <td>2.604</td>\n",
       "      <td>60.1914</td>\n",
       "      <td>0.9004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.366800</td>\n",
       "      <td>2.361917</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>6.6479</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1384</td>\n",
       "      <td>74.5887</td>\n",
       "      <td>1.1463</td>\n",
       "      <td>2.8265</td>\n",
       "      <td>60.3133</td>\n",
       "      <td>0.9514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.366400</td>\n",
       "      <td>2.344239</td>\n",
       "      <td>0.0346</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>7.0749</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>50.</td>\n",
       "      <td>2.5431</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>60.1246</td>\n",
       "      <td>0.8156</td>\n",
       "      <td>2.0547</td>\n",
       "      <td>59.4312</td>\n",
       "      <td>0.9626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.362900</td>\n",
       "      <td>2.350115</td>\n",
       "      <td>-0.0153</td>\n",
       "      <td>-0.0781</td>\n",
       "      <td>6.4030</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1531</td>\n",
       "      <td>49.0083</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>2.2121</td>\n",
       "      <td>57.1878</td>\n",
       "      <td>0.8502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.363300</td>\n",
       "      <td>2.348323</td>\n",
       "      <td>-0.0017</td>\n",
       "      <td>-0.0095</td>\n",
       "      <td>7.5585</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>58.6207</td>\n",
       "      <td>0.9162</td>\n",
       "      <td>0.4335</td>\n",
       "      <td>61.8033</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>5.5155</td>\n",
       "      <td>54.9159</td>\n",
       "      <td>0.8781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.360700</td>\n",
       "      <td>2.342533</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.2127</td>\n",
       "      <td>6.4056</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>81.6017</td>\n",
       "      <td>0.9204</td>\n",
       "      <td>1.5039</td>\n",
       "      <td>58.1041</td>\n",
       "      <td>0.9342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.360400</td>\n",
       "      <td>2.340984</td>\n",
       "      <td>-0.0052</td>\n",
       "      <td>-0.0383</td>\n",
       "      <td>6.3183</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>80.</td>\n",
       "      <td>1.7877</td>\n",
       "      <td>0.0917</td>\n",
       "      <td>70.4828</td>\n",
       "      <td>1.0957</td>\n",
       "      <td>1.8707</td>\n",
       "      <td>58.104</td>\n",
       "      <td>0.9804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.359900</td>\n",
       "      <td>2.343131</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>7.3074</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>72.9299</td>\n",
       "      <td>0.8955</td>\n",
       "      <td>5.9557</td>\n",
       "      <td>50.4598</td>\n",
       "      <td>0.8966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.358400</td>\n",
       "      <td>2.343443</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>0.1569</td>\n",
       "      <td>7.9026</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>75.</td>\n",
       "      <td>1.2933</td>\n",
       "      <td>0.2134</td>\n",
       "      <td>70.1245</td>\n",
       "      <td>1.0960</td>\n",
       "      <td>3.9678</td>\n",
       "      <td>54.1762</td>\n",
       "      <td>0.8751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.355900</td>\n",
       "      <td>2.342669</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.1649</td>\n",
       "      <td>6.5457</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>78.5714</td>\n",
       "      <td>1.2524</td>\n",
       "      <td>0.401</td>\n",
       "      <td>65.5836</td>\n",
       "      <td>1.1820</td>\n",
       "      <td>2.1654</td>\n",
       "      <td>62.013</td>\n",
       "      <td>0.9947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.356600</td>\n",
       "      <td>2.347079</td>\n",
       "      <td>-0.0076</td>\n",
       "      <td>-0.0747</td>\n",
       "      <td>5.8224</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>83.3333</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.2849</td>\n",
       "      <td>69.627</td>\n",
       "      <td>0.9907</td>\n",
       "      <td>2.9984</td>\n",
       "      <td>60.4117</td>\n",
       "      <td>1.0091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>2.353100</td>\n",
       "      <td>2.338747</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>0.214</td>\n",
       "      <td>7.1482</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>50.</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>0.4670</td>\n",
       "      <td>67.4702</td>\n",
       "      <td>1.0813</td>\n",
       "      <td>4.2593</td>\n",
       "      <td>57.6978</td>\n",
       "      <td>0.861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.355300</td>\n",
       "      <td>2.339464</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>5.5053</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>22.2222</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>67.6471</td>\n",
       "      <td>1.1824</td>\n",
       "      <td>2.3693</td>\n",
       "      <td>63.9848</td>\n",
       "      <td>1.0323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>2.350800</td>\n",
       "      <td>2.340298</td>\n",
       "      <td>0.0313</td>\n",
       "      <td>0.2827</td>\n",
       "      <td>6.2544</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>65.9574</td>\n",
       "      <td>1.4375</td>\n",
       "      <td>0.5365</td>\n",
       "      <td>73.4025</td>\n",
       "      <td>1.1835</td>\n",
       "      <td>3.6525</td>\n",
       "      <td>58.4381</td>\n",
       "      <td>1.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.351500</td>\n",
       "      <td>2.345522</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>6.4914</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>53.9326</td>\n",
       "      <td>1.0327</td>\n",
       "      <td>0.7921</td>\n",
       "      <td>65.7458</td>\n",
       "      <td>1.1549</td>\n",
       "      <td>3.6135</td>\n",
       "      <td>56.6423</td>\n",
       "      <td>0.8217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>2.351100</td>\n",
       "      <td>2.336553</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.143</td>\n",
       "      <td>5.5595</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>40.</td>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.3404</td>\n",
       "      <td>74.9535</td>\n",
       "      <td>1.0753</td>\n",
       "      <td>2.9021</td>\n",
       "      <td>60.476</td>\n",
       "      <td>0.9915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.351500</td>\n",
       "      <td>2.339783</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>6.8474</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>76.9231</td>\n",
       "      <td>1.7362</td>\n",
       "      <td>0.7049</td>\n",
       "      <td>64.6689</td>\n",
       "      <td>1.1769</td>\n",
       "      <td>4.0072</td>\n",
       "      <td>57.7733</td>\n",
       "      <td>0.8132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>2.349500</td>\n",
       "      <td>2.339214</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0966</td>\n",
       "      <td>5.0411</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>74.8658</td>\n",
       "      <td>1.1052</td>\n",
       "      <td>2.2328</td>\n",
       "      <td>62.3555</td>\n",
       "      <td>0.9188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.348200</td>\n",
       "      <td>2.338644</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.093</td>\n",
       "      <td>5.3595</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>22.2222</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.4265</td>\n",
       "      <td>69.6323</td>\n",
       "      <td>1.0908</td>\n",
       "      <td>2.6469</td>\n",
       "      <td>61.6392</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>2.347500</td>\n",
       "      <td>2.335184</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.241</td>\n",
       "      <td>5.5630</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>65.3409</td>\n",
       "      <td>1.0866</td>\n",
       "      <td>0.7009</td>\n",
       "      <td>68.7782</td>\n",
       "      <td>1.1271</td>\n",
       "      <td>3.0520</td>\n",
       "      <td>59.2507</td>\n",
       "      <td>0.9733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.349600</td>\n",
       "      <td>2.346455</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.2192</td>\n",
       "      <td>5.5995</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>79.8387</td>\n",
       "      <td>1.2449</td>\n",
       "      <td>0.7004</td>\n",
       "      <td>71.1215</td>\n",
       "      <td>1.1438</td>\n",
       "      <td>2.9578</td>\n",
       "      <td>60.7236</td>\n",
       "      <td>0.9849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>2.347400</td>\n",
       "      <td>2.333284</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.2400</td>\n",
       "      <td>6.2801</td>\n",
       "      <td>0.0028</td>\n",
       "      <td>54.5455</td>\n",
       "      <td>1.5413</td>\n",
       "      <td>0.4412</td>\n",
       "      <td>72.8784</td>\n",
       "      <td>1.1555</td>\n",
       "      <td>3.4711</td>\n",
       "      <td>56.5213</td>\n",
       "      <td>0.9501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.346700</td>\n",
       "      <td>2.340185</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>6.1704</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>63.0631</td>\n",
       "      <td>1.3868</td>\n",
       "      <td>0.5253</td>\n",
       "      <td>70.5033</td>\n",
       "      <td>1.1212</td>\n",
       "      <td>2.6947</td>\n",
       "      <td>60.231</td>\n",
       "      <td>0.9651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>2.345300</td>\n",
       "      <td>2.340732</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>5.2571</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>42.3077</td>\n",
       "      <td>0.6955</td>\n",
       "      <td>0.3568</td>\n",
       "      <td>72.6338</td>\n",
       "      <td>1.2369</td>\n",
       "      <td>2.2065</td>\n",
       "      <td>61.6372</td>\n",
       "      <td>0.9586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.346500</td>\n",
       "      <td>2.357605</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.18</td>\n",
       "      <td>5.4441</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>42.4242</td>\n",
       "      <td>0.9803</td>\n",
       "      <td>0.6527</td>\n",
       "      <td>71.4535</td>\n",
       "      <td>1.0650</td>\n",
       "      <td>2.5796</td>\n",
       "      <td>60.5943</td>\n",
       "      <td>0.9722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>2.345000</td>\n",
       "      <td>2.335780</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1670</td>\n",
       "      <td>5.5861</td>\n",
       "      <td>0.0168</td>\n",
       "      <td>62.4060</td>\n",
       "      <td>1.3074</td>\n",
       "      <td>0.8126</td>\n",
       "      <td>66.8898</td>\n",
       "      <td>1.1868</td>\n",
       "      <td>3.6739</td>\n",
       "      <td>57.1994</td>\n",
       "      <td>0.8476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.346100</td>\n",
       "      <td>2.336495</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.3446</td>\n",
       "      <td>6.3908</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>33.3333</td>\n",
       "      <td>1.322</td>\n",
       "      <td>0.3589</td>\n",
       "      <td>66.9722</td>\n",
       "      <td>1.1677</td>\n",
       "      <td>5.1498</td>\n",
       "      <td>54.0283</td>\n",
       "      <td>1.0931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>2.345000</td>\n",
       "      <td>2.337394</td>\n",
       "      <td>-0.0101</td>\n",
       "      <td>-0.0607</td>\n",
       "      <td>6.8385</td>\n",
       "      <td>0.0046</td>\n",
       "      <td>44.4444</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.3802</td>\n",
       "      <td>74.3513</td>\n",
       "      <td>1.1551</td>\n",
       "      <td>3.5948</td>\n",
       "      <td>57.0780</td>\n",
       "      <td>1.0402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.345200</td>\n",
       "      <td>2.343632</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>5.7222</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>62.3529</td>\n",
       "      <td>1.3926</td>\n",
       "      <td>0.6151</td>\n",
       "      <td>71.2317</td>\n",
       "      <td>1.1895</td>\n",
       "      <td>3.1129</td>\n",
       "      <td>59.0312</td>\n",
       "      <td>0.9342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>2.344700</td>\n",
       "      <td>2.332627</td>\n",
       "      <td>0.0217</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>6.5359</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>67.3591</td>\n",
       "      <td>1.4275</td>\n",
       "      <td>1.4740</td>\n",
       "      <td>66.455</td>\n",
       "      <td>1.1147</td>\n",
       "      <td>5.3654</td>\n",
       "      <td>53.7355</td>\n",
       "      <td>0.8977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.343700</td>\n",
       "      <td>2.334415</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>6.0831</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>59.5238</td>\n",
       "      <td>1.208</td>\n",
       "      <td>0.7253</td>\n",
       "      <td>69.7593</td>\n",
       "      <td>1.1444</td>\n",
       "      <td>4.9405</td>\n",
       "      <td>57.0920</td>\n",
       "      <td>0.9438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>2.341500</td>\n",
       "      <td>2.334683</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.3051</td>\n",
       "      <td>6.1761</td>\n",
       "      <td>0.0114</td>\n",
       "      <td>53.3333</td>\n",
       "      <td>0.8403</td>\n",
       "      <td>0.6428</td>\n",
       "      <td>68.9886</td>\n",
       "      <td>1.1632</td>\n",
       "      <td>5.4154</td>\n",
       "      <td>54.069</td>\n",
       "      <td>1.0866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.341500</td>\n",
       "      <td>2.335323</td>\n",
       "      <td>0.0301</td>\n",
       "      <td>0.2376</td>\n",
       "      <td>6.0037</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>50.</td>\n",
       "      <td>0.9174</td>\n",
       "      <td>0.5343</td>\n",
       "      <td>70.0521</td>\n",
       "      <td>1.1972</td>\n",
       "      <td>4.7207</td>\n",
       "      <td>53.7379</td>\n",
       "      <td>0.9681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>2.344400</td>\n",
       "      <td>2.333125</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.2805</td>\n",
       "      <td>6.4267</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>73.2759</td>\n",
       "      <td>1.4163</td>\n",
       "      <td>1.0472</td>\n",
       "      <td>66.9525</td>\n",
       "      <td>1.2994</td>\n",
       "      <td>5.7886</td>\n",
       "      <td>51.4903</td>\n",
       "      <td>0.8883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.343100</td>\n",
       "      <td>2.337150</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.2741</td>\n",
       "      <td>6.044</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>64.2857</td>\n",
       "      <td>1.3969</td>\n",
       "      <td>0.6007</td>\n",
       "      <td>67.0457</td>\n",
       "      <td>1.3805</td>\n",
       "      <td>4.4466</td>\n",
       "      <td>54.0352</td>\n",
       "      <td>0.9939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>2.341100</td>\n",
       "      <td>2.332531</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>0.2454</td>\n",
       "      <td>5.6413</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>77.6316</td>\n",
       "      <td>1.5990</td>\n",
       "      <td>1.0309</td>\n",
       "      <td>68.1963</td>\n",
       "      <td>1.393</td>\n",
       "      <td>4.7278</td>\n",
       "      <td>54.4360</td>\n",
       "      <td>1.0356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>2.341200</td>\n",
       "      <td>2.334671</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.1742</td>\n",
       "      <td>6.7236</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>75.4902</td>\n",
       "      <td>1.5261</td>\n",
       "      <td>1.0598</td>\n",
       "      <td>66.1017</td>\n",
       "      <td>1.3193</td>\n",
       "      <td>5.0444</td>\n",
       "      <td>55.3198</td>\n",
       "      <td>0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>2.341100</td>\n",
       "      <td>2.338248</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>7.4978</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>71.3450</td>\n",
       "      <td>1.1303</td>\n",
       "      <td>1.5178</td>\n",
       "      <td>61.7968</td>\n",
       "      <td>1.2446</td>\n",
       "      <td>5.3893</td>\n",
       "      <td>53.2132</td>\n",
       "      <td>0.9378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>2.341400</td>\n",
       "      <td>2.333149</td>\n",
       "      <td>0.0339</td>\n",
       "      <td>0.255</td>\n",
       "      <td>6.4104</td>\n",
       "      <td>0.1345</td>\n",
       "      <td>74.9765</td>\n",
       "      <td>1.2447</td>\n",
       "      <td>1.5989</td>\n",
       "      <td>65.4984</td>\n",
       "      <td>1.1617</td>\n",
       "      <td>4.7146</td>\n",
       "      <td>52.9459</td>\n",
       "      <td>0.8105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>2.341200</td>\n",
       "      <td>2.332998</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.3637</td>\n",
       "      <td>6.0639</td>\n",
       "      <td>0.1892</td>\n",
       "      <td>69.6524</td>\n",
       "      <td>1.1831</td>\n",
       "      <td>1.5972</td>\n",
       "      <td>63.5622</td>\n",
       "      <td>1.2718</td>\n",
       "      <td>5.0366</td>\n",
       "      <td>53.5098</td>\n",
       "      <td>0.9507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>2.341700</td>\n",
       "      <td>2.333272</td>\n",
       "      <td>0.0125</td>\n",
       "      <td>0.1521</td>\n",
       "      <td>5.6962</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>74.7768</td>\n",
       "      <td>1.2420</td>\n",
       "      <td>1.0762</td>\n",
       "      <td>65.5853</td>\n",
       "      <td>1.1994</td>\n",
       "      <td>4.2904</td>\n",
       "      <td>55.1831</td>\n",
       "      <td>0.9854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>2.341500</td>\n",
       "      <td>2.332819</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.2599</td>\n",
       "      <td>5.5440</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>57.4713</td>\n",
       "      <td>0.9782</td>\n",
       "      <td>0.9223</td>\n",
       "      <td>65.6563</td>\n",
       "      <td>1.3118</td>\n",
       "      <td>4.0529</td>\n",
       "      <td>56.1749</td>\n",
       "      <td>1.0376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>2.340200</td>\n",
       "      <td>2.332248</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.2173</td>\n",
       "      <td>6.1097</td>\n",
       "      <td>0.1758</td>\n",
       "      <td>73.0935</td>\n",
       "      <td>1.3448</td>\n",
       "      <td>1.7488</td>\n",
       "      <td>63.3562</td>\n",
       "      <td>1.1889</td>\n",
       "      <td>4.5277</td>\n",
       "      <td>53.9364</td>\n",
       "      <td>0.8682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>2.342900</td>\n",
       "      <td>2.336865</td>\n",
       "      <td>0.0234</td>\n",
       "      <td>0.3077</td>\n",
       "      <td>5.5241</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>64.3357</td>\n",
       "      <td>1.4121</td>\n",
       "      <td>0.686</td>\n",
       "      <td>65.9229</td>\n",
       "      <td>1.2254</td>\n",
       "      <td>3.8904</td>\n",
       "      <td>56.2427</td>\n",
       "      <td>0.9945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>2.338800</td>\n",
       "      <td>2.334391</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>6.1043</td>\n",
       "      <td>0.0567</td>\n",
       "      <td>69.1964</td>\n",
       "      <td>1.4161</td>\n",
       "      <td>1.3741</td>\n",
       "      <td>61.4103</td>\n",
       "      <td>1.2718</td>\n",
       "      <td>4.6699</td>\n",
       "      <td>54.3583</td>\n",
       "      <td>0.9274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>2.336000</td>\n",
       "      <td>2.331765</td>\n",
       "      <td>0.0408</td>\n",
       "      <td>0.2638</td>\n",
       "      <td>7.1599</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>69.0537</td>\n",
       "      <td>1.4846</td>\n",
       "      <td>2.2684</td>\n",
       "      <td>61.0216</td>\n",
       "      <td>1.2047</td>\n",
       "      <td>5.3084</td>\n",
       "      <td>52.2256</td>\n",
       "      <td>0.8868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>2.339200</td>\n",
       "      <td>2.331961</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.3071</td>\n",
       "      <td>6.0258</td>\n",
       "      <td>0.113</td>\n",
       "      <td>71.7805</td>\n",
       "      <td>1.2611</td>\n",
       "      <td>1.5054</td>\n",
       "      <td>62.9107</td>\n",
       "      <td>1.2138</td>\n",
       "      <td>4.7914</td>\n",
       "      <td>53.7105</td>\n",
       "      <td>0.9042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>2.337400</td>\n",
       "      <td>2.339552</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0635</td>\n",
       "      <td>6.2245</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>68.8559</td>\n",
       "      <td>1.2456</td>\n",
       "      <td>1.0523</td>\n",
       "      <td>63.0004</td>\n",
       "      <td>1.2465</td>\n",
       "      <td>3.5881</td>\n",
       "      <td>56.4796</td>\n",
       "      <td>0.9869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>2.337000</td>\n",
       "      <td>2.334130</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>6.0438</td>\n",
       "      <td>0.1510</td>\n",
       "      <td>59.3802</td>\n",
       "      <td>1.5660</td>\n",
       "      <td>1.8107</td>\n",
       "      <td>59.6717</td>\n",
       "      <td>1.2390</td>\n",
       "      <td>4.4577</td>\n",
       "      <td>53.9883</td>\n",
       "      <td>1.0081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>2.336100</td>\n",
       "      <td>2.330685</td>\n",
       "      <td>0.0351</td>\n",
       "      <td>0.3462</td>\n",
       "      <td>6.3769</td>\n",
       "      <td>0.1911</td>\n",
       "      <td>59.7617</td>\n",
       "      <td>1.3532</td>\n",
       "      <td>2.1234</td>\n",
       "      <td>58.4798</td>\n",
       "      <td>1.2315</td>\n",
       "      <td>4.7535</td>\n",
       "      <td>52.1967</td>\n",
       "      <td>0.9493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>2.340200</td>\n",
       "      <td>2.330764</td>\n",
       "      <td>0.0494</td>\n",
       "      <td>0.3517</td>\n",
       "      <td>6.5545</td>\n",
       "      <td>0.1854</td>\n",
       "      <td>66.3711</td>\n",
       "      <td>1.2712</td>\n",
       "      <td>2.1133</td>\n",
       "      <td>59.6157</td>\n",
       "      <td>1.2244</td>\n",
       "      <td>4.9188</td>\n",
       "      <td>51.8567</td>\n",
       "      <td>0.9121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>2.337300</td>\n",
       "      <td>2.331192</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.2461</td>\n",
       "      <td>6.3795</td>\n",
       "      <td>0.1431</td>\n",
       "      <td>53.1388</td>\n",
       "      <td>1.4261</td>\n",
       "      <td>2.0577</td>\n",
       "      <td>59.0275</td>\n",
       "      <td>1.2346</td>\n",
       "      <td>5.1665</td>\n",
       "      <td>53.1584</td>\n",
       "      <td>0.9273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>2.336300</td>\n",
       "      <td>2.334171</td>\n",
       "      <td>0.0211</td>\n",
       "      <td>0.2051</td>\n",
       "      <td>6.0934</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>69.4700</td>\n",
       "      <td>1.1724</td>\n",
       "      <td>1.6228</td>\n",
       "      <td>62.5926</td>\n",
       "      <td>1.1912</td>\n",
       "      <td>4.5383</td>\n",
       "      <td>54.1084</td>\n",
       "      <td>0.9588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>2.335600</td>\n",
       "      <td>2.331812</td>\n",
       "      <td>0.0431</td>\n",
       "      <td>0.2905</td>\n",
       "      <td>6.0466</td>\n",
       "      <td>0.1147</td>\n",
       "      <td>67.2547</td>\n",
       "      <td>1.4576</td>\n",
       "      <td>1.5423</td>\n",
       "      <td>62.6015</td>\n",
       "      <td>1.2186</td>\n",
       "      <td>4.1698</td>\n",
       "      <td>55.1919</td>\n",
       "      <td>0.9512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>2.336000</td>\n",
       "      <td>2.333792</td>\n",
       "      <td>0.0349</td>\n",
       "      <td>0.3036</td>\n",
       "      <td>6.4794</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>66.3489</td>\n",
       "      <td>1.3632</td>\n",
       "      <td>2.2094</td>\n",
       "      <td>61.2355</td>\n",
       "      <td>1.2113</td>\n",
       "      <td>5.1170</td>\n",
       "      <td>52.0332</td>\n",
       "      <td>0.8918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>2.338700</td>\n",
       "      <td>2.332220</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.3347</td>\n",
       "      <td>6.3901</td>\n",
       "      <td>0.2130</td>\n",
       "      <td>56.8884</td>\n",
       "      <td>1.5445</td>\n",
       "      <td>1.9766</td>\n",
       "      <td>58.4859</td>\n",
       "      <td>1.2063</td>\n",
       "      <td>4.8113</td>\n",
       "      <td>53.0471</td>\n",
       "      <td>0.9698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>2.337500</td>\n",
       "      <td>2.339356</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.3066</td>\n",
       "      <td>5.1464</td>\n",
       "      <td>0.0969</td>\n",
       "      <td>68.9295</td>\n",
       "      <td>1.8956</td>\n",
       "      <td>1.4515</td>\n",
       "      <td>61.0283</td>\n",
       "      <td>1.2616</td>\n",
       "      <td>4.1634</td>\n",
       "      <td>55.9245</td>\n",
       "      <td>0.993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>2.336700</td>\n",
       "      <td>2.345249</td>\n",
       "      <td>0.0266</td>\n",
       "      <td>0.2659</td>\n",
       "      <td>6.0978</td>\n",
       "      <td>0.1944</td>\n",
       "      <td>60.3123</td>\n",
       "      <td>1.697</td>\n",
       "      <td>1.7881</td>\n",
       "      <td>59.2105</td>\n",
       "      <td>1.2415</td>\n",
       "      <td>4.8949</td>\n",
       "      <td>53.7639</td>\n",
       "      <td>0.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>2.335400</td>\n",
       "      <td>2.331818</td>\n",
       "      <td>0.0369</td>\n",
       "      <td>0.3541</td>\n",
       "      <td>6.3800</td>\n",
       "      <td>0.3107</td>\n",
       "      <td>53.4609</td>\n",
       "      <td>1.5185</td>\n",
       "      <td>2.0765</td>\n",
       "      <td>58.7658</td>\n",
       "      <td>1.2462</td>\n",
       "      <td>4.8328</td>\n",
       "      <td>53.3948</td>\n",
       "      <td>0.9185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-38d0f3c3b369>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# .5x multiloss as an auxillary with a exp tanh trade loss no trade penalty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1740\u001b[0m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1742\u001b[1;33m                 if (\n\u001b[0m\u001b[0;32m   1743\u001b[0m                     \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1744\u001b[0m                     \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_torch_tpu_available\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub (doesn't trade hours!!)\n",
    "\n",
    "# sru lr of 5e-5, batch size 2 hidden size 448, 60 min, \n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, no rotary embed on conv embed\n",
    "\n",
    "# .5x multiloss as an auxillary with a exp tanh trade loss no trade penalty\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43942' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43942/43942 3:01:27, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.365100</td>\n",
       "      <td>2.271987</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.1120</td>\n",
       "      <td>20.4304</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>58.1633</td>\n",
       "      <td>0.9029</td>\n",
       "      <td>3.9211</td>\n",
       "      <td>52.0662</td>\n",
       "      <td>0.9602</td>\n",
       "      <td>40.9175</td>\n",
       "      <td>50.3591</td>\n",
       "      <td>0.9868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.310700</td>\n",
       "      <td>2.263404</td>\n",
       "      <td>-0.0609</td>\n",
       "      <td>-0.1764</td>\n",
       "      <td>17.0962</td>\n",
       "      <td>0.0732</td>\n",
       "      <td>50.7772</td>\n",
       "      <td>1.3195</td>\n",
       "      <td>2.857</td>\n",
       "      <td>50.5269</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>30.886</td>\n",
       "      <td>49.5561</td>\n",
       "      <td>0.9037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.297700</td>\n",
       "      <td>2.243276</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.3192</td>\n",
       "      <td>14.5861</td>\n",
       "      <td>0.0037</td>\n",
       "      <td>48.2759</td>\n",
       "      <td>1.0854</td>\n",
       "      <td>0.9859</td>\n",
       "      <td>54.1314</td>\n",
       "      <td>0.8972</td>\n",
       "      <td>25.7063</td>\n",
       "      <td>52.7108</td>\n",
       "      <td>1.0102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.289900</td>\n",
       "      <td>2.238785</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.1586</td>\n",
       "      <td>13.2528</td>\n",
       "      <td>0.009</td>\n",
       "      <td>73.2394</td>\n",
       "      <td>0.8262</td>\n",
       "      <td>1.2491</td>\n",
       "      <td>56.1013</td>\n",
       "      <td>0.9362</td>\n",
       "      <td>20.1333</td>\n",
       "      <td>52.0834</td>\n",
       "      <td>0.9609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.285800</td>\n",
       "      <td>2.251485</td>\n",
       "      <td>0.0165</td>\n",
       "      <td>0.0659</td>\n",
       "      <td>12.5112</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>49.4624</td>\n",
       "      <td>0.5482</td>\n",
       "      <td>0.7285</td>\n",
       "      <td>54.4018</td>\n",
       "      <td>0.8398</td>\n",
       "      <td>18.8565</td>\n",
       "      <td>52.6652</td>\n",
       "      <td>0.8978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.279400</td>\n",
       "      <td>2.258569</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.2853</td>\n",
       "      <td>14.188</td>\n",
       "      <td>0.1765</td>\n",
       "      <td>58.7814</td>\n",
       "      <td>0.8465</td>\n",
       "      <td>3.8170</td>\n",
       "      <td>55.6336</td>\n",
       "      <td>0.9862</td>\n",
       "      <td>18.7504</td>\n",
       "      <td>52.1672</td>\n",
       "      <td>0.9844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.274300</td>\n",
       "      <td>2.232306</td>\n",
       "      <td>-0.0223</td>\n",
       "      <td>-0.0792</td>\n",
       "      <td>10.4327</td>\n",
       "      <td>0.083</td>\n",
       "      <td>50.7622</td>\n",
       "      <td>0.885</td>\n",
       "      <td>1.2833</td>\n",
       "      <td>52.7649</td>\n",
       "      <td>0.8490</td>\n",
       "      <td>12.2227</td>\n",
       "      <td>51.3971</td>\n",
       "      <td>0.8517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.271300</td>\n",
       "      <td>2.234195</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.2119</td>\n",
       "      <td>9.6117</td>\n",
       "      <td>0.1504</td>\n",
       "      <td>58.032</td>\n",
       "      <td>0.8308</td>\n",
       "      <td>1.2467</td>\n",
       "      <td>58.7865</td>\n",
       "      <td>0.8671</td>\n",
       "      <td>9.9398</td>\n",
       "      <td>53.4513</td>\n",
       "      <td>0.9155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.265800</td>\n",
       "      <td>2.258793</td>\n",
       "      <td>-0.0031</td>\n",
       "      <td>-0.0074</td>\n",
       "      <td>13.6128</td>\n",
       "      <td>0.4609</td>\n",
       "      <td>57.4369</td>\n",
       "      <td>0.9017</td>\n",
       "      <td>3.7993</td>\n",
       "      <td>55.3303</td>\n",
       "      <td>0.8145</td>\n",
       "      <td>17.6895</td>\n",
       "      <td>50.4719</td>\n",
       "      <td>0.9117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.264300</td>\n",
       "      <td>2.223534</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.1698</td>\n",
       "      <td>8.2806</td>\n",
       "      <td>0.3256</td>\n",
       "      <td>60.4118</td>\n",
       "      <td>0.834</td>\n",
       "      <td>1.1997</td>\n",
       "      <td>62.7162</td>\n",
       "      <td>0.7828</td>\n",
       "      <td>6.9142</td>\n",
       "      <td>53.3360</td>\n",
       "      <td>0.8857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.257700</td>\n",
       "      <td>2.233855</td>\n",
       "      <td>-0.0252</td>\n",
       "      <td>-0.0563</td>\n",
       "      <td>12.9361</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>59.8858</td>\n",
       "      <td>0.8467</td>\n",
       "      <td>2.8327</td>\n",
       "      <td>55.9212</td>\n",
       "      <td>0.7882</td>\n",
       "      <td>14.9590</td>\n",
       "      <td>50.3196</td>\n",
       "      <td>0.9213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.257500</td>\n",
       "      <td>2.234159</td>\n",
       "      <td>0.0111</td>\n",
       "      <td>0.0204</td>\n",
       "      <td>15.1499</td>\n",
       "      <td>1.4038</td>\n",
       "      <td>57.7942</td>\n",
       "      <td>0.7806</td>\n",
       "      <td>5.1495</td>\n",
       "      <td>53.6871</td>\n",
       "      <td>0.8201</td>\n",
       "      <td>17.5749</td>\n",
       "      <td>50.8932</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.254600</td>\n",
       "      <td>2.219925</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.1879</td>\n",
       "      <td>8.7852</td>\n",
       "      <td>0.4866</td>\n",
       "      <td>61.4245</td>\n",
       "      <td>0.9086</td>\n",
       "      <td>1.2862</td>\n",
       "      <td>57.6515</td>\n",
       "      <td>0.7470</td>\n",
       "      <td>8.5499</td>\n",
       "      <td>53.7297</td>\n",
       "      <td>0.9557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.254400</td>\n",
       "      <td>2.222691</td>\n",
       "      <td>-0.0060</td>\n",
       "      <td>-0.0212</td>\n",
       "      <td>10.1249</td>\n",
       "      <td>0.6135</td>\n",
       "      <td>63.1959</td>\n",
       "      <td>0.9168</td>\n",
       "      <td>1.4061</td>\n",
       "      <td>59.0860</td>\n",
       "      <td>0.7410</td>\n",
       "      <td>9.0987</td>\n",
       "      <td>52.4308</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.254500</td>\n",
       "      <td>2.223530</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.1091</td>\n",
       "      <td>9.9071</td>\n",
       "      <td>0.286</td>\n",
       "      <td>72.0478</td>\n",
       "      <td>0.7379</td>\n",
       "      <td>0.8244</td>\n",
       "      <td>57.9101</td>\n",
       "      <td>0.7332</td>\n",
       "      <td>9.8611</td>\n",
       "      <td>51.8459</td>\n",
       "      <td>0.9257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.250300</td>\n",
       "      <td>2.232808</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.1756</td>\n",
       "      <td>10.2303</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>63.8061</td>\n",
       "      <td>0.9873</td>\n",
       "      <td>1.4051</td>\n",
       "      <td>61.9193</td>\n",
       "      <td>0.775</td>\n",
       "      <td>10.7506</td>\n",
       "      <td>51.3060</td>\n",
       "      <td>0.9655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.246300</td>\n",
       "      <td>2.218408</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>8.0596</td>\n",
       "      <td>0.7244</td>\n",
       "      <td>63.2792</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>1.2773</td>\n",
       "      <td>60.7942</td>\n",
       "      <td>0.7453</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>53.5772</td>\n",
       "      <td>0.863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.246900</td>\n",
       "      <td>2.221697</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.093</td>\n",
       "      <td>9.5937</td>\n",
       "      <td>1.1745</td>\n",
       "      <td>66.6667</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>1.7036</td>\n",
       "      <td>59.1699</td>\n",
       "      <td>0.7575</td>\n",
       "      <td>9.2723</td>\n",
       "      <td>50.8369</td>\n",
       "      <td>0.8970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>2.241700</td>\n",
       "      <td>2.221539</td>\n",
       "      <td>0.051</td>\n",
       "      <td>0.2618</td>\n",
       "      <td>8.3613</td>\n",
       "      <td>0.6776</td>\n",
       "      <td>60.3509</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>1.1225</td>\n",
       "      <td>61.6295</td>\n",
       "      <td>0.7830</td>\n",
       "      <td>6.0531</td>\n",
       "      <td>54.6465</td>\n",
       "      <td>0.9313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.247000</td>\n",
       "      <td>2.214571</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.1275</td>\n",
       "      <td>8.7733</td>\n",
       "      <td>1.0276</td>\n",
       "      <td>67.1467</td>\n",
       "      <td>0.9947</td>\n",
       "      <td>1.5684</td>\n",
       "      <td>60.8033</td>\n",
       "      <td>0.7688</td>\n",
       "      <td>6.2930</td>\n",
       "      <td>53.2281</td>\n",
       "      <td>0.8729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>2.238500</td>\n",
       "      <td>2.211366</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.1833</td>\n",
       "      <td>7.7417</td>\n",
       "      <td>0.7137</td>\n",
       "      <td>67.7597</td>\n",
       "      <td>0.7702</td>\n",
       "      <td>1.4644</td>\n",
       "      <td>58.8754</td>\n",
       "      <td>0.7563</td>\n",
       "      <td>5.1232</td>\n",
       "      <td>53.9504</td>\n",
       "      <td>0.8841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.240200</td>\n",
       "      <td>2.229264</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>9.5047</td>\n",
       "      <td>1.2725</td>\n",
       "      <td>64.3837</td>\n",
       "      <td>0.8572</td>\n",
       "      <td>1.9543</td>\n",
       "      <td>60.6343</td>\n",
       "      <td>0.7746</td>\n",
       "      <td>6.7185</td>\n",
       "      <td>52.2198</td>\n",
       "      <td>0.8940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>2.238900</td>\n",
       "      <td>2.215608</td>\n",
       "      <td>0.0058</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>9.6702</td>\n",
       "      <td>1.2768</td>\n",
       "      <td>62.8591</td>\n",
       "      <td>0.7384</td>\n",
       "      <td>2.4323</td>\n",
       "      <td>55.4683</td>\n",
       "      <td>0.787</td>\n",
       "      <td>7.2217</td>\n",
       "      <td>52.3996</td>\n",
       "      <td>0.8854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.239000</td>\n",
       "      <td>2.217757</td>\n",
       "      <td>0.0557</td>\n",
       "      <td>0.2291</td>\n",
       "      <td>9.5305</td>\n",
       "      <td>1.2035</td>\n",
       "      <td>64.3157</td>\n",
       "      <td>0.869</td>\n",
       "      <td>1.8311</td>\n",
       "      <td>59.4708</td>\n",
       "      <td>0.7617</td>\n",
       "      <td>6.5891</td>\n",
       "      <td>53.6119</td>\n",
       "      <td>0.9306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>2.236900</td>\n",
       "      <td>2.216845</td>\n",
       "      <td>0.0131</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>8.0202</td>\n",
       "      <td>0.9691</td>\n",
       "      <td>65.9836</td>\n",
       "      <td>0.7677</td>\n",
       "      <td>1.7359</td>\n",
       "      <td>58.8938</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>5.6499</td>\n",
       "      <td>54.0344</td>\n",
       "      <td>0.8760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.235000</td>\n",
       "      <td>2.213993</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>7.1808</td>\n",
       "      <td>0.8381</td>\n",
       "      <td>63.1452</td>\n",
       "      <td>0.8570</td>\n",
       "      <td>1.4071</td>\n",
       "      <td>63.0259</td>\n",
       "      <td>0.7184</td>\n",
       "      <td>4.2799</td>\n",
       "      <td>54.5382</td>\n",
       "      <td>0.8426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>2.233300</td>\n",
       "      <td>2.207680</td>\n",
       "      <td>0.0322</td>\n",
       "      <td>0.2220</td>\n",
       "      <td>7.2483</td>\n",
       "      <td>1.2902</td>\n",
       "      <td>65.9314</td>\n",
       "      <td>0.9058</td>\n",
       "      <td>1.6549</td>\n",
       "      <td>62.0576</td>\n",
       "      <td>0.7369</td>\n",
       "      <td>4.3314</td>\n",
       "      <td>53.4256</td>\n",
       "      <td>0.8608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.237900</td>\n",
       "      <td>2.223591</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.2304</td>\n",
       "      <td>10.5061</td>\n",
       "      <td>1.7634</td>\n",
       "      <td>63.1949</td>\n",
       "      <td>0.8163</td>\n",
       "      <td>2.9503</td>\n",
       "      <td>57.6188</td>\n",
       "      <td>0.8100</td>\n",
       "      <td>7.8458</td>\n",
       "      <td>52.9568</td>\n",
       "      <td>0.9129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>2.234900</td>\n",
       "      <td>2.208152</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.2376</td>\n",
       "      <td>10.4166</td>\n",
       "      <td>2.2611</td>\n",
       "      <td>63.4573</td>\n",
       "      <td>0.7678</td>\n",
       "      <td>2.8616</td>\n",
       "      <td>57.3841</td>\n",
       "      <td>0.8097</td>\n",
       "      <td>6.5891</td>\n",
       "      <td>51.7671</td>\n",
       "      <td>0.9246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.232400</td>\n",
       "      <td>2.212519</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>8.9545</td>\n",
       "      <td>1.5771</td>\n",
       "      <td>63.0895</td>\n",
       "      <td>0.7714</td>\n",
       "      <td>2.2522</td>\n",
       "      <td>58.5791</td>\n",
       "      <td>0.7193</td>\n",
       "      <td>5.4934</td>\n",
       "      <td>53.1258</td>\n",
       "      <td>0.8905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>2.229000</td>\n",
       "      <td>2.217824</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>9.1429</td>\n",
       "      <td>1.8785</td>\n",
       "      <td>61.8073</td>\n",
       "      <td>0.7666</td>\n",
       "      <td>2.4319</td>\n",
       "      <td>58.837</td>\n",
       "      <td>0.7782</td>\n",
       "      <td>5.571</td>\n",
       "      <td>52.2342</td>\n",
       "      <td>0.8661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.231900</td>\n",
       "      <td>2.231490</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.1848</td>\n",
       "      <td>9.5766</td>\n",
       "      <td>1.9021</td>\n",
       "      <td>65.4186</td>\n",
       "      <td>0.7787</td>\n",
       "      <td>2.0971</td>\n",
       "      <td>58.4233</td>\n",
       "      <td>0.7591</td>\n",
       "      <td>5.1615</td>\n",
       "      <td>52.7019</td>\n",
       "      <td>0.9616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>2.229400</td>\n",
       "      <td>2.210572</td>\n",
       "      <td>0.0517</td>\n",
       "      <td>0.2502</td>\n",
       "      <td>8.7294</td>\n",
       "      <td>2.0358</td>\n",
       "      <td>65.8568</td>\n",
       "      <td>0.8702</td>\n",
       "      <td>1.8515</td>\n",
       "      <td>57.7714</td>\n",
       "      <td>0.7830</td>\n",
       "      <td>5.1402</td>\n",
       "      <td>52.5126</td>\n",
       "      <td>0.9446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.232800</td>\n",
       "      <td>2.212337</td>\n",
       "      <td>0.0796</td>\n",
       "      <td>0.3344</td>\n",
       "      <td>12.4314</td>\n",
       "      <td>2.6070</td>\n",
       "      <td>61.2858</td>\n",
       "      <td>0.8247</td>\n",
       "      <td>3.3547</td>\n",
       "      <td>56.4534</td>\n",
       "      <td>0.8889</td>\n",
       "      <td>10.3926</td>\n",
       "      <td>52.7860</td>\n",
       "      <td>0.9832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>2.230300</td>\n",
       "      <td>2.211809</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>9.4002</td>\n",
       "      <td>1.6989</td>\n",
       "      <td>65.3488</td>\n",
       "      <td>0.8156</td>\n",
       "      <td>1.6223</td>\n",
       "      <td>60.6316</td>\n",
       "      <td>0.7289</td>\n",
       "      <td>4.7712</td>\n",
       "      <td>52.7082</td>\n",
       "      <td>0.9137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.229300</td>\n",
       "      <td>2.224185</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0528</td>\n",
       "      <td>10.0416</td>\n",
       "      <td>2.2665</td>\n",
       "      <td>63.2381</td>\n",
       "      <td>0.8246</td>\n",
       "      <td>2.5034</td>\n",
       "      <td>55.9951</td>\n",
       "      <td>0.8054</td>\n",
       "      <td>6.2704</td>\n",
       "      <td>51.4474</td>\n",
       "      <td>0.9307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>2.229400</td>\n",
       "      <td>2.207183</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.1790</td>\n",
       "      <td>6.4014</td>\n",
       "      <td>1.6369</td>\n",
       "      <td>64.8713</td>\n",
       "      <td>0.8414</td>\n",
       "      <td>1.5847</td>\n",
       "      <td>60.1293</td>\n",
       "      <td>0.7632</td>\n",
       "      <td>3.0075</td>\n",
       "      <td>53.1881</td>\n",
       "      <td>0.8850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.227900</td>\n",
       "      <td>2.210832</td>\n",
       "      <td>0.0122</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>7.6121</td>\n",
       "      <td>1.3969</td>\n",
       "      <td>63.5516</td>\n",
       "      <td>0.7891</td>\n",
       "      <td>1.5966</td>\n",
       "      <td>59.6974</td>\n",
       "      <td>0.7159</td>\n",
       "      <td>3.8231</td>\n",
       "      <td>53.8943</td>\n",
       "      <td>0.9085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>2.224000</td>\n",
       "      <td>2.209961</td>\n",
       "      <td>0.0518</td>\n",
       "      <td>0.3358</td>\n",
       "      <td>6.7310</td>\n",
       "      <td>1.5445</td>\n",
       "      <td>65.9869</td>\n",
       "      <td>0.8654</td>\n",
       "      <td>1.3244</td>\n",
       "      <td>60.6590</td>\n",
       "      <td>0.8057</td>\n",
       "      <td>3.1523</td>\n",
       "      <td>55.4793</td>\n",
       "      <td>0.9154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.222200</td>\n",
       "      <td>2.212795</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>0.2780</td>\n",
       "      <td>7.86</td>\n",
       "      <td>1.7216</td>\n",
       "      <td>64.82</td>\n",
       "      <td>0.8411</td>\n",
       "      <td>1.8625</td>\n",
       "      <td>57.7085</td>\n",
       "      <td>0.8254</td>\n",
       "      <td>4.5594</td>\n",
       "      <td>54.2711</td>\n",
       "      <td>0.9071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>2.229200</td>\n",
       "      <td>2.208822</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.1328</td>\n",
       "      <td>7.8288</td>\n",
       "      <td>1.8295</td>\n",
       "      <td>63.3755</td>\n",
       "      <td>0.7799</td>\n",
       "      <td>2.0315</td>\n",
       "      <td>57.6401</td>\n",
       "      <td>0.7888</td>\n",
       "      <td>4.4471</td>\n",
       "      <td>53.9153</td>\n",
       "      <td>0.8789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.225800</td>\n",
       "      <td>2.222408</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.2911</td>\n",
       "      <td>8.5457</td>\n",
       "      <td>1.7661</td>\n",
       "      <td>62.1114</td>\n",
       "      <td>0.8304</td>\n",
       "      <td>2.4875</td>\n",
       "      <td>56.6997</td>\n",
       "      <td>0.8847</td>\n",
       "      <td>5.8416</td>\n",
       "      <td>54.6675</td>\n",
       "      <td>0.8996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>2.224200</td>\n",
       "      <td>2.206365</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.3067</td>\n",
       "      <td>6.1844</td>\n",
       "      <td>1.533</td>\n",
       "      <td>67.3653</td>\n",
       "      <td>0.8713</td>\n",
       "      <td>1.2904</td>\n",
       "      <td>62.788</td>\n",
       "      <td>0.8377</td>\n",
       "      <td>2.603</td>\n",
       "      <td>55.7051</td>\n",
       "      <td>0.9292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>2.223900</td>\n",
       "      <td>2.214703</td>\n",
       "      <td>0.0577</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>9.3060</td>\n",
       "      <td>2.0450</td>\n",
       "      <td>64.8234</td>\n",
       "      <td>0.8298</td>\n",
       "      <td>1.9818</td>\n",
       "      <td>58.9392</td>\n",
       "      <td>0.8554</td>\n",
       "      <td>4.5699</td>\n",
       "      <td>53.5319</td>\n",
       "      <td>0.9510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>2.222400</td>\n",
       "      <td>2.213845</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.2794</td>\n",
       "      <td>8.9584</td>\n",
       "      <td>2.1457</td>\n",
       "      <td>62.6304</td>\n",
       "      <td>0.8286</td>\n",
       "      <td>2.2851</td>\n",
       "      <td>58.4445</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>5.1891</td>\n",
       "      <td>53.2579</td>\n",
       "      <td>0.9557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>2.225100</td>\n",
       "      <td>2.206667</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>8.2334</td>\n",
       "      <td>2.2054</td>\n",
       "      <td>64.5713</td>\n",
       "      <td>0.8332</td>\n",
       "      <td>1.9576</td>\n",
       "      <td>59.0010</td>\n",
       "      <td>0.8357</td>\n",
       "      <td>4.1697</td>\n",
       "      <td>52.3784</td>\n",
       "      <td>0.9197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>2.224000</td>\n",
       "      <td>2.207264</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>0.4328</td>\n",
       "      <td>7.2431</td>\n",
       "      <td>1.8095</td>\n",
       "      <td>64.8724</td>\n",
       "      <td>0.855</td>\n",
       "      <td>1.4711</td>\n",
       "      <td>60.1634</td>\n",
       "      <td>0.8339</td>\n",
       "      <td>3.1194</td>\n",
       "      <td>54.3855</td>\n",
       "      <td>0.9021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>2.224200</td>\n",
       "      <td>2.207536</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.2947</td>\n",
       "      <td>6.5617</td>\n",
       "      <td>1.7717</td>\n",
       "      <td>64.8008</td>\n",
       "      <td>0.8092</td>\n",
       "      <td>1.6140</td>\n",
       "      <td>58.5266</td>\n",
       "      <td>0.8149</td>\n",
       "      <td>3.2760</td>\n",
       "      <td>54.9095</td>\n",
       "      <td>0.8983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>2.224300</td>\n",
       "      <td>2.212693</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.2339</td>\n",
       "      <td>6.2328</td>\n",
       "      <td>1.3117</td>\n",
       "      <td>65.7184</td>\n",
       "      <td>0.826</td>\n",
       "      <td>1.3659</td>\n",
       "      <td>59.8352</td>\n",
       "      <td>0.8209</td>\n",
       "      <td>2.8102</td>\n",
       "      <td>56.8014</td>\n",
       "      <td>0.8948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>2.219600</td>\n",
       "      <td>2.211394</td>\n",
       "      <td>0.0284</td>\n",
       "      <td>0.1462</td>\n",
       "      <td>9.1692</td>\n",
       "      <td>3.0647</td>\n",
       "      <td>63.3358</td>\n",
       "      <td>0.8301</td>\n",
       "      <td>2.1953</td>\n",
       "      <td>55.909</td>\n",
       "      <td>0.8285</td>\n",
       "      <td>3.9281</td>\n",
       "      <td>51.6423</td>\n",
       "      <td>0.9424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>2.226100</td>\n",
       "      <td>2.213986</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.1742</td>\n",
       "      <td>9.7486</td>\n",
       "      <td>2.8285</td>\n",
       "      <td>59.5322</td>\n",
       "      <td>0.8068</td>\n",
       "      <td>2.9836</td>\n",
       "      <td>56.7643</td>\n",
       "      <td>0.8448</td>\n",
       "      <td>5.6317</td>\n",
       "      <td>53.9014</td>\n",
       "      <td>0.9157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>2.218800</td>\n",
       "      <td>2.210501</td>\n",
       "      <td>0.0267</td>\n",
       "      <td>0.1287</td>\n",
       "      <td>7.6776</td>\n",
       "      <td>2.5875</td>\n",
       "      <td>61.7276</td>\n",
       "      <td>0.7634</td>\n",
       "      <td>1.9357</td>\n",
       "      <td>57.1653</td>\n",
       "      <td>0.8070</td>\n",
       "      <td>3.2372</td>\n",
       "      <td>53.5128</td>\n",
       "      <td>0.8853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>2.215800</td>\n",
       "      <td>2.202265</td>\n",
       "      <td>0.0499</td>\n",
       "      <td>0.2842</td>\n",
       "      <td>7.4736</td>\n",
       "      <td>2.6146</td>\n",
       "      <td>64.4654</td>\n",
       "      <td>0.8915</td>\n",
       "      <td>1.8345</td>\n",
       "      <td>56.7331</td>\n",
       "      <td>0.8469</td>\n",
       "      <td>3.2922</td>\n",
       "      <td>52.6031</td>\n",
       "      <td>0.9187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>2.218700</td>\n",
       "      <td>2.205803</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>0.1203</td>\n",
       "      <td>7.1087</td>\n",
       "      <td>2.3518</td>\n",
       "      <td>63.1239</td>\n",
       "      <td>0.7729</td>\n",
       "      <td>1.7489</td>\n",
       "      <td>57.0881</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>3.0263</td>\n",
       "      <td>53.4671</td>\n",
       "      <td>0.8914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>2.216900</td>\n",
       "      <td>2.220012</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>10.228</td>\n",
       "      <td>2.7302</td>\n",
       "      <td>60.1418</td>\n",
       "      <td>0.7613</td>\n",
       "      <td>2.3118</td>\n",
       "      <td>55.9258</td>\n",
       "      <td>0.8041</td>\n",
       "      <td>4.5208</td>\n",
       "      <td>53.2708</td>\n",
       "      <td>0.8757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>2.216300</td>\n",
       "      <td>2.210311</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1441</td>\n",
       "      <td>7.3566</td>\n",
       "      <td>2.2093</td>\n",
       "      <td>62.3154</td>\n",
       "      <td>0.7899</td>\n",
       "      <td>1.7767</td>\n",
       "      <td>57.9311</td>\n",
       "      <td>0.8183</td>\n",
       "      <td>3.3237</td>\n",
       "      <td>54.5859</td>\n",
       "      <td>0.8483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>2.214100</td>\n",
       "      <td>2.202967</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.2198</td>\n",
       "      <td>7.1966</td>\n",
       "      <td>2.4555</td>\n",
       "      <td>63.2804</td>\n",
       "      <td>0.7942</td>\n",
       "      <td>1.6941</td>\n",
       "      <td>57.2687</td>\n",
       "      <td>0.8539</td>\n",
       "      <td>3.111</td>\n",
       "      <td>53.8383</td>\n",
       "      <td>0.8690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>2.221900</td>\n",
       "      <td>2.201098</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.3339</td>\n",
       "      <td>6.6189</td>\n",
       "      <td>2.1945</td>\n",
       "      <td>63.6751</td>\n",
       "      <td>0.8054</td>\n",
       "      <td>1.5485</td>\n",
       "      <td>59.4511</td>\n",
       "      <td>0.8527</td>\n",
       "      <td>2.7202</td>\n",
       "      <td>54.2478</td>\n",
       "      <td>0.8934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>2.216500</td>\n",
       "      <td>2.202285</td>\n",
       "      <td>0.0308</td>\n",
       "      <td>0.1697</td>\n",
       "      <td>7.398</td>\n",
       "      <td>2.6333</td>\n",
       "      <td>63.6901</td>\n",
       "      <td>0.8347</td>\n",
       "      <td>1.9071</td>\n",
       "      <td>56.6558</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>3.1786</td>\n",
       "      <td>51.9320</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>2.215700</td>\n",
       "      <td>2.205670</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0799</td>\n",
       "      <td>7.0710</td>\n",
       "      <td>2.2485</td>\n",
       "      <td>60.8405</td>\n",
       "      <td>0.7647</td>\n",
       "      <td>1.7457</td>\n",
       "      <td>58.8870</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>3.1827</td>\n",
       "      <td>53.885</td>\n",
       "      <td>0.8722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>2.214400</td>\n",
       "      <td>2.208181</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.2582</td>\n",
       "      <td>7.6317</td>\n",
       "      <td>2.3997</td>\n",
       "      <td>61.3937</td>\n",
       "      <td>0.8204</td>\n",
       "      <td>2.0202</td>\n",
       "      <td>57.9363</td>\n",
       "      <td>0.7897</td>\n",
       "      <td>3.7103</td>\n",
       "      <td>54.3468</td>\n",
       "      <td>0.8793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>2.213100</td>\n",
       "      <td>2.211913</td>\n",
       "      <td>0.0352</td>\n",
       "      <td>0.1933</td>\n",
       "      <td>7.5601</td>\n",
       "      <td>2.7384</td>\n",
       "      <td>62.6172</td>\n",
       "      <td>0.8242</td>\n",
       "      <td>2.0238</td>\n",
       "      <td>56.6910</td>\n",
       "      <td>0.8381</td>\n",
       "      <td>3.4231</td>\n",
       "      <td>53.0670</td>\n",
       "      <td>0.8733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>2.219700</td>\n",
       "      <td>2.209418</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.1912</td>\n",
       "      <td>7.4318</td>\n",
       "      <td>2.5483</td>\n",
       "      <td>61.0692</td>\n",
       "      <td>0.7794</td>\n",
       "      <td>2.0450</td>\n",
       "      <td>57.1844</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>3.5954</td>\n",
       "      <td>54.4047</td>\n",
       "      <td>0.8811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>2.217500</td>\n",
       "      <td>2.215579</td>\n",
       "      <td>0.0293</td>\n",
       "      <td>0.1971</td>\n",
       "      <td>6.0013</td>\n",
       "      <td>2.0125</td>\n",
       "      <td>62.8347</td>\n",
       "      <td>0.7959</td>\n",
       "      <td>1.5610</td>\n",
       "      <td>59.3793</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>2.7099</td>\n",
       "      <td>54.8896</td>\n",
       "      <td>0.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>2.214900</td>\n",
       "      <td>2.223587</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>8.1083</td>\n",
       "      <td>3.0432</td>\n",
       "      <td>60.3375</td>\n",
       "      <td>0.7776</td>\n",
       "      <td>2.2747</td>\n",
       "      <td>56.3143</td>\n",
       "      <td>0.8285</td>\n",
       "      <td>3.6773</td>\n",
       "      <td>53.6824</td>\n",
       "      <td>0.9090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>2.213200</td>\n",
       "      <td>2.206501</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>0.1977</td>\n",
       "      <td>8.1476</td>\n",
       "      <td>3.0368</td>\n",
       "      <td>60.9838</td>\n",
       "      <td>0.809</td>\n",
       "      <td>2.15</td>\n",
       "      <td>57.1571</td>\n",
       "      <td>0.8154</td>\n",
       "      <td>3.503</td>\n",
       "      <td>53.6309</td>\n",
       "      <td>0.8749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>2.213100</td>\n",
       "      <td>2.213908</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.1538</td>\n",
       "      <td>7.709</td>\n",
       "      <td>3.0191</td>\n",
       "      <td>61.0734</td>\n",
       "      <td>0.7748</td>\n",
       "      <td>2.0537</td>\n",
       "      <td>57.3356</td>\n",
       "      <td>0.8266</td>\n",
       "      <td>3.3824</td>\n",
       "      <td>53.2274</td>\n",
       "      <td>0.8951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>2.214200</td>\n",
       "      <td>2.219279</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.2831</td>\n",
       "      <td>6.3931</td>\n",
       "      <td>2.4513</td>\n",
       "      <td>63.5430</td>\n",
       "      <td>0.8293</td>\n",
       "      <td>1.6076</td>\n",
       "      <td>58.2265</td>\n",
       "      <td>0.8064</td>\n",
       "      <td>2.5592</td>\n",
       "      <td>54.1667</td>\n",
       "      <td>0.8597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>2.211200</td>\n",
       "      <td>2.208773</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.2126</td>\n",
       "      <td>7.1431</td>\n",
       "      <td>2.5850</td>\n",
       "      <td>61.2742</td>\n",
       "      <td>0.8173</td>\n",
       "      <td>1.8683</td>\n",
       "      <td>58.0095</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>3.2197</td>\n",
       "      <td>55.0483</td>\n",
       "      <td>0.8656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>2.217500</td>\n",
       "      <td>2.212835</td>\n",
       "      <td>0.0297</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>6.3152</td>\n",
       "      <td>2.2573</td>\n",
       "      <td>63.3287</td>\n",
       "      <td>0.8018</td>\n",
       "      <td>1.4157</td>\n",
       "      <td>59.069</td>\n",
       "      <td>0.8004</td>\n",
       "      <td>2.3421</td>\n",
       "      <td>55.5033</td>\n",
       "      <td>0.8478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>2.214000</td>\n",
       "      <td>2.212973</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.2432</td>\n",
       "      <td>7.4872</td>\n",
       "      <td>2.9344</td>\n",
       "      <td>62.1304</td>\n",
       "      <td>0.8270</td>\n",
       "      <td>1.9274</td>\n",
       "      <td>57.1307</td>\n",
       "      <td>0.8169</td>\n",
       "      <td>3.1817</td>\n",
       "      <td>53.3217</td>\n",
       "      <td>0.8833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>2.210200</td>\n",
       "      <td>2.212424</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.2932</td>\n",
       "      <td>6.9685</td>\n",
       "      <td>2.6398</td>\n",
       "      <td>62.1784</td>\n",
       "      <td>0.8406</td>\n",
       "      <td>1.8536</td>\n",
       "      <td>58.4004</td>\n",
       "      <td>0.8076</td>\n",
       "      <td>3.0079</td>\n",
       "      <td>53.8963</td>\n",
       "      <td>0.8699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>2.214400</td>\n",
       "      <td>2.205915</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.2963</td>\n",
       "      <td>6.4793</td>\n",
       "      <td>2.4061</td>\n",
       "      <td>62.3804</td>\n",
       "      <td>0.8294</td>\n",
       "      <td>1.6479</td>\n",
       "      <td>58.9423</td>\n",
       "      <td>0.8086</td>\n",
       "      <td>2.7455</td>\n",
       "      <td>54.4667</td>\n",
       "      <td>0.8753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>2.208400</td>\n",
       "      <td>2.212064</td>\n",
       "      <td>0.0378</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>6.2426</td>\n",
       "      <td>2.3639</td>\n",
       "      <td>63.0833</td>\n",
       "      <td>0.8331</td>\n",
       "      <td>1.5417</td>\n",
       "      <td>58.9022</td>\n",
       "      <td>0.8137</td>\n",
       "      <td>2.551</td>\n",
       "      <td>54.8371</td>\n",
       "      <td>0.8698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>2.209400</td>\n",
       "      <td>2.206386</td>\n",
       "      <td>0.0430</td>\n",
       "      <td>0.2661</td>\n",
       "      <td>6.7647</td>\n",
       "      <td>2.6942</td>\n",
       "      <td>62.9044</td>\n",
       "      <td>0.8348</td>\n",
       "      <td>1.6966</td>\n",
       "      <td>57.9289</td>\n",
       "      <td>0.8278</td>\n",
       "      <td>2.7773</td>\n",
       "      <td>53.6027</td>\n",
       "      <td>0.8683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>2.212500</td>\n",
       "      <td>2.204891</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1842</td>\n",
       "      <td>7.9045</td>\n",
       "      <td>3.1406</td>\n",
       "      <td>61.3098</td>\n",
       "      <td>0.8083</td>\n",
       "      <td>2.0685</td>\n",
       "      <td>57.0843</td>\n",
       "      <td>0.8078</td>\n",
       "      <td>3.3903</td>\n",
       "      <td>52.8207</td>\n",
       "      <td>0.8827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>2.210900</td>\n",
       "      <td>2.210552</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.2236</td>\n",
       "      <td>6.438</td>\n",
       "      <td>2.5574</td>\n",
       "      <td>62.9983</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>1.5352</td>\n",
       "      <td>58.2022</td>\n",
       "      <td>0.7880</td>\n",
       "      <td>2.4182</td>\n",
       "      <td>54.0671</td>\n",
       "      <td>0.9064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>2.208400</td>\n",
       "      <td>2.209548</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.2662</td>\n",
       "      <td>6.5887</td>\n",
       "      <td>2.6319</td>\n",
       "      <td>62.3108</td>\n",
       "      <td>0.8227</td>\n",
       "      <td>1.7083</td>\n",
       "      <td>58.334</td>\n",
       "      <td>0.7983</td>\n",
       "      <td>2.7735</td>\n",
       "      <td>53.9588</td>\n",
       "      <td>0.8638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>2.208800</td>\n",
       "      <td>2.205755</td>\n",
       "      <td>0.0388</td>\n",
       "      <td>0.2213</td>\n",
       "      <td>7.1465</td>\n",
       "      <td>2.9685</td>\n",
       "      <td>62.1485</td>\n",
       "      <td>0.8190</td>\n",
       "      <td>1.8532</td>\n",
       "      <td>57.1906</td>\n",
       "      <td>0.7988</td>\n",
       "      <td>2.9827</td>\n",
       "      <td>53.0958</td>\n",
       "      <td>0.8758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>2.213700</td>\n",
       "      <td>2.207741</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.2554</td>\n",
       "      <td>6.7209</td>\n",
       "      <td>2.7463</td>\n",
       "      <td>62.4706</td>\n",
       "      <td>0.8274</td>\n",
       "      <td>1.7311</td>\n",
       "      <td>57.4132</td>\n",
       "      <td>0.7933</td>\n",
       "      <td>2.753</td>\n",
       "      <td>53.8917</td>\n",
       "      <td>0.8843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>2.207900</td>\n",
       "      <td>2.208453</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>6.8609</td>\n",
       "      <td>2.7754</td>\n",
       "      <td>62.2943</td>\n",
       "      <td>0.8240</td>\n",
       "      <td>1.7565</td>\n",
       "      <td>57.7056</td>\n",
       "      <td>0.7915</td>\n",
       "      <td>2.8059</td>\n",
       "      <td>53.8094</td>\n",
       "      <td>0.8842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>2.210200</td>\n",
       "      <td>2.207402</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.2492</td>\n",
       "      <td>6.6684</td>\n",
       "      <td>2.7288</td>\n",
       "      <td>62.467</td>\n",
       "      <td>0.8231</td>\n",
       "      <td>1.7285</td>\n",
       "      <td>57.7387</td>\n",
       "      <td>0.788</td>\n",
       "      <td>2.7306</td>\n",
       "      <td>53.8148</td>\n",
       "      <td>0.8900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>2.206800</td>\n",
       "      <td>2.206831</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.2510</td>\n",
       "      <td>6.6597</td>\n",
       "      <td>2.6815</td>\n",
       "      <td>62.5313</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>1.7185</td>\n",
       "      <td>57.8242</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>2.7291</td>\n",
       "      <td>53.7798</td>\n",
       "      <td>0.8807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>2.214200</td>\n",
       "      <td>2.206153</td>\n",
       "      <td>0.0384</td>\n",
       "      <td>0.2377</td>\n",
       "      <td>6.6257</td>\n",
       "      <td>2.6451</td>\n",
       "      <td>62.3069</td>\n",
       "      <td>0.8179</td>\n",
       "      <td>1.6964</td>\n",
       "      <td>57.9972</td>\n",
       "      <td>0.7918</td>\n",
       "      <td>2.7233</td>\n",
       "      <td>54.2152</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>2.206900</td>\n",
       "      <td>2.206577</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.2378</td>\n",
       "      <td>6.5845</td>\n",
       "      <td>2.6302</td>\n",
       "      <td>62.2806</td>\n",
       "      <td>0.8168</td>\n",
       "      <td>1.6990</td>\n",
       "      <td>58.0703</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>2.7226</td>\n",
       "      <td>54.1303</td>\n",
       "      <td>0.8710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>2.207900</td>\n",
       "      <td>2.207183</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>6.5692</td>\n",
       "      <td>2.6236</td>\n",
       "      <td>62.3355</td>\n",
       "      <td>0.8186</td>\n",
       "      <td>1.7075</td>\n",
       "      <td>57.9598</td>\n",
       "      <td>0.7958</td>\n",
       "      <td>2.7283</td>\n",
       "      <td>54.1425</td>\n",
       "      <td>0.8705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>2.212000</td>\n",
       "      <td>2.207158</td>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.2442</td>\n",
       "      <td>6.5584</td>\n",
       "      <td>2.6190</td>\n",
       "      <td>62.3762</td>\n",
       "      <td>0.8197</td>\n",
       "      <td>1.704</td>\n",
       "      <td>57.9541</td>\n",
       "      <td>0.7960</td>\n",
       "      <td>2.7168</td>\n",
       "      <td>54.1717</td>\n",
       "      <td>0.8676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=43942, training_loss=2.2321777246520447, metrics={'train_runtime': 10890.6776, 'train_samples_per_second': 8.07, 'train_steps_per_second': 4.035, 'total_flos': 0.0, 'train_loss': 2.2321777246520447, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 5e-5, batch size 2 hidden size 448, 60 min, \n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, no rotary embed on conv embed\n",
    "\n",
    "# multiloss as an auxillary with a tanh trade loss (with .1 trade penalty)\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='42173' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [42173/43942 2:56:47 < 07:24, 3.98 it/s, Epoch 0.96/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.340100</td>\n",
       "      <td>2.250065</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>11.2118</td>\n",
       "      <td>6.2066</td>\n",
       "      <td>51.7374</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>43.2511</td>\n",
       "      <td>49.8710</td>\n",
       "      <td>1.0035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.294000</td>\n",
       "      <td>2.243068</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>-0.0177</td>\n",
       "      <td>10.4816</td>\n",
       "      <td>4.8305</td>\n",
       "      <td>52.0870</td>\n",
       "      <td>0.8721</td>\n",
       "      <td>40.9087</td>\n",
       "      <td>49.5198</td>\n",
       "      <td>0.9492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.284100</td>\n",
       "      <td>2.235510</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.254</td>\n",
       "      <td>9.199</td>\n",
       "      <td>2.6046</td>\n",
       "      <td>53.6739</td>\n",
       "      <td>0.8981</td>\n",
       "      <td>36.4486</td>\n",
       "      <td>50.8086</td>\n",
       "      <td>0.9949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>2.277900</td>\n",
       "      <td>2.226625</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>10.3973</td>\n",
       "      <td>4.097</td>\n",
       "      <td>54.3086</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>42.0074</td>\n",
       "      <td>50.8738</td>\n",
       "      <td>0.9838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>2.273600</td>\n",
       "      <td>2.237979</td>\n",
       "      <td>-0.0033</td>\n",
       "      <td>-0.0159</td>\n",
       "      <td>11.2904</td>\n",
       "      <td>6.5665</td>\n",
       "      <td>53.0898</td>\n",
       "      <td>0.8942</td>\n",
       "      <td>42.9458</td>\n",
       "      <td>49.7723</td>\n",
       "      <td>0.9334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>2.269900</td>\n",
       "      <td>2.245837</td>\n",
       "      <td>0.0465</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>11.6407</td>\n",
       "      <td>7.8300</td>\n",
       "      <td>51.0476</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>42.7608</td>\n",
       "      <td>51.0877</td>\n",
       "      <td>1.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>2.265200</td>\n",
       "      <td>2.219329</td>\n",
       "      <td>-0.0290</td>\n",
       "      <td>-0.1365</td>\n",
       "      <td>10.3976</td>\n",
       "      <td>4.7116</td>\n",
       "      <td>54.0002</td>\n",
       "      <td>0.8689</td>\n",
       "      <td>40.3156</td>\n",
       "      <td>49.5505</td>\n",
       "      <td>0.8987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>2.265400</td>\n",
       "      <td>2.223316</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>11.4702</td>\n",
       "      <td>6.6306</td>\n",
       "      <td>50.1898</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>44.1822</td>\n",
       "      <td>51.168</td>\n",
       "      <td>1.0187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>2.260100</td>\n",
       "      <td>2.239433</td>\n",
       "      <td>-0.0125</td>\n",
       "      <td>-0.0427</td>\n",
       "      <td>12.3819</td>\n",
       "      <td>8.9430</td>\n",
       "      <td>53.5898</td>\n",
       "      <td>0.9137</td>\n",
       "      <td>44.9982</td>\n",
       "      <td>49.5969</td>\n",
       "      <td>0.9418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>2.260400</td>\n",
       "      <td>2.217421</td>\n",
       "      <td>-0.0241</td>\n",
       "      <td>-0.1066</td>\n",
       "      <td>9.8419</td>\n",
       "      <td>3.7037</td>\n",
       "      <td>53.873</td>\n",
       "      <td>0.8686</td>\n",
       "      <td>38.4656</td>\n",
       "      <td>49.0753</td>\n",
       "      <td>0.9124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>2.254100</td>\n",
       "      <td>2.230823</td>\n",
       "      <td>-0.0301</td>\n",
       "      <td>-0.0936</td>\n",
       "      <td>12.4897</td>\n",
       "      <td>9.4796</td>\n",
       "      <td>52.562</td>\n",
       "      <td>0.8773</td>\n",
       "      <td>44.3968</td>\n",
       "      <td>49.0594</td>\n",
       "      <td>0.9237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>2.252800</td>\n",
       "      <td>2.224249</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0227</td>\n",
       "      <td>13.3441</td>\n",
       "      <td>11.6229</td>\n",
       "      <td>51.7696</td>\n",
       "      <td>0.8574</td>\n",
       "      <td>45.8934</td>\n",
       "      <td>50.4987</td>\n",
       "      <td>0.9614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>2.251500</td>\n",
       "      <td>2.219654</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.1696</td>\n",
       "      <td>11.1435</td>\n",
       "      <td>5.6442</td>\n",
       "      <td>52.2893</td>\n",
       "      <td>0.8553</td>\n",
       "      <td>43.4120</td>\n",
       "      <td>50.9578</td>\n",
       "      <td>0.9849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>2.251300</td>\n",
       "      <td>2.213917</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>12.1922</td>\n",
       "      <td>8.9992</td>\n",
       "      <td>52.0100</td>\n",
       "      <td>0.893</td>\n",
       "      <td>43.7763</td>\n",
       "      <td>49.8587</td>\n",
       "      <td>0.9421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>2.251400</td>\n",
       "      <td>2.217340</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0379</td>\n",
       "      <td>11.7811</td>\n",
       "      <td>7.094</td>\n",
       "      <td>51.7082</td>\n",
       "      <td>0.8933</td>\n",
       "      <td>45.1791</td>\n",
       "      <td>50.7512</td>\n",
       "      <td>0.9349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>2.248400</td>\n",
       "      <td>2.229753</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>15.0721</td>\n",
       "      <td>14.9295</td>\n",
       "      <td>51.3213</td>\n",
       "      <td>0.9222</td>\n",
       "      <td>51.1965</td>\n",
       "      <td>50.7727</td>\n",
       "      <td>1.0154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>2.244200</td>\n",
       "      <td>2.217505</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>11.7214</td>\n",
       "      <td>7.1596</td>\n",
       "      <td>54.2782</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>43.2457</td>\n",
       "      <td>50.3839</td>\n",
       "      <td>0.9418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>2.244800</td>\n",
       "      <td>2.217239</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>10.6042</td>\n",
       "      <td>5.7898</td>\n",
       "      <td>53.7468</td>\n",
       "      <td>0.8807</td>\n",
       "      <td>38.8096</td>\n",
       "      <td>50.9102</td>\n",
       "      <td>0.9343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>2.240100</td>\n",
       "      <td>2.215176</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>0.1960</td>\n",
       "      <td>11.0875</td>\n",
       "      <td>6.1659</td>\n",
       "      <td>53.4824</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>41.8863</td>\n",
       "      <td>51.3653</td>\n",
       "      <td>0.9748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>2.244900</td>\n",
       "      <td>2.209218</td>\n",
       "      <td>0.0271</td>\n",
       "      <td>0.0929</td>\n",
       "      <td>12.0172</td>\n",
       "      <td>8.0096</td>\n",
       "      <td>53.8526</td>\n",
       "      <td>0.8907</td>\n",
       "      <td>43.4842</td>\n",
       "      <td>50.5476</td>\n",
       "      <td>0.9394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>2.236300</td>\n",
       "      <td>2.205822</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.1645</td>\n",
       "      <td>12.0917</td>\n",
       "      <td>9.9715</td>\n",
       "      <td>53.3851</td>\n",
       "      <td>0.8739</td>\n",
       "      <td>40.0008</td>\n",
       "      <td>50.5638</td>\n",
       "      <td>0.9809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>2.239100</td>\n",
       "      <td>2.237077</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.091</td>\n",
       "      <td>11.8632</td>\n",
       "      <td>8.22</td>\n",
       "      <td>53.4609</td>\n",
       "      <td>0.8560</td>\n",
       "      <td>42.4493</td>\n",
       "      <td>50.3935</td>\n",
       "      <td>0.9436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>2.238500</td>\n",
       "      <td>2.209936</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>-0.0145</td>\n",
       "      <td>11.5605</td>\n",
       "      <td>8.0093</td>\n",
       "      <td>53.075</td>\n",
       "      <td>0.8415</td>\n",
       "      <td>40.9687</td>\n",
       "      <td>49.8512</td>\n",
       "      <td>0.9266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>2.239100</td>\n",
       "      <td>2.214078</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.062</td>\n",
       "      <td>11.8899</td>\n",
       "      <td>8.1906</td>\n",
       "      <td>52.7644</td>\n",
       "      <td>0.8665</td>\n",
       "      <td>42.0964</td>\n",
       "      <td>50.5455</td>\n",
       "      <td>0.9311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>2.235700</td>\n",
       "      <td>2.211444</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.018</td>\n",
       "      <td>11.3579</td>\n",
       "      <td>7.7128</td>\n",
       "      <td>54.4609</td>\n",
       "      <td>0.9098</td>\n",
       "      <td>38.5935</td>\n",
       "      <td>50.3187</td>\n",
       "      <td>0.8962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>2.234000</td>\n",
       "      <td>2.214271</td>\n",
       "      <td>-0.0075</td>\n",
       "      <td>-0.0361</td>\n",
       "      <td>11.9422</td>\n",
       "      <td>8.8673</td>\n",
       "      <td>53.3202</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>40.2806</td>\n",
       "      <td>49.8333</td>\n",
       "      <td>0.9064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>2.233800</td>\n",
       "      <td>2.204441</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>0.0784</td>\n",
       "      <td>11.1773</td>\n",
       "      <td>8.2192</td>\n",
       "      <td>54.7093</td>\n",
       "      <td>0.8839</td>\n",
       "      <td>35.8866</td>\n",
       "      <td>50.2240</td>\n",
       "      <td>0.9146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>2.236800</td>\n",
       "      <td>2.220021</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>0.2105</td>\n",
       "      <td>11.9857</td>\n",
       "      <td>9.4620</td>\n",
       "      <td>54.4283</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>38.8790</td>\n",
       "      <td>50.5944</td>\n",
       "      <td>0.9810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>2.234400</td>\n",
       "      <td>2.202725</td>\n",
       "      <td>0.0432</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>12.2241</td>\n",
       "      <td>9.3307</td>\n",
       "      <td>55.1549</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>41.3643</td>\n",
       "      <td>50.4572</td>\n",
       "      <td>0.9827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>2.233000</td>\n",
       "      <td>2.209610</td>\n",
       "      <td>-0.0029</td>\n",
       "      <td>-0.0103</td>\n",
       "      <td>12.5172</td>\n",
       "      <td>9.4837</td>\n",
       "      <td>54.0121</td>\n",
       "      <td>0.8752</td>\n",
       "      <td>43.8379</td>\n",
       "      <td>49.6550</td>\n",
       "      <td>0.9094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>2.229900</td>\n",
       "      <td>2.215399</td>\n",
       "      <td>-0.0094</td>\n",
       "      <td>-0.0527</td>\n",
       "      <td>10.9107</td>\n",
       "      <td>6.1081</td>\n",
       "      <td>55.1421</td>\n",
       "      <td>0.9001</td>\n",
       "      <td>39.5353</td>\n",
       "      <td>50.0499</td>\n",
       "      <td>0.8861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>2.232100</td>\n",
       "      <td>2.245782</td>\n",
       "      <td>-0.0078</td>\n",
       "      <td>-0.0414</td>\n",
       "      <td>11.0582</td>\n",
       "      <td>6.3078</td>\n",
       "      <td>55.4314</td>\n",
       "      <td>0.9278</td>\n",
       "      <td>39.7003</td>\n",
       "      <td>49.6761</td>\n",
       "      <td>0.8856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>2.230400</td>\n",
       "      <td>2.207609</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>11.2903</td>\n",
       "      <td>8.5558</td>\n",
       "      <td>52.7181</td>\n",
       "      <td>0.8938</td>\n",
       "      <td>34.9383</td>\n",
       "      <td>50.9435</td>\n",
       "      <td>0.9613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>2.234100</td>\n",
       "      <td>2.209995</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>12.3192</td>\n",
       "      <td>9.5828</td>\n",
       "      <td>53.1825</td>\n",
       "      <td>0.9473</td>\n",
       "      <td>41.3942</td>\n",
       "      <td>50.7869</td>\n",
       "      <td>0.9462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>2.229600</td>\n",
       "      <td>2.208556</td>\n",
       "      <td>-0.0230</td>\n",
       "      <td>-0.0790</td>\n",
       "      <td>13.3668</td>\n",
       "      <td>9.194</td>\n",
       "      <td>54.5402</td>\n",
       "      <td>0.9261</td>\n",
       "      <td>49.9676</td>\n",
       "      <td>49.1714</td>\n",
       "      <td>0.8955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>2.230000</td>\n",
       "      <td>2.226754</td>\n",
       "      <td>-0.0145</td>\n",
       "      <td>-0.071</td>\n",
       "      <td>11.6597</td>\n",
       "      <td>7.6885</td>\n",
       "      <td>54.7728</td>\n",
       "      <td>0.9129</td>\n",
       "      <td>40.7051</td>\n",
       "      <td>49.6958</td>\n",
       "      <td>0.8816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>2.229500</td>\n",
       "      <td>2.202409</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>11.2546</td>\n",
       "      <td>7.6976</td>\n",
       "      <td>55.0153</td>\n",
       "      <td>0.8878</td>\n",
       "      <td>37.2818</td>\n",
       "      <td>50.1847</td>\n",
       "      <td>0.9229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>2.228600</td>\n",
       "      <td>2.205368</td>\n",
       "      <td>-0.0131</td>\n",
       "      <td>-0.0836</td>\n",
       "      <td>10.8370</td>\n",
       "      <td>7.5319</td>\n",
       "      <td>54.7511</td>\n",
       "      <td>0.9231</td>\n",
       "      <td>35.4842</td>\n",
       "      <td>49.4275</td>\n",
       "      <td>0.8954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>2.225700</td>\n",
       "      <td>2.212288</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.1637</td>\n",
       "      <td>11.2129</td>\n",
       "      <td>6.977</td>\n",
       "      <td>52.5101</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>40.1214</td>\n",
       "      <td>50.9814</td>\n",
       "      <td>0.9673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>2.222500</td>\n",
       "      <td>2.210314</td>\n",
       "      <td>0.0390</td>\n",
       "      <td>0.1708</td>\n",
       "      <td>12.0670</td>\n",
       "      <td>9.4398</td>\n",
       "      <td>52.9808</td>\n",
       "      <td>0.8876</td>\n",
       "      <td>39.8539</td>\n",
       "      <td>51.2688</td>\n",
       "      <td>0.9614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>2.231000</td>\n",
       "      <td>2.206112</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1063</td>\n",
       "      <td>11.4496</td>\n",
       "      <td>9.0442</td>\n",
       "      <td>52.6685</td>\n",
       "      <td>0.9389</td>\n",
       "      <td>35.229</td>\n",
       "      <td>50.5400</td>\n",
       "      <td>0.9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>2.228200</td>\n",
       "      <td>2.206749</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.1762</td>\n",
       "      <td>11.2725</td>\n",
       "      <td>8.3785</td>\n",
       "      <td>53.1772</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>36.3383</td>\n",
       "      <td>51.3485</td>\n",
       "      <td>0.9432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>2.225200</td>\n",
       "      <td>2.201801</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0377</td>\n",
       "      <td>10.3352</td>\n",
       "      <td>6.6339</td>\n",
       "      <td>55.6221</td>\n",
       "      <td>0.9808</td>\n",
       "      <td>32.9159</td>\n",
       "      <td>49.8417</td>\n",
       "      <td>0.8867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>2.226000</td>\n",
       "      <td>2.209673</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>12.3561</td>\n",
       "      <td>9.0264</td>\n",
       "      <td>53.1313</td>\n",
       "      <td>0.9382</td>\n",
       "      <td>42.7679</td>\n",
       "      <td>51.0018</td>\n",
       "      <td>0.9383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>2.225800</td>\n",
       "      <td>2.208384</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.1046</td>\n",
       "      <td>13.1362</td>\n",
       "      <td>9.8669</td>\n",
       "      <td>53.4524</td>\n",
       "      <td>0.9363</td>\n",
       "      <td>45.1298</td>\n",
       "      <td>50.2708</td>\n",
       "      <td>0.9439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>2.225600</td>\n",
       "      <td>2.203817</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.1114</td>\n",
       "      <td>11.9822</td>\n",
       "      <td>9.8397</td>\n",
       "      <td>53.3173</td>\n",
       "      <td>0.9096</td>\n",
       "      <td>35.7143</td>\n",
       "      <td>50.3862</td>\n",
       "      <td>0.9393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>2.225000</td>\n",
       "      <td>2.202343</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.191</td>\n",
       "      <td>12.0153</td>\n",
       "      <td>10.6382</td>\n",
       "      <td>52.4869</td>\n",
       "      <td>0.9625</td>\n",
       "      <td>34.4257</td>\n",
       "      <td>50.7080</td>\n",
       "      <td>0.9479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>2.228000</td>\n",
       "      <td>2.205878</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>11.1367</td>\n",
       "      <td>8.6455</td>\n",
       "      <td>53.2100</td>\n",
       "      <td>0.9202</td>\n",
       "      <td>33.0864</td>\n",
       "      <td>49.9155</td>\n",
       "      <td>0.9188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>2.225500</td>\n",
       "      <td>2.204225</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>10.5956</td>\n",
       "      <td>6.9317</td>\n",
       "      <td>54.0941</td>\n",
       "      <td>0.9043</td>\n",
       "      <td>34.9351</td>\n",
       "      <td>50.3061</td>\n",
       "      <td>0.9388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>2.222300</td>\n",
       "      <td>2.203034</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.046</td>\n",
       "      <td>10.8851</td>\n",
       "      <td>8.4235</td>\n",
       "      <td>54.4306</td>\n",
       "      <td>0.9339</td>\n",
       "      <td>31.2399</td>\n",
       "      <td>49.4206</td>\n",
       "      <td>0.9145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>2.230100</td>\n",
       "      <td>2.206585</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>11.9455</td>\n",
       "      <td>9.5525</td>\n",
       "      <td>52.659</td>\n",
       "      <td>0.9</td>\n",
       "      <td>38.3299</td>\n",
       "      <td>50.5038</td>\n",
       "      <td>0.9259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>2.220900</td>\n",
       "      <td>2.204188</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0374</td>\n",
       "      <td>10.4841</td>\n",
       "      <td>7.1896</td>\n",
       "      <td>52.8221</td>\n",
       "      <td>0.9439</td>\n",
       "      <td>32.9951</td>\n",
       "      <td>50.2837</td>\n",
       "      <td>0.9393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>2.217000</td>\n",
       "      <td>2.198967</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.1722</td>\n",
       "      <td>12.1482</td>\n",
       "      <td>9.0258</td>\n",
       "      <td>52.5465</td>\n",
       "      <td>0.9369</td>\n",
       "      <td>40.3498</td>\n",
       "      <td>51.4413</td>\n",
       "      <td>0.9391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>2.221200</td>\n",
       "      <td>2.202377</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0831</td>\n",
       "      <td>11.344</td>\n",
       "      <td>9.1541</td>\n",
       "      <td>52.3055</td>\n",
       "      <td>0.9079</td>\n",
       "      <td>33.5756</td>\n",
       "      <td>50.5928</td>\n",
       "      <td>0.9189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>2.220300</td>\n",
       "      <td>2.210444</td>\n",
       "      <td>-0.0157</td>\n",
       "      <td>-0.0652</td>\n",
       "      <td>12.5520</td>\n",
       "      <td>9.7573</td>\n",
       "      <td>53.1146</td>\n",
       "      <td>0.9049</td>\n",
       "      <td>42.6176</td>\n",
       "      <td>49.0897</td>\n",
       "      <td>0.8995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>2.220100</td>\n",
       "      <td>2.209617</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>10.6893</td>\n",
       "      <td>8.0017</td>\n",
       "      <td>53.1996</td>\n",
       "      <td>0.9385</td>\n",
       "      <td>31.6348</td>\n",
       "      <td>50.7385</td>\n",
       "      <td>0.9262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>2.217400</td>\n",
       "      <td>2.201338</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>11.0274</td>\n",
       "      <td>8.7786</td>\n",
       "      <td>52.2565</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>31.9166</td>\n",
       "      <td>51.8148</td>\n",
       "      <td>0.9436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>2.224600</td>\n",
       "      <td>2.198941</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.2282</td>\n",
       "      <td>11.2083</td>\n",
       "      <td>9.0346</td>\n",
       "      <td>52.1435</td>\n",
       "      <td>0.9608</td>\n",
       "      <td>32.1511</td>\n",
       "      <td>52.0152</td>\n",
       "      <td>0.9605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>2.218900</td>\n",
       "      <td>2.199956</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.1003</td>\n",
       "      <td>11.0550</td>\n",
       "      <td>9.1849</td>\n",
       "      <td>52.9444</td>\n",
       "      <td>0.9598</td>\n",
       "      <td>30.9225</td>\n",
       "      <td>50.8502</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>2.219100</td>\n",
       "      <td>2.201379</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0457</td>\n",
       "      <td>11.0060</td>\n",
       "      <td>7.8433</td>\n",
       "      <td>53.8383</td>\n",
       "      <td>0.9670</td>\n",
       "      <td>34.1167</td>\n",
       "      <td>50.137</td>\n",
       "      <td>0.9129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>2.216900</td>\n",
       "      <td>2.205085</td>\n",
       "      <td>0.0469</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>11.2119</td>\n",
       "      <td>7.9497</td>\n",
       "      <td>53.7878</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>36.1756</td>\n",
       "      <td>51.5707</td>\n",
       "      <td>0.9548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>2.217200</td>\n",
       "      <td>2.204699</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>0.2102</td>\n",
       "      <td>10.908</td>\n",
       "      <td>9.2909</td>\n",
       "      <td>52.0912</td>\n",
       "      <td>0.961</td>\n",
       "      <td>29.7549</td>\n",
       "      <td>51.4994</td>\n",
       "      <td>0.9424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>2.221700</td>\n",
       "      <td>2.206339</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>11.3933</td>\n",
       "      <td>9.6165</td>\n",
       "      <td>52.5860</td>\n",
       "      <td>0.9466</td>\n",
       "      <td>32.9102</td>\n",
       "      <td>50.8869</td>\n",
       "      <td>0.9414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>2.220400</td>\n",
       "      <td>2.208309</td>\n",
       "      <td>0.0221</td>\n",
       "      <td>0.1494</td>\n",
       "      <td>9.2552</td>\n",
       "      <td>6.6955</td>\n",
       "      <td>54.0807</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>24.7192</td>\n",
       "      <td>51.0526</td>\n",
       "      <td>0.9313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>2.218100</td>\n",
       "      <td>2.221456</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0797</td>\n",
       "      <td>10.5678</td>\n",
       "      <td>8.0762</td>\n",
       "      <td>52.9626</td>\n",
       "      <td>0.9591</td>\n",
       "      <td>30.6265</td>\n",
       "      <td>50.3723</td>\n",
       "      <td>0.9082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>2.219000</td>\n",
       "      <td>2.202700</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>10.7055</td>\n",
       "      <td>8.5486</td>\n",
       "      <td>52.6472</td>\n",
       "      <td>0.9682</td>\n",
       "      <td>30.2468</td>\n",
       "      <td>50.8559</td>\n",
       "      <td>0.9285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>2.216400</td>\n",
       "      <td>2.209294</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1317</td>\n",
       "      <td>10.5815</td>\n",
       "      <td>8.0305</td>\n",
       "      <td>53.4874</td>\n",
       "      <td>0.9583</td>\n",
       "      <td>30.7306</td>\n",
       "      <td>50.4223</td>\n",
       "      <td>0.9268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>2.218100</td>\n",
       "      <td>2.211207</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.2208</td>\n",
       "      <td>10.4176</td>\n",
       "      <td>8.1433</td>\n",
       "      <td>52.9451</td>\n",
       "      <td>0.9722</td>\n",
       "      <td>29.3038</td>\n",
       "      <td>51.4659</td>\n",
       "      <td>0.9474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>2.217100</td>\n",
       "      <td>2.204463</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.1945</td>\n",
       "      <td>10.2172</td>\n",
       "      <td>7.7378</td>\n",
       "      <td>53.2172</td>\n",
       "      <td>0.9663</td>\n",
       "      <td>29.0379</td>\n",
       "      <td>51.0738</td>\n",
       "      <td>0.9276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>2.220900</td>\n",
       "      <td>2.207791</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>10.2381</td>\n",
       "      <td>7.846</td>\n",
       "      <td>53.6073</td>\n",
       "      <td>0.9617</td>\n",
       "      <td>28.4968</td>\n",
       "      <td>50.4763</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>2.218600</td>\n",
       "      <td>2.208206</td>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.2209</td>\n",
       "      <td>10.4470</td>\n",
       "      <td>7.9941</td>\n",
       "      <td>53.4969</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>29.4438</td>\n",
       "      <td>51.2302</td>\n",
       "      <td>0.9475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>2.213800</td>\n",
       "      <td>2.206859</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>10.7103</td>\n",
       "      <td>8.7675</td>\n",
       "      <td>52.6734</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>29.4117</td>\n",
       "      <td>51.4896</td>\n",
       "      <td>0.9425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>2.219000</td>\n",
       "      <td>2.206700</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>0.2454</td>\n",
       "      <td>10.5112</td>\n",
       "      <td>8.2763</td>\n",
       "      <td>52.6051</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>29.3593</td>\n",
       "      <td>51.8839</td>\n",
       "      <td>0.9473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>2.213700</td>\n",
       "      <td>2.209453</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.1938</td>\n",
       "      <td>10.3168</td>\n",
       "      <td>7.9875</td>\n",
       "      <td>52.9170</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>28.8177</td>\n",
       "      <td>51.1823</td>\n",
       "      <td>0.9283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>2.212400</td>\n",
       "      <td>2.203500</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>0.2072</td>\n",
       "      <td>10.5235</td>\n",
       "      <td>8.6394</td>\n",
       "      <td>52.4919</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>28.0881</td>\n",
       "      <td>51.3179</td>\n",
       "      <td>0.9362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>2.216800</td>\n",
       "      <td>2.200491</td>\n",
       "      <td>0.0263</td>\n",
       "      <td>0.1605</td>\n",
       "      <td>11.033</td>\n",
       "      <td>9.0178</td>\n",
       "      <td>52.5705</td>\n",
       "      <td>0.9522</td>\n",
       "      <td>31.0522</td>\n",
       "      <td>50.7890</td>\n",
       "      <td>0.9304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>2.215600</td>\n",
       "      <td>2.206280</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>10.5204</td>\n",
       "      <td>8.6744</td>\n",
       "      <td>52.3813</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>27.6577</td>\n",
       "      <td>51.0878</td>\n",
       "      <td>0.9222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>2.211800</td>\n",
       "      <td>2.204585</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.2107</td>\n",
       "      <td>10.6587</td>\n",
       "      <td>8.781</td>\n",
       "      <td>52.3589</td>\n",
       "      <td>0.9554</td>\n",
       "      <td>28.6007</td>\n",
       "      <td>51.5453</td>\n",
       "      <td>0.9417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>2.214900</td>\n",
       "      <td>2.201114</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>0.1891</td>\n",
       "      <td>10.685</td>\n",
       "      <td>8.7578</td>\n",
       "      <td>52.7471</td>\n",
       "      <td>0.9457</td>\n",
       "      <td>28.7795</td>\n",
       "      <td>51.2515</td>\n",
       "      <td>0.9354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>2.217100</td>\n",
       "      <td>2.203322</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.192</td>\n",
       "      <td>10.591</td>\n",
       "      <td>8.6976</td>\n",
       "      <td>52.5684</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>28.3595</td>\n",
       "      <td>51.3499</td>\n",
       "      <td>0.9350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>2.214100</td>\n",
       "      <td>2.204177</td>\n",
       "      <td>0.0327</td>\n",
       "      <td>0.1997</td>\n",
       "      <td>10.6507</td>\n",
       "      <td>8.7688</td>\n",
       "      <td>52.5641</td>\n",
       "      <td>0.9540</td>\n",
       "      <td>28.5289</td>\n",
       "      <td>51.3701</td>\n",
       "      <td>0.9358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>2.214000</td>\n",
       "      <td>2.202639</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.2033</td>\n",
       "      <td>10.6176</td>\n",
       "      <td>8.7266</td>\n",
       "      <td>52.7185</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>28.4053</td>\n",
       "      <td>51.3785</td>\n",
       "      <td>0.9388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>2.209900</td>\n",
       "      <td>2.202451</td>\n",
       "      <td>0.0337</td>\n",
       "      <td>0.2071</td>\n",
       "      <td>10.6791</td>\n",
       "      <td>8.7291</td>\n",
       "      <td>52.8033</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>28.9659</td>\n",
       "      <td>51.399</td>\n",
       "      <td>0.9408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>2.218800</td>\n",
       "      <td>2.201995</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.1985</td>\n",
       "      <td>10.6274</td>\n",
       "      <td>8.6274</td>\n",
       "      <td>52.829</td>\n",
       "      <td>0.9557</td>\n",
       "      <td>28.8784</td>\n",
       "      <td>51.2941</td>\n",
       "      <td>0.9377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7dfe00015223>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# weight decay, head size of 64, NO diagonal attention allowed, no rotary embed on conv embed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1738\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2479\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_grad_scaling\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2480\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2481\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_apex\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2482\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mamp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mscaled_loss\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    395\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 396\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    397\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    398\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    171\u001b[0m     \u001b[1;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub (no volume)\n",
    "\n",
    "# sru lr of 1e-4, batch size 1 hidden size 448, 60 min, \n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed, no rotary embed on conv embed\n",
    "\n",
    "# multiloss with estimated kelly betting\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='35539' max='43942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [35539/43942 2:15:24 < 32:01, 4.37 it/s, Epoch 0.81/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.712900</td>\n",
       "      <td>0.702702</td>\n",
       "      <td>-0.0407</td>\n",
       "      <td>-0.1414</td>\n",
       "      <td>11.0819</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>48.9510</td>\n",
       "      <td>0.7216</td>\n",
       "      <td>15.0973</td>\n",
       "      <td>49.4759</td>\n",
       "      <td>0.9027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.701000</td>\n",
       "      <td>0.695547</td>\n",
       "      <td>-0.0088</td>\n",
       "      <td>-0.0551</td>\n",
       "      <td>7.7724</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>60.</td>\n",
       "      <td>1.1202</td>\n",
       "      <td>3.312</td>\n",
       "      <td>53.8441</td>\n",
       "      <td>0.8659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.697700</td>\n",
       "      <td>0.693413</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.3032</td>\n",
       "      <td>7.3341</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>92.3077</td>\n",
       "      <td>1.8466</td>\n",
       "      <td>2.6501</td>\n",
       "      <td>52.5894</td>\n",
       "      <td>0.9571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.696400</td>\n",
       "      <td>0.692905</td>\n",
       "      <td>0.0128</td>\n",
       "      <td>0.1226</td>\n",
       "      <td>6.7059</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>92.3077</td>\n",
       "      <td>1.7545</td>\n",
       "      <td>1.4597</td>\n",
       "      <td>58.7695</td>\n",
       "      <td>0.8097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.695300</td>\n",
       "      <td>0.692987</td>\n",
       "      <td>0.0123</td>\n",
       "      <td>0.1379</td>\n",
       "      <td>6.4725</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>88.8889</td>\n",
       "      <td>1.8710</td>\n",
       "      <td>1.6033</td>\n",
       "      <td>59.8422</td>\n",
       "      <td>0.8481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693400</td>\n",
       "      <td>0.693709</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>0.1745</td>\n",
       "      <td>8.4820</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>81.6176</td>\n",
       "      <td>1.0397</td>\n",
       "      <td>5.2247</td>\n",
       "      <td>52.5688</td>\n",
       "      <td>0.9962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.693600</td>\n",
       "      <td>0.692260</td>\n",
       "      <td>0.0156</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>6.2218</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0218</td>\n",
       "      <td>77.907</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>2.2557</td>\n",
       "      <td>61.0834</td>\n",
       "      <td>0.8756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.692800</td>\n",
       "      <td>0.692575</td>\n",
       "      <td>0.0148</td>\n",
       "      <td>0.1766</td>\n",
       "      <td>5.983</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>80.6338</td>\n",
       "      <td>0.9032</td>\n",
       "      <td>2.0278</td>\n",
       "      <td>60.3019</td>\n",
       "      <td>0.9118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>0.691798</td>\n",
       "      <td>0.0183</td>\n",
       "      <td>0.2283</td>\n",
       "      <td>5.6482</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>84.3972</td>\n",
       "      <td>1.0914</td>\n",
       "      <td>1.8684</td>\n",
       "      <td>64.7959</td>\n",
       "      <td>1.0265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.692300</td>\n",
       "      <td>0.691543</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.282</td>\n",
       "      <td>5.2993</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>83.3333</td>\n",
       "      <td>1.0570</td>\n",
       "      <td>1.9293</td>\n",
       "      <td>63.1983</td>\n",
       "      <td>1.1086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.692100</td>\n",
       "      <td>0.692663</td>\n",
       "      <td>0.0068</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>5.4611</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>66.6667</td>\n",
       "      <td>2.5503</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>82.4417</td>\n",
       "      <td>1.1379</td>\n",
       "      <td>1.4217</td>\n",
       "      <td>63.9203</td>\n",
       "      <td>1.1037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.691800</td>\n",
       "      <td>0.693552</td>\n",
       "      <td>0.0158</td>\n",
       "      <td>0.0837</td>\n",
       "      <td>7.3629</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1455</td>\n",
       "      <td>77.8261</td>\n",
       "      <td>1.1526</td>\n",
       "      <td>4.2088</td>\n",
       "      <td>54.8793</td>\n",
       "      <td>0.8754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.692900</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>5.8145</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>89.0459</td>\n",
       "      <td>1.7541</td>\n",
       "      <td>1.2619</td>\n",
       "      <td>62.1592</td>\n",
       "      <td>0.9287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.692874</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0235</td>\n",
       "      <td>5.7884</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>82.4092</td>\n",
       "      <td>1.2032</td>\n",
       "      <td>1.5804</td>\n",
       "      <td>63.4865</td>\n",
       "      <td>1.0665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.691700</td>\n",
       "      <td>0.692239</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.0651</td>\n",
       "      <td>5.126</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>87.5536</td>\n",
       "      <td>1.6721</td>\n",
       "      <td>1.0738</td>\n",
       "      <td>56.9914</td>\n",
       "      <td>1.2194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.692606</td>\n",
       "      <td>0.0511</td>\n",
       "      <td>0.2192</td>\n",
       "      <td>8.5777</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1699</td>\n",
       "      <td>80.1191</td>\n",
       "      <td>1.0846</td>\n",
       "      <td>5.941</td>\n",
       "      <td>55.2771</td>\n",
       "      <td>0.9754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.691100</td>\n",
       "      <td>0.691383</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>5.9734</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1992</td>\n",
       "      <td>83.9365</td>\n",
       "      <td>1.0184</td>\n",
       "      <td>2.6171</td>\n",
       "      <td>60.493</td>\n",
       "      <td>1.1143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.691663</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.1292</td>\n",
       "      <td>4.999</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>84.4607</td>\n",
       "      <td>1.4069</td>\n",
       "      <td>1.2524</td>\n",
       "      <td>64.9429</td>\n",
       "      <td>1.2116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.690469</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.4147</td>\n",
       "      <td>5.3392</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>81.5524</td>\n",
       "      <td>1.2902</td>\n",
       "      <td>2.3192</td>\n",
       "      <td>62.4489</td>\n",
       "      <td>1.0609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.691976</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>5.7248</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>77.0596</td>\n",
       "      <td>0.9874</td>\n",
       "      <td>2.4603</td>\n",
       "      <td>61.4139</td>\n",
       "      <td>1.0498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.690122</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.3880</td>\n",
       "      <td>5.427</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1189</td>\n",
       "      <td>86.8085</td>\n",
       "      <td>1.4166</td>\n",
       "      <td>2.422</td>\n",
       "      <td>66.9557</td>\n",
       "      <td>1.1512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.691039</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.2403</td>\n",
       "      <td>5.9856</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>76.2279</td>\n",
       "      <td>1.2730</td>\n",
       "      <td>2.7191</td>\n",
       "      <td>62.5279</td>\n",
       "      <td>0.9097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.692008</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>6.2387</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0963</td>\n",
       "      <td>83.7057</td>\n",
       "      <td>0.8812</td>\n",
       "      <td>2.4965</td>\n",
       "      <td>61.6386</td>\n",
       "      <td>1.1719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.690700</td>\n",
       "      <td>0.691285</td>\n",
       "      <td>0.0350</td>\n",
       "      <td>0.2142</td>\n",
       "      <td>6.5041</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>81.4465</td>\n",
       "      <td>1.2038</td>\n",
       "      <td>1.9113</td>\n",
       "      <td>65.3872</td>\n",
       "      <td>1.1227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.691742</td>\n",
       "      <td>0.0081</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>5.7973</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>50.</td>\n",
       "      <td>1.4590</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>79.8429</td>\n",
       "      <td>0.9939</td>\n",
       "      <td>2.5477</td>\n",
       "      <td>64.3563</td>\n",
       "      <td>1.0318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.690400</td>\n",
       "      <td>0.692095</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0924</td>\n",
       "      <td>6.0237</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1918</td>\n",
       "      <td>80.2111</td>\n",
       "      <td>1.2356</td>\n",
       "      <td>3.6516</td>\n",
       "      <td>58.8922</td>\n",
       "      <td>0.9054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.690738</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>5.0063</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1566</td>\n",
       "      <td>81.4216</td>\n",
       "      <td>1.2528</td>\n",
       "      <td>1.8494</td>\n",
       "      <td>64.5236</td>\n",
       "      <td>1.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.691729</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.1395</td>\n",
       "      <td>5.8357</td>\n",
       "      <td>0.0008</td>\n",
       "      <td>83.3333</td>\n",
       "      <td>10.5052</td>\n",
       "      <td>0.4388</td>\n",
       "      <td>72.0957</td>\n",
       "      <td>1.3760</td>\n",
       "      <td>2.5511</td>\n",
       "      <td>61.9744</td>\n",
       "      <td>0.9772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.690400</td>\n",
       "      <td>0.690788</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>6.5792</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1813</td>\n",
       "      <td>80.4606</td>\n",
       "      <td>1.4319</td>\n",
       "      <td>2.5964</td>\n",
       "      <td>60.8156</td>\n",
       "      <td>0.9865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.690538</td>\n",
       "      <td>0.0216</td>\n",
       "      <td>0.3453</td>\n",
       "      <td>5.6589</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2114</td>\n",
       "      <td>84.0215</td>\n",
       "      <td>1.0297</td>\n",
       "      <td>2.4137</td>\n",
       "      <td>64.3276</td>\n",
       "      <td>1.2055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.692203</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>6.4476</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2178</td>\n",
       "      <td>75.0871</td>\n",
       "      <td>1.0851</td>\n",
       "      <td>2.3719</td>\n",
       "      <td>62.4180</td>\n",
       "      <td>1.0443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>0.690889</td>\n",
       "      <td>0.0288</td>\n",
       "      <td>0.3574</td>\n",
       "      <td>6.1329</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>69.697</td>\n",
       "      <td>1.2090</td>\n",
       "      <td>0.5318</td>\n",
       "      <td>74.9762</td>\n",
       "      <td>1.1603</td>\n",
       "      <td>3.3284</td>\n",
       "      <td>60.5404</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.691111</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.3807</td>\n",
       "      <td>5.5692</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>71.4286</td>\n",
       "      <td>1.2749</td>\n",
       "      <td>0.3073</td>\n",
       "      <td>76.6982</td>\n",
       "      <td>1.1952</td>\n",
       "      <td>3.0236</td>\n",
       "      <td>58.8545</td>\n",
       "      <td>1.0229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>0.690986</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.4548</td>\n",
       "      <td>7.9502</td>\n",
       "      <td>0.0091</td>\n",
       "      <td>76.3889</td>\n",
       "      <td>1.5647</td>\n",
       "      <td>0.4011</td>\n",
       "      <td>77.1365</td>\n",
       "      <td>1.1562</td>\n",
       "      <td>4.9917</td>\n",
       "      <td>57.3539</td>\n",
       "      <td>0.9882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.691848</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.2262</td>\n",
       "      <td>7.3860</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>70.2703</td>\n",
       "      <td>1.9844</td>\n",
       "      <td>0.4057</td>\n",
       "      <td>75.3664</td>\n",
       "      <td>1.1135</td>\n",
       "      <td>4.3775</td>\n",
       "      <td>58.5315</td>\n",
       "      <td>1.0384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.695585</td>\n",
       "      <td>-0.0026</td>\n",
       "      <td>-0.0127</td>\n",
       "      <td>9.1032</td>\n",
       "      <td>0.0035</td>\n",
       "      <td>50.</td>\n",
       "      <td>1.3358</td>\n",
       "      <td>0.5729</td>\n",
       "      <td>69.2868</td>\n",
       "      <td>1.2516</td>\n",
       "      <td>6.3583</td>\n",
       "      <td>55.3237</td>\n",
       "      <td>0.8947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.690984</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.3734</td>\n",
       "      <td>5.9693</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>68.4211</td>\n",
       "      <td>2.0717</td>\n",
       "      <td>0.55</td>\n",
       "      <td>69.2962</td>\n",
       "      <td>1.1231</td>\n",
       "      <td>3.8379</td>\n",
       "      <td>58.1655</td>\n",
       "      <td>1.0316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.690610</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>0.2272</td>\n",
       "      <td>4.8219</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>25.</td>\n",
       "      <td>0.2669</td>\n",
       "      <td>0.2064</td>\n",
       "      <td>81.7402</td>\n",
       "      <td>1.0169</td>\n",
       "      <td>2.4836</td>\n",
       "      <td>64.5768</td>\n",
       "      <td>1.2006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.690180</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.3830</td>\n",
       "      <td>6.1323</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>68.</td>\n",
       "      <td>1.2693</td>\n",
       "      <td>0.4131</td>\n",
       "      <td>75.1378</td>\n",
       "      <td>1.1867</td>\n",
       "      <td>3.1031</td>\n",
       "      <td>60.9164</td>\n",
       "      <td>1.1302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.690205</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.3345</td>\n",
       "      <td>5.7763</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>50.</td>\n",
       "      <td>0.9328</td>\n",
       "      <td>0.2647</td>\n",
       "      <td>79.6464</td>\n",
       "      <td>1.1138</td>\n",
       "      <td>2.8828</td>\n",
       "      <td>61.5182</td>\n",
       "      <td>1.1073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.689795</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.4701</td>\n",
       "      <td>5.3167</td>\n",
       "      <td>0.0259</td>\n",
       "      <td>72.1951</td>\n",
       "      <td>1.0277</td>\n",
       "      <td>0.4673</td>\n",
       "      <td>77.4499</td>\n",
       "      <td>1.2749</td>\n",
       "      <td>2.9903</td>\n",
       "      <td>60.2665</td>\n",
       "      <td>1.1524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.691162</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.3596</td>\n",
       "      <td>7.2236</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>68.2927</td>\n",
       "      <td>1.4391</td>\n",
       "      <td>0.3839</td>\n",
       "      <td>68.7315</td>\n",
       "      <td>1.2681</td>\n",
       "      <td>4.9459</td>\n",
       "      <td>55.4041</td>\n",
       "      <td>0.9397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.690905</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.1255</td>\n",
       "      <td>5.3427</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>77.5</td>\n",
       "      <td>1.4216</td>\n",
       "      <td>0.4829</td>\n",
       "      <td>78.3918</td>\n",
       "      <td>1.3128</td>\n",
       "      <td>3.3295</td>\n",
       "      <td>60.9870</td>\n",
       "      <td>1.0525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.689761</td>\n",
       "      <td>0.0348</td>\n",
       "      <td>0.3346</td>\n",
       "      <td>5.8638</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>61.2500</td>\n",
       "      <td>1.1319</td>\n",
       "      <td>0.3222</td>\n",
       "      <td>75.6184</td>\n",
       "      <td>1.1298</td>\n",
       "      <td>3.5302</td>\n",
       "      <td>61.4519</td>\n",
       "      <td>1.1602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.690825</td>\n",
       "      <td>0.0403</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>6.5228</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>71.9697</td>\n",
       "      <td>0.8079</td>\n",
       "      <td>0.6925</td>\n",
       "      <td>73.4977</td>\n",
       "      <td>1.2317</td>\n",
       "      <td>4.2715</td>\n",
       "      <td>57.7157</td>\n",
       "      <td>0.9943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.691149</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.2481</td>\n",
       "      <td>6.0713</td>\n",
       "      <td>0.028</td>\n",
       "      <td>69.6833</td>\n",
       "      <td>0.8751</td>\n",
       "      <td>0.6853</td>\n",
       "      <td>74.5847</td>\n",
       "      <td>1.2118</td>\n",
       "      <td>4.0402</td>\n",
       "      <td>58.8197</td>\n",
       "      <td>1.0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.689300</td>\n",
       "      <td>0.690467</td>\n",
       "      <td>0.0415</td>\n",
       "      <td>0.3588</td>\n",
       "      <td>5.9250</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>73.8764</td>\n",
       "      <td>0.9044</td>\n",
       "      <td>0.7032</td>\n",
       "      <td>73.0347</td>\n",
       "      <td>1.1815</td>\n",
       "      <td>4.1874</td>\n",
       "      <td>59.2376</td>\n",
       "      <td>1.0905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.689100</td>\n",
       "      <td>0.690797</td>\n",
       "      <td>0.0242</td>\n",
       "      <td>0.2775</td>\n",
       "      <td>5.2144</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>65.1613</td>\n",
       "      <td>0.8141</td>\n",
       "      <td>0.3697</td>\n",
       "      <td>73.1782</td>\n",
       "      <td>1.1211</td>\n",
       "      <td>2.8785</td>\n",
       "      <td>63.5657</td>\n",
       "      <td>1.1436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>0.691112</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.3359</td>\n",
       "      <td>5.6386</td>\n",
       "      <td>0.0108</td>\n",
       "      <td>62.3529</td>\n",
       "      <td>1.0831</td>\n",
       "      <td>0.2769</td>\n",
       "      <td>76.1535</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>2.9053</td>\n",
       "      <td>62.9659</td>\n",
       "      <td>1.1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.691675</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.2211</td>\n",
       "      <td>5.5683</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>75.3846</td>\n",
       "      <td>1.4756</td>\n",
       "      <td>0.7597</td>\n",
       "      <td>68.2651</td>\n",
       "      <td>1.2209</td>\n",
       "      <td>4.5995</td>\n",
       "      <td>58.1926</td>\n",
       "      <td>0.9404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.689100</td>\n",
       "      <td>0.690910</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.2316</td>\n",
       "      <td>6.2706</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>68.9189</td>\n",
       "      <td>1.2379</td>\n",
       "      <td>0.3365</td>\n",
       "      <td>73.8346</td>\n",
       "      <td>1.0983</td>\n",
       "      <td>3.4301</td>\n",
       "      <td>60.593</td>\n",
       "      <td>1.097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.691141</td>\n",
       "      <td>0.0276</td>\n",
       "      <td>0.2801</td>\n",
       "      <td>5.7499</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>64.3939</td>\n",
       "      <td>1.1938</td>\n",
       "      <td>0.7726</td>\n",
       "      <td>66.8795</td>\n",
       "      <td>1.1595</td>\n",
       "      <td>4.3240</td>\n",
       "      <td>59.1359</td>\n",
       "      <td>1.0402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>0.689543</td>\n",
       "      <td>0.0548</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>6.5466</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>70.2290</td>\n",
       "      <td>1.1434</td>\n",
       "      <td>0.5473</td>\n",
       "      <td>70.1179</td>\n",
       "      <td>1.1203</td>\n",
       "      <td>4.4950</td>\n",
       "      <td>57.9609</td>\n",
       "      <td>1.0708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.689545</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.5144</td>\n",
       "      <td>5.9793</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>69.0909</td>\n",
       "      <td>1.0071</td>\n",
       "      <td>0.5501</td>\n",
       "      <td>70.407</td>\n",
       "      <td>1.1636</td>\n",
       "      <td>4.4495</td>\n",
       "      <td>57.5733</td>\n",
       "      <td>1.0847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.689200</td>\n",
       "      <td>0.690794</td>\n",
       "      <td>0.0193</td>\n",
       "      <td>0.1943</td>\n",
       "      <td>5.5968</td>\n",
       "      <td>0.0157</td>\n",
       "      <td>70.9677</td>\n",
       "      <td>1.1659</td>\n",
       "      <td>0.3538</td>\n",
       "      <td>73.3643</td>\n",
       "      <td>0.9954</td>\n",
       "      <td>3.0682</td>\n",
       "      <td>62.2279</td>\n",
       "      <td>1.1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.691038</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.4452</td>\n",
       "      <td>6.4271</td>\n",
       "      <td>0.0317</td>\n",
       "      <td>70.1195</td>\n",
       "      <td>1.1056</td>\n",
       "      <td>1.2043</td>\n",
       "      <td>64.2264</td>\n",
       "      <td>1.1432</td>\n",
       "      <td>4.8865</td>\n",
       "      <td>55.0050</td>\n",
       "      <td>1.0719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.690679</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.4311</td>\n",
       "      <td>6.0074</td>\n",
       "      <td>0.0487</td>\n",
       "      <td>72.4675</td>\n",
       "      <td>0.7995</td>\n",
       "      <td>1.0608</td>\n",
       "      <td>64.6315</td>\n",
       "      <td>1.1729</td>\n",
       "      <td>4.4491</td>\n",
       "      <td>56.1112</td>\n",
       "      <td>1.1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.689829</td>\n",
       "      <td>0.0514</td>\n",
       "      <td>0.4373</td>\n",
       "      <td>5.6456</td>\n",
       "      <td>0.0471</td>\n",
       "      <td>73.6559</td>\n",
       "      <td>0.9247</td>\n",
       "      <td>0.9201</td>\n",
       "      <td>67.6382</td>\n",
       "      <td>1.1799</td>\n",
       "      <td>4.4381</td>\n",
       "      <td>56.9942</td>\n",
       "      <td>1.1499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.688600</td>\n",
       "      <td>0.691067</td>\n",
       "      <td>0.0379</td>\n",
       "      <td>0.411</td>\n",
       "      <td>6.7892</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>70.7386</td>\n",
       "      <td>0.8908</td>\n",
       "      <td>1.4939</td>\n",
       "      <td>63.9797</td>\n",
       "      <td>1.2449</td>\n",
       "      <td>5.4845</td>\n",
       "      <td>54.3867</td>\n",
       "      <td>0.973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.688600</td>\n",
       "      <td>0.691404</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.2340</td>\n",
       "      <td>6.5497</td>\n",
       "      <td>0.0479</td>\n",
       "      <td>73.6148</td>\n",
       "      <td>0.9304</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>67.3356</td>\n",
       "      <td>1.1099</td>\n",
       "      <td>4.6406</td>\n",
       "      <td>56.7722</td>\n",
       "      <td>1.0592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.689200</td>\n",
       "      <td>0.689549</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.4547</td>\n",
       "      <td>5.6772</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>74.6875</td>\n",
       "      <td>1.0275</td>\n",
       "      <td>0.7802</td>\n",
       "      <td>65.8722</td>\n",
       "      <td>1.1138</td>\n",
       "      <td>4.0832</td>\n",
       "      <td>57.8253</td>\n",
       "      <td>1.0945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.688600</td>\n",
       "      <td>0.690947</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.3719</td>\n",
       "      <td>6.4558</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>71.0145</td>\n",
       "      <td>0.8362</td>\n",
       "      <td>1.1202</td>\n",
       "      <td>64.9616</td>\n",
       "      <td>1.1086</td>\n",
       "      <td>5.2680</td>\n",
       "      <td>55.6102</td>\n",
       "      <td>1.0853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.689100</td>\n",
       "      <td>0.690253</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.4238</td>\n",
       "      <td>5.7277</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>62.5698</td>\n",
       "      <td>0.8926</td>\n",
       "      <td>0.7794</td>\n",
       "      <td>62.8692</td>\n",
       "      <td>1.1341</td>\n",
       "      <td>4.3955</td>\n",
       "      <td>56.9283</td>\n",
       "      <td>1.0797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.690442</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.2949</td>\n",
       "      <td>5.5925</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>64.9007</td>\n",
       "      <td>0.9665</td>\n",
       "      <td>0.6182</td>\n",
       "      <td>63.761</td>\n",
       "      <td>1.1094</td>\n",
       "      <td>3.9535</td>\n",
       "      <td>60.1792</td>\n",
       "      <td>1.1404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.688700</td>\n",
       "      <td>0.690958</td>\n",
       "      <td>0.0247</td>\n",
       "      <td>0.2634</td>\n",
       "      <td>6.0983</td>\n",
       "      <td>0.0368</td>\n",
       "      <td>65.6357</td>\n",
       "      <td>0.7334</td>\n",
       "      <td>0.9075</td>\n",
       "      <td>64.2459</td>\n",
       "      <td>1.2404</td>\n",
       "      <td>4.7403</td>\n",
       "      <td>57.2568</td>\n",
       "      <td>1.0291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.690043</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.4198</td>\n",
       "      <td>5.9427</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>67.8431</td>\n",
       "      <td>0.8742</td>\n",
       "      <td>0.7495</td>\n",
       "      <td>64.692</td>\n",
       "      <td>1.1586</td>\n",
       "      <td>4.4689</td>\n",
       "      <td>57.2334</td>\n",
       "      <td>1.0465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>0.690419</td>\n",
       "      <td>0.0296</td>\n",
       "      <td>0.4132</td>\n",
       "      <td>5.4036</td>\n",
       "      <td>0.0311</td>\n",
       "      <td>66.2602</td>\n",
       "      <td>0.8618</td>\n",
       "      <td>0.7028</td>\n",
       "      <td>63.8409</td>\n",
       "      <td>1.1686</td>\n",
       "      <td>3.7786</td>\n",
       "      <td>59.9223</td>\n",
       "      <td>1.1082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.690422</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.4262</td>\n",
       "      <td>5.3072</td>\n",
       "      <td>0.0377</td>\n",
       "      <td>66.1074</td>\n",
       "      <td>0.7644</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>63.6885</td>\n",
       "      <td>1.1274</td>\n",
       "      <td>3.9912</td>\n",
       "      <td>57.7917</td>\n",
       "      <td>1.1127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.688300</td>\n",
       "      <td>0.690452</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.3981</td>\n",
       "      <td>5.616</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>65.9236</td>\n",
       "      <td>0.7653</td>\n",
       "      <td>0.865</td>\n",
       "      <td>62.8693</td>\n",
       "      <td>1.1359</td>\n",
       "      <td>3.9553</td>\n",
       "      <td>58.2782</td>\n",
       "      <td>1.0867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>0.690262</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.3986</td>\n",
       "      <td>5.3862</td>\n",
       "      <td>0.0334</td>\n",
       "      <td>64.0152</td>\n",
       "      <td>0.7822</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>64.2936</td>\n",
       "      <td>1.1249</td>\n",
       "      <td>4.0256</td>\n",
       "      <td>57.3134</td>\n",
       "      <td>1.1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.690253</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.4534</td>\n",
       "      <td>5.3884</td>\n",
       "      <td>0.0419</td>\n",
       "      <td>68.2779</td>\n",
       "      <td>0.8651</td>\n",
       "      <td>1.1053</td>\n",
       "      <td>63.4356</td>\n",
       "      <td>1.2131</td>\n",
       "      <td>4.2132</td>\n",
       "      <td>57.5147</td>\n",
       "      <td>1.0525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35538</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.689078</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.4395</td>\n",
       "      <td>5.1573</td>\n",
       "      <td>0.0437</td>\n",
       "      <td>79.7386</td>\n",
       "      <td>4.7623</td>\n",
       "      <td>1.0528</td>\n",
       "      <td>70.9283</td>\n",
       "      <td>1.5994</td>\n",
       "      <td>3.8495</td>\n",
       "      <td>56.0134</td>\n",
       "      <td>1.0686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='31' max='31' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [31/31 00:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-7085042cc8e7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# weight decay, head size of 64, NO diagonal attention allowed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_inner_training_loop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_train_batch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_find_batch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1497\u001b[0m         )\n\u001b[1;32m-> 1498\u001b[1;33m         return inner_training_loop(\n\u001b[0m\u001b[0;32m   1499\u001b[0m             \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1500\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   1738\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1739\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1740\u001b[1;33m                     \u001b[0mtr_loss_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1742\u001b[0m                 if (\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   2468\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2469\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss_context_manager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2470\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2471\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2472\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[1;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[0;32m   2500\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2501\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2502\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2503\u001b[0m         \u001b[1;31m# Save past state if it exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2504\u001b[0m         \u001b[1;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Trader\\trader_models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, ohlcv, future)\u001b[0m\n\u001b[0;32m     99\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mohlcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 101\u001b[1;33m         \u001b[0membed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membed_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv_embed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mohlcv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    102\u001b[0m         \u001b[0membed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# sequence first for SRU\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\Trader\\trader_models.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, hidden_states)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 44\u001b[1;33m         \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrotary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrotate_queries_or_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[0mmod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout_proj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\rotary_embedding_torch\\rotary_embedding_torch.py\u001b[0m in \u001b[0;36mrotate_queries_or_keys\u001b[1;34m(self, t, seq_dim)\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mseq_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mseq_dim\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m         \u001b[0mfreqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseq_len\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 95\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mapply_rotary_emb\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreqs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     96\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcache_key\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\rotary_embedding_torch\\rotary_embedding_torch.py\u001b[0m in \u001b[0;36mapply_rotary_emb\u001b[1;34m(freqs, t, start_index)\u001b[0m\n\u001b[0;32m     44\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0mrot_dim\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mf'feature dimension {t.shape[-1]} is not of sufficient size to rotate in all the positions {rot_dim}'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m     \u001b[0mt_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_right\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mstart_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mend_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_index\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 46\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrotate_half\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mfreqs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     47\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_left\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt_right\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\rotary_embedding_torch\\rotary_embedding_torch.py\u001b[0m in \u001b[0;36mrotate_half\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrotate_half\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrearrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'... (d r) -> ... d r'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mx1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mx2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\einops\\einops.py\u001b[0m in \u001b[0;36mrearrange\u001b[1;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[0;32m    450\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Rearrange can't be applied to an empty list\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack_on_zeroth_dimension\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rearrange'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\einops\\einops.py\u001b[0m in \u001b[0;36mreduce\u001b[1;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[0;32m    380\u001b[0m         \u001b[0mhashable_axes_lengths\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxes_lengths\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    381\u001b[0m         \u001b[0mrecipe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_prepare_transformation_recipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes_lengths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mhashable_axes_lengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 382\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mrecipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    383\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mEinopsError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    384\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' Error while processing {}-reduction pattern \"{}\".'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\einops\\einops.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    204\u001b[0m         init_shapes, reduced_axes, axes_reordering, added_axes, final_shapes = self.reconstruct_from_shape(\n\u001b[0;32m    205\u001b[0m             backend.shape(tensor))\n\u001b[1;32m--> 206\u001b[1;33m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_shapes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    207\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_reduce_axes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduced_axes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduced_axes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes_reordering\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\einops\\_backends.py\u001b[0m in \u001b[0;36mreshape\u001b[1;34m(self, x, shape)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 84\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# OANDA finnhub (no volume), still doesn't trade throughout day\n",
    "\n",
    "# sru lr of 1e-4, batch size 1 hidden size 448, 60 min, \n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43898' max='43898' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43898/43898 2:54:51, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.714100</td>\n",
       "      <td>0.702749</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>12.8162</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0906</td>\n",
       "      <td>46.8837</td>\n",
       "      <td>0.8986</td>\n",
       "      <td>20.9581</td>\n",
       "      <td>50.3539</td>\n",
       "      <td>0.9168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.701400</td>\n",
       "      <td>0.694041</td>\n",
       "      <td>0.034</td>\n",
       "      <td>0.2181</td>\n",
       "      <td>8.2214</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>59.8571</td>\n",
       "      <td>0.4046</td>\n",
       "      <td>5.5157</td>\n",
       "      <td>54.4805</td>\n",
       "      <td>0.9636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.697900</td>\n",
       "      <td>0.693440</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.2518</td>\n",
       "      <td>6.5004</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>94.1176</td>\n",
       "      <td>72.2788</td>\n",
       "      <td>1.5021</td>\n",
       "      <td>55.2683</td>\n",
       "      <td>1.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.696300</td>\n",
       "      <td>0.695563</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>6.8643</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>93.5484</td>\n",
       "      <td>27.5334</td>\n",
       "      <td>2.8389</td>\n",
       "      <td>50.4585</td>\n",
       "      <td>1.0021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.694800</td>\n",
       "      <td>0.695171</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>8.0565</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0071</td>\n",
       "      <td>94.6903</td>\n",
       "      <td>1.0648</td>\n",
       "      <td>6.5174</td>\n",
       "      <td>52.0872</td>\n",
       "      <td>0.811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.693900</td>\n",
       "      <td>0.693521</td>\n",
       "      <td>0.0017</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>6.5760</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>92.1053</td>\n",
       "      <td>0.3644</td>\n",
       "      <td>1.7569</td>\n",
       "      <td>62.3045</td>\n",
       "      <td>0.8116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.693200</td>\n",
       "      <td>0.691826</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.3032</td>\n",
       "      <td>6.1701</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0198</td>\n",
       "      <td>93.038</td>\n",
       "      <td>0.489</td>\n",
       "      <td>2.2128</td>\n",
       "      <td>61.0081</td>\n",
       "      <td>0.9354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.693100</td>\n",
       "      <td>0.696090</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>7.9513</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>93.3333</td>\n",
       "      <td>1.0624</td>\n",
       "      <td>4.0942</td>\n",
       "      <td>55.7312</td>\n",
       "      <td>0.9366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.692700</td>\n",
       "      <td>0.690591</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.377</td>\n",
       "      <td>6.2824</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>92.6829</td>\n",
       "      <td>1.2121</td>\n",
       "      <td>2.222</td>\n",
       "      <td>61.5330</td>\n",
       "      <td>1.0547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.692500</td>\n",
       "      <td>0.692242</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>5.3958</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.039</td>\n",
       "      <td>94.2029</td>\n",
       "      <td>1.8579</td>\n",
       "      <td>0.8069</td>\n",
       "      <td>72.9358</td>\n",
       "      <td>1.0889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.692404</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.1437</td>\n",
       "      <td>7.8774</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1903</td>\n",
       "      <td>79.2944</td>\n",
       "      <td>1.0814</td>\n",
       "      <td>4.5574</td>\n",
       "      <td>59.63</td>\n",
       "      <td>0.9404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.691800</td>\n",
       "      <td>0.691304</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.2199</td>\n",
       "      <td>5.8155</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1817</td>\n",
       "      <td>85.3987</td>\n",
       "      <td>1.1696</td>\n",
       "      <td>2.509</td>\n",
       "      <td>64.9806</td>\n",
       "      <td>0.9699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.691800</td>\n",
       "      <td>0.693050</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.1244</td>\n",
       "      <td>6.4998</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.7396</td>\n",
       "      <td>69.771</td>\n",
       "      <td>0.9188</td>\n",
       "      <td>4.7662</td>\n",
       "      <td>56.7369</td>\n",
       "      <td>0.9195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.693098</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>7.5495</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>87.9702</td>\n",
       "      <td>1.6664</td>\n",
       "      <td>3.2259</td>\n",
       "      <td>62.1862</td>\n",
       "      <td>1.0324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.692096</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.1789</td>\n",
       "      <td>6.8040</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1001</td>\n",
       "      <td>91.3534</td>\n",
       "      <td>1.4621</td>\n",
       "      <td>2.1665</td>\n",
       "      <td>65.7246</td>\n",
       "      <td>1.1087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.690445</td>\n",
       "      <td>0.0474</td>\n",
       "      <td>0.3994</td>\n",
       "      <td>6.2998</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1323</td>\n",
       "      <td>84.3054</td>\n",
       "      <td>1.0266</td>\n",
       "      <td>2.6374</td>\n",
       "      <td>60.7259</td>\n",
       "      <td>1.0840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.691100</td>\n",
       "      <td>0.693064</td>\n",
       "      <td>0.0181</td>\n",
       "      <td>0.1035</td>\n",
       "      <td>7.468</td>\n",
       "      <td>0.0006</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2</td>\n",
       "      <td>80.1757</td>\n",
       "      <td>1.1794</td>\n",
       "      <td>2.5501</td>\n",
       "      <td>62.5741</td>\n",
       "      <td>0.9729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.690188</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.3219</td>\n",
       "      <td>5.0773</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>88.9081</td>\n",
       "      <td>0.6233</td>\n",
       "      <td>1.2192</td>\n",
       "      <td>70.2701</td>\n",
       "      <td>0.9914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.689549</td>\n",
       "      <td>0.0416</td>\n",
       "      <td>0.4095</td>\n",
       "      <td>5.9104</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>97.3684</td>\n",
       "      <td>19.2207</td>\n",
       "      <td>0.1856</td>\n",
       "      <td>86.4097</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>2.0194</td>\n",
       "      <td>65.1952</td>\n",
       "      <td>1.032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.690620</td>\n",
       "      <td>0.0323</td>\n",
       "      <td>0.2919</td>\n",
       "      <td>6.0064</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1453</td>\n",
       "      <td>87.3057</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2.6612</td>\n",
       "      <td>63.7703</td>\n",
       "      <td>1.1334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.691100</td>\n",
       "      <td>0.689356</td>\n",
       "      <td>0.0478</td>\n",
       "      <td>0.3958</td>\n",
       "      <td>5.4281</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1592</td>\n",
       "      <td>86.1702</td>\n",
       "      <td>1.0233</td>\n",
       "      <td>1.6817</td>\n",
       "      <td>67.6913</td>\n",
       "      <td>1.2627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.690700</td>\n",
       "      <td>0.690559</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>0.4047</td>\n",
       "      <td>6.4093</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1626</td>\n",
       "      <td>85.7639</td>\n",
       "      <td>0.8665</td>\n",
       "      <td>2.381</td>\n",
       "      <td>62.0788</td>\n",
       "      <td>1.1261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.689251</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.4555</td>\n",
       "      <td>5.3798</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>86.0647</td>\n",
       "      <td>0.7883</td>\n",
       "      <td>1.6736</td>\n",
       "      <td>67.9474</td>\n",
       "      <td>0.9761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.690237</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.3396</td>\n",
       "      <td>6.1802</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>94.6565</td>\n",
       "      <td>6.7338</td>\n",
       "      <td>0.332</td>\n",
       "      <td>83.8435</td>\n",
       "      <td>1.2783</td>\n",
       "      <td>3.2032</td>\n",
       "      <td>64.6638</td>\n",
       "      <td>1.0761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.690400</td>\n",
       "      <td>0.694755</td>\n",
       "      <td>0.0253</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>9.0175</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>96.7949</td>\n",
       "      <td>1.1099</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>74.6637</td>\n",
       "      <td>0.9649</td>\n",
       "      <td>7.3563</td>\n",
       "      <td>54.5623</td>\n",
       "      <td>0.9266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.690400</td>\n",
       "      <td>0.689233</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.3473</td>\n",
       "      <td>6.4193</td>\n",
       "      <td>0.004</td>\n",
       "      <td>98.4127</td>\n",
       "      <td>33.0513</td>\n",
       "      <td>0.2668</td>\n",
       "      <td>84.2699</td>\n",
       "      <td>1.1777</td>\n",
       "      <td>2.9635</td>\n",
       "      <td>63.9373</td>\n",
       "      <td>1.1955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.690069</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.2961</td>\n",
       "      <td>6.1988</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2544</td>\n",
       "      <td>85.8235</td>\n",
       "      <td>1.1611</td>\n",
       "      <td>3.7652</td>\n",
       "      <td>62.4631</td>\n",
       "      <td>1.1627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.692652</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.1219</td>\n",
       "      <td>7.8129</td>\n",
       "      <td>0.0015</td>\n",
       "      <td>91.6667</td>\n",
       "      <td>5.9911</td>\n",
       "      <td>0.3963</td>\n",
       "      <td>76.4603</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>5.0436</td>\n",
       "      <td>58.8801</td>\n",
       "      <td>0.9564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.689315</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.3675</td>\n",
       "      <td>7.1974</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>98.5075</td>\n",
       "      <td>26.2443</td>\n",
       "      <td>0.386</td>\n",
       "      <td>77.7019</td>\n",
       "      <td>1.0080</td>\n",
       "      <td>4.431</td>\n",
       "      <td>61.14</td>\n",
       "      <td>1.2926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.690804</td>\n",
       "      <td>0.0318</td>\n",
       "      <td>0.1946</td>\n",
       "      <td>5.4772</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1121</td>\n",
       "      <td>89.0319</td>\n",
       "      <td>0.9789</td>\n",
       "      <td>1.55</td>\n",
       "      <td>66.5372</td>\n",
       "      <td>1.3771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.689588</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.3549</td>\n",
       "      <td>6.0315</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>92.6829</td>\n",
       "      <td>9.3664</td>\n",
       "      <td>0.2139</td>\n",
       "      <td>86.3596</td>\n",
       "      <td>0.8557</td>\n",
       "      <td>2.4550</td>\n",
       "      <td>65.8899</td>\n",
       "      <td>1.0037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.692917</td>\n",
       "      <td>0.0201</td>\n",
       "      <td>0.1015</td>\n",
       "      <td>7.7683</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>93.75</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>0.2999</td>\n",
       "      <td>81.0291</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>2.6602</td>\n",
       "      <td>64.4193</td>\n",
       "      <td>1.1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.689304</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.3260</td>\n",
       "      <td>5.4808</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>97.8261</td>\n",
       "      <td>82.0102</td>\n",
       "      <td>0.1815</td>\n",
       "      <td>86.6621</td>\n",
       "      <td>1.2506</td>\n",
       "      <td>2.2345</td>\n",
       "      <td>65.8956</td>\n",
       "      <td>1.3253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.688300</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.4535</td>\n",
       "      <td>5.8767</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>98.3871</td>\n",
       "      <td>29.1961</td>\n",
       "      <td>0.2429</td>\n",
       "      <td>85.8729</td>\n",
       "      <td>2.0483</td>\n",
       "      <td>3.4236</td>\n",
       "      <td>63.0838</td>\n",
       "      <td>1.2091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.689445</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.3832</td>\n",
       "      <td>5.6013</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>98.3957</td>\n",
       "      <td>4.7186</td>\n",
       "      <td>0.4270</td>\n",
       "      <td>79.0363</td>\n",
       "      <td>1.6058</td>\n",
       "      <td>3.4195</td>\n",
       "      <td>62.1347</td>\n",
       "      <td>1.1257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>0.688538</td>\n",
       "      <td>0.0530</td>\n",
       "      <td>0.5262</td>\n",
       "      <td>5.5587</td>\n",
       "      <td>0.0152</td>\n",
       "      <td>97.5309</td>\n",
       "      <td>16.6627</td>\n",
       "      <td>0.3947</td>\n",
       "      <td>82.9466</td>\n",
       "      <td>1.39</td>\n",
       "      <td>2.6745</td>\n",
       "      <td>65.0412</td>\n",
       "      <td>1.1757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>0.690556</td>\n",
       "      <td>0.0405</td>\n",
       "      <td>0.2723</td>\n",
       "      <td>5.9379</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>96.6887</td>\n",
       "      <td>5.2554</td>\n",
       "      <td>0.5192</td>\n",
       "      <td>73.7707</td>\n",
       "      <td>1.6799</td>\n",
       "      <td>3.6201</td>\n",
       "      <td>60.3279</td>\n",
       "      <td>0.9676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.690919</td>\n",
       "      <td>0.0499</td>\n",
       "      <td>0.3298</td>\n",
       "      <td>6.8663</td>\n",
       "      <td>0.0372</td>\n",
       "      <td>92.5801</td>\n",
       "      <td>3.1893</td>\n",
       "      <td>0.8969</td>\n",
       "      <td>72.8144</td>\n",
       "      <td>1.3829</td>\n",
       "      <td>3.8964</td>\n",
       "      <td>58.6891</td>\n",
       "      <td>0.9467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.688958</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.395</td>\n",
       "      <td>5.7462</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>94.0559</td>\n",
       "      <td>3.379</td>\n",
       "      <td>0.6526</td>\n",
       "      <td>73.4788</td>\n",
       "      <td>1.4560</td>\n",
       "      <td>3.554</td>\n",
       "      <td>60.9623</td>\n",
       "      <td>1.2159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.690075</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.4186</td>\n",
       "      <td>6.6393</td>\n",
       "      <td>0.0536</td>\n",
       "      <td>88.7719</td>\n",
       "      <td>2.8011</td>\n",
       "      <td>1.1389</td>\n",
       "      <td>71.1925</td>\n",
       "      <td>1.2764</td>\n",
       "      <td>4.1049</td>\n",
       "      <td>59.5629</td>\n",
       "      <td>0.9802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.688714</td>\n",
       "      <td>0.0566</td>\n",
       "      <td>0.4008</td>\n",
       "      <td>6.0744</td>\n",
       "      <td>0.0409</td>\n",
       "      <td>93.7117</td>\n",
       "      <td>0.8544</td>\n",
       "      <td>0.806</td>\n",
       "      <td>74.2372</td>\n",
       "      <td>0.9617</td>\n",
       "      <td>3.3952</td>\n",
       "      <td>62.4300</td>\n",
       "      <td>1.1591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>0.687758</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.4899</td>\n",
       "      <td>5.5152</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>93.6709</td>\n",
       "      <td>4.1572</td>\n",
       "      <td>0.5213</td>\n",
       "      <td>77.6775</td>\n",
       "      <td>1.7339</td>\n",
       "      <td>3.6033</td>\n",
       "      <td>61.7577</td>\n",
       "      <td>1.0979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.689163</td>\n",
       "      <td>0.0535</td>\n",
       "      <td>0.3201</td>\n",
       "      <td>6.3565</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>97.5831</td>\n",
       "      <td>10.5246</td>\n",
       "      <td>0.7802</td>\n",
       "      <td>74.6804</td>\n",
       "      <td>1.6957</td>\n",
       "      <td>4.0749</td>\n",
       "      <td>61.9964</td>\n",
       "      <td>1.0356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.690563</td>\n",
       "      <td>0.0484</td>\n",
       "      <td>0.2335</td>\n",
       "      <td>6.9505</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>98.1081</td>\n",
       "      <td>8.5675</td>\n",
       "      <td>0.6706</td>\n",
       "      <td>71.8335</td>\n",
       "      <td>1.7711</td>\n",
       "      <td>3.9483</td>\n",
       "      <td>61.4198</td>\n",
       "      <td>1.1621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.687581</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.4806</td>\n",
       "      <td>5.2466</td>\n",
       "      <td>0.0321</td>\n",
       "      <td>96.2891</td>\n",
       "      <td>3.5997</td>\n",
       "      <td>0.6685</td>\n",
       "      <td>75.4621</td>\n",
       "      <td>1.6479</td>\n",
       "      <td>3.5696</td>\n",
       "      <td>62.8537</td>\n",
       "      <td>1.1975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.689745</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.336</td>\n",
       "      <td>7.1810</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>97.0696</td>\n",
       "      <td>8.4411</td>\n",
       "      <td>0.7822</td>\n",
       "      <td>75.1704</td>\n",
       "      <td>1.6627</td>\n",
       "      <td>4.805</td>\n",
       "      <td>60.7846</td>\n",
       "      <td>1.0997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.688957</td>\n",
       "      <td>0.0625</td>\n",
       "      <td>0.3817</td>\n",
       "      <td>6.4019</td>\n",
       "      <td>0.0230</td>\n",
       "      <td>96.7302</td>\n",
       "      <td>5.061</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>70.4216</td>\n",
       "      <td>1.3953</td>\n",
       "      <td>3.8785</td>\n",
       "      <td>60.5124</td>\n",
       "      <td>1.1793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.689100</td>\n",
       "      <td>0.689447</td>\n",
       "      <td>0.0515</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>7.2171</td>\n",
       "      <td>0.0239</td>\n",
       "      <td>94.2257</td>\n",
       "      <td>3.7884</td>\n",
       "      <td>0.598</td>\n",
       "      <td>75.7344</td>\n",
       "      <td>1.5538</td>\n",
       "      <td>3.9354</td>\n",
       "      <td>61.3441</td>\n",
       "      <td>1.1062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.688379</td>\n",
       "      <td>0.0633</td>\n",
       "      <td>0.4678</td>\n",
       "      <td>5.7276</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>95.7447</td>\n",
       "      <td>1.7332</td>\n",
       "      <td>0.6209</td>\n",
       "      <td>74.1538</td>\n",
       "      <td>1.3408</td>\n",
       "      <td>3.6001</td>\n",
       "      <td>62.106</td>\n",
       "      <td>1.1333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.689300</td>\n",
       "      <td>0.688635</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>0.4445</td>\n",
       "      <td>5.6272</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>94.4954</td>\n",
       "      <td>1.7980</td>\n",
       "      <td>0.5588</td>\n",
       "      <td>73.608</td>\n",
       "      <td>1.5586</td>\n",
       "      <td>3.3057</td>\n",
       "      <td>61.8092</td>\n",
       "      <td>1.3150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.688073</td>\n",
       "      <td>0.0651</td>\n",
       "      <td>0.525</td>\n",
       "      <td>5.78</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>97.0696</td>\n",
       "      <td>3.5561</td>\n",
       "      <td>0.7730</td>\n",
       "      <td>73.3182</td>\n",
       "      <td>1.5442</td>\n",
       "      <td>3.8869</td>\n",
       "      <td>61.1168</td>\n",
       "      <td>1.0832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.689100</td>\n",
       "      <td>0.687530</td>\n",
       "      <td>0.0695</td>\n",
       "      <td>0.5531</td>\n",
       "      <td>5.6233</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>97.0845</td>\n",
       "      <td>4.868</td>\n",
       "      <td>0.7889</td>\n",
       "      <td>71.9364</td>\n",
       "      <td>1.5139</td>\n",
       "      <td>3.8427</td>\n",
       "      <td>61.465</td>\n",
       "      <td>1.1656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.689100</td>\n",
       "      <td>0.687559</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.5833</td>\n",
       "      <td>5.9497</td>\n",
       "      <td>0.0338</td>\n",
       "      <td>94.8052</td>\n",
       "      <td>4.5582</td>\n",
       "      <td>0.8407</td>\n",
       "      <td>72.2558</td>\n",
       "      <td>1.6468</td>\n",
       "      <td>3.7674</td>\n",
       "      <td>60.7749</td>\n",
       "      <td>1.1614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.688600</td>\n",
       "      <td>0.688438</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.541</td>\n",
       "      <td>7.0283</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>93.6170</td>\n",
       "      <td>4.8060</td>\n",
       "      <td>1.4299</td>\n",
       "      <td>67.6216</td>\n",
       "      <td>1.6297</td>\n",
       "      <td>4.4093</td>\n",
       "      <td>58.8351</td>\n",
       "      <td>1.0784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.689100</td>\n",
       "      <td>0.688718</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>0.4824</td>\n",
       "      <td>5.7709</td>\n",
       "      <td>0.0587</td>\n",
       "      <td>91.2299</td>\n",
       "      <td>3.8581</td>\n",
       "      <td>1.4015</td>\n",
       "      <td>67.1411</td>\n",
       "      <td>1.5882</td>\n",
       "      <td>3.5023</td>\n",
       "      <td>59.4763</td>\n",
       "      <td>1.0931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>0.688005</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.4665</td>\n",
       "      <td>5.5413</td>\n",
       "      <td>0.0658</td>\n",
       "      <td>91.8017</td>\n",
       "      <td>3.6992</td>\n",
       "      <td>1.2580</td>\n",
       "      <td>69.3976</td>\n",
       "      <td>1.4328</td>\n",
       "      <td>3.9172</td>\n",
       "      <td>59.7111</td>\n",
       "      <td>1.2219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.688292</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.4619</td>\n",
       "      <td>5.5951</td>\n",
       "      <td>0.0482</td>\n",
       "      <td>93.238</td>\n",
       "      <td>3.9336</td>\n",
       "      <td>1.0201</td>\n",
       "      <td>70.4587</td>\n",
       "      <td>1.5835</td>\n",
       "      <td>3.3644</td>\n",
       "      <td>62.27</td>\n",
       "      <td>1.1581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.688700</td>\n",
       "      <td>0.687797</td>\n",
       "      <td>0.0742</td>\n",
       "      <td>0.5288</td>\n",
       "      <td>5.8856</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>93.1767</td>\n",
       "      <td>2.7168</td>\n",
       "      <td>1.2459</td>\n",
       "      <td>68.5313</td>\n",
       "      <td>1.4528</td>\n",
       "      <td>3.731</td>\n",
       "      <td>60.6675</td>\n",
       "      <td>1.1136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>0.688312</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.4752</td>\n",
       "      <td>6.3216</td>\n",
       "      <td>0.0507</td>\n",
       "      <td>93.4406</td>\n",
       "      <td>2.625</td>\n",
       "      <td>1.1293</td>\n",
       "      <td>67.8091</td>\n",
       "      <td>1.4582</td>\n",
       "      <td>3.7124</td>\n",
       "      <td>61.3528</td>\n",
       "      <td>1.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.688075</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.4792</td>\n",
       "      <td>6.3524</td>\n",
       "      <td>0.0563</td>\n",
       "      <td>92.9844</td>\n",
       "      <td>3.1038</td>\n",
       "      <td>1.1614</td>\n",
       "      <td>67.8189</td>\n",
       "      <td>1.3788</td>\n",
       "      <td>3.7637</td>\n",
       "      <td>60.7457</td>\n",
       "      <td>1.1289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.689000</td>\n",
       "      <td>0.688095</td>\n",
       "      <td>0.0614</td>\n",
       "      <td>0.4804</td>\n",
       "      <td>5.8676</td>\n",
       "      <td>0.0333</td>\n",
       "      <td>94.9153</td>\n",
       "      <td>4.8932</td>\n",
       "      <td>0.8949</td>\n",
       "      <td>71.5037</td>\n",
       "      <td>1.5574</td>\n",
       "      <td>3.9465</td>\n",
       "      <td>62.2530</td>\n",
       "      <td>1.0799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.688800</td>\n",
       "      <td>0.687717</td>\n",
       "      <td>0.0719</td>\n",
       "      <td>0.4871</td>\n",
       "      <td>5.7794</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>95.0402</td>\n",
       "      <td>5.4808</td>\n",
       "      <td>1.0747</td>\n",
       "      <td>68.9218</td>\n",
       "      <td>1.5034</td>\n",
       "      <td>3.8113</td>\n",
       "      <td>60.6024</td>\n",
       "      <td>1.1015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.688700</td>\n",
       "      <td>0.687917</td>\n",
       "      <td>0.0662</td>\n",
       "      <td>0.4853</td>\n",
       "      <td>5.7083</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>95.5316</td>\n",
       "      <td>4.0651</td>\n",
       "      <td>1.0818</td>\n",
       "      <td>68.4720</td>\n",
       "      <td>1.7414</td>\n",
       "      <td>3.4528</td>\n",
       "      <td>61.0963</td>\n",
       "      <td>1.2297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.688400</td>\n",
       "      <td>0.688622</td>\n",
       "      <td>0.0619</td>\n",
       "      <td>0.4236</td>\n",
       "      <td>6.2549</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>94.9171</td>\n",
       "      <td>3.9435</td>\n",
       "      <td>1.2088</td>\n",
       "      <td>70.0623</td>\n",
       "      <td>1.4222</td>\n",
       "      <td>3.7882</td>\n",
       "      <td>60.5793</td>\n",
       "      <td>1.0429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.688600</td>\n",
       "      <td>0.688093</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.4462</td>\n",
       "      <td>5.6747</td>\n",
       "      <td>0.0510</td>\n",
       "      <td>94.9569</td>\n",
       "      <td>3.6988</td>\n",
       "      <td>1.0722</td>\n",
       "      <td>70.0369</td>\n",
       "      <td>1.588</td>\n",
       "      <td>3.5808</td>\n",
       "      <td>61.2726</td>\n",
       "      <td>1.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.688600</td>\n",
       "      <td>0.688243</td>\n",
       "      <td>0.0617</td>\n",
       "      <td>0.3973</td>\n",
       "      <td>5.5934</td>\n",
       "      <td>0.0456</td>\n",
       "      <td>94.7730</td>\n",
       "      <td>4.0119</td>\n",
       "      <td>1.0257</td>\n",
       "      <td>68.4465</td>\n",
       "      <td>1.4789</td>\n",
       "      <td>3.6415</td>\n",
       "      <td>61.0209</td>\n",
       "      <td>1.1074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.688700</td>\n",
       "      <td>0.688043</td>\n",
       "      <td>0.068</td>\n",
       "      <td>0.4276</td>\n",
       "      <td>5.9061</td>\n",
       "      <td>0.0709</td>\n",
       "      <td>91.6814</td>\n",
       "      <td>3.4483</td>\n",
       "      <td>1.4425</td>\n",
       "      <td>69.0541</td>\n",
       "      <td>1.3195</td>\n",
       "      <td>3.9140</td>\n",
       "      <td>59.5884</td>\n",
       "      <td>1.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.688700</td>\n",
       "      <td>0.688340</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.4195</td>\n",
       "      <td>5.5415</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>93.5025</td>\n",
       "      <td>3.6886</td>\n",
       "      <td>0.9799</td>\n",
       "      <td>70.6338</td>\n",
       "      <td>1.2457</td>\n",
       "      <td>3.3343</td>\n",
       "      <td>62.3721</td>\n",
       "      <td>1.1308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.689250</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>0.3642</td>\n",
       "      <td>6.6297</td>\n",
       "      <td>0.0977</td>\n",
       "      <td>89.2742</td>\n",
       "      <td>3.2882</td>\n",
       "      <td>1.4950</td>\n",
       "      <td>68.4080</td>\n",
       "      <td>1.1250</td>\n",
       "      <td>3.6573</td>\n",
       "      <td>59.8120</td>\n",
       "      <td>1.2133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.687800</td>\n",
       "      <td>0.688336</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.4318</td>\n",
       "      <td>6.2395</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>88.5358</td>\n",
       "      <td>3.2831</td>\n",
       "      <td>1.5289</td>\n",
       "      <td>67.3314</td>\n",
       "      <td>1.1457</td>\n",
       "      <td>3.5844</td>\n",
       "      <td>59.7098</td>\n",
       "      <td>1.1817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.687800</td>\n",
       "      <td>0.687940</td>\n",
       "      <td>0.0724</td>\n",
       "      <td>0.4679</td>\n",
       "      <td>6.1114</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>91.3580</td>\n",
       "      <td>3.7082</td>\n",
       "      <td>1.3928</td>\n",
       "      <td>67.8813</td>\n",
       "      <td>1.2521</td>\n",
       "      <td>3.6608</td>\n",
       "      <td>60.1361</td>\n",
       "      <td>1.1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.688900</td>\n",
       "      <td>0.687968</td>\n",
       "      <td>0.0656</td>\n",
       "      <td>0.4852</td>\n",
       "      <td>5.7825</td>\n",
       "      <td>0.0499</td>\n",
       "      <td>93.9698</td>\n",
       "      <td>3.5754</td>\n",
       "      <td>1.2418</td>\n",
       "      <td>67.9717</td>\n",
       "      <td>1.5975</td>\n",
       "      <td>3.486</td>\n",
       "      <td>61.1132</td>\n",
       "      <td>1.0502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>0.688600</td>\n",
       "      <td>0.687682</td>\n",
       "      <td>0.0705</td>\n",
       "      <td>0.4965</td>\n",
       "      <td>5.7483</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>92.4362</td>\n",
       "      <td>3.3605</td>\n",
       "      <td>1.4196</td>\n",
       "      <td>68.2192</td>\n",
       "      <td>1.5265</td>\n",
       "      <td>3.7079</td>\n",
       "      <td>60.4751</td>\n",
       "      <td>1.0366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.687992</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.4675</td>\n",
       "      <td>6.0513</td>\n",
       "      <td>0.0912</td>\n",
       "      <td>89.6836</td>\n",
       "      <td>3.6091</td>\n",
       "      <td>1.4829</td>\n",
       "      <td>69.3007</td>\n",
       "      <td>1.4290</td>\n",
       "      <td>3.8452</td>\n",
       "      <td>60.0708</td>\n",
       "      <td>1.013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.688200</td>\n",
       "      <td>0.687790</td>\n",
       "      <td>0.0715</td>\n",
       "      <td>0.5049</td>\n",
       "      <td>5.9231</td>\n",
       "      <td>0.0822</td>\n",
       "      <td>92.0611</td>\n",
       "      <td>3.6866</td>\n",
       "      <td>1.532</td>\n",
       "      <td>68.1094</td>\n",
       "      <td>1.5451</td>\n",
       "      <td>3.7553</td>\n",
       "      <td>59.7681</td>\n",
       "      <td>1.0138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.687900</td>\n",
       "      <td>0.687878</td>\n",
       "      <td>0.0747</td>\n",
       "      <td>0.5173</td>\n",
       "      <td>6.1127</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>88.8671</td>\n",
       "      <td>3.6118</td>\n",
       "      <td>1.7146</td>\n",
       "      <td>67.7594</td>\n",
       "      <td>1.4867</td>\n",
       "      <td>3.9268</td>\n",
       "      <td>58.7466</td>\n",
       "      <td>1.0028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>0.687800</td>\n",
       "      <td>0.687912</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>0.4933</td>\n",
       "      <td>6.104</td>\n",
       "      <td>0.0909</td>\n",
       "      <td>89.441</td>\n",
       "      <td>3.6313</td>\n",
       "      <td>1.6618</td>\n",
       "      <td>67.3688</td>\n",
       "      <td>1.4656</td>\n",
       "      <td>3.9551</td>\n",
       "      <td>58.8266</td>\n",
       "      <td>1.0259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.688200</td>\n",
       "      <td>0.687699</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.5152</td>\n",
       "      <td>6.1682</td>\n",
       "      <td>0.0973</td>\n",
       "      <td>88.8459</td>\n",
       "      <td>3.7228</td>\n",
       "      <td>1.6951</td>\n",
       "      <td>67.8768</td>\n",
       "      <td>1.469</td>\n",
       "      <td>3.9588</td>\n",
       "      <td>58.8255</td>\n",
       "      <td>1.0158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>0.688300</td>\n",
       "      <td>0.687688</td>\n",
       "      <td>0.0755</td>\n",
       "      <td>0.5225</td>\n",
       "      <td>6.2206</td>\n",
       "      <td>0.0908</td>\n",
       "      <td>89.6337</td>\n",
       "      <td>3.7010</td>\n",
       "      <td>1.5888</td>\n",
       "      <td>68.1052</td>\n",
       "      <td>1.4909</td>\n",
       "      <td>3.9290</td>\n",
       "      <td>59.4185</td>\n",
       "      <td>1.0034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.688200</td>\n",
       "      <td>0.687856</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>5.9954</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>90.2579</td>\n",
       "      <td>3.6183</td>\n",
       "      <td>1.412</td>\n",
       "      <td>69.2465</td>\n",
       "      <td>1.5082</td>\n",
       "      <td>3.8100</td>\n",
       "      <td>60.1301</td>\n",
       "      <td>1.0026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.688200</td>\n",
       "      <td>0.687866</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.5036</td>\n",
       "      <td>5.8809</td>\n",
       "      <td>0.0882</td>\n",
       "      <td>90.1138</td>\n",
       "      <td>3.679</td>\n",
       "      <td>1.4981</td>\n",
       "      <td>68.3975</td>\n",
       "      <td>1.4945</td>\n",
       "      <td>3.8061</td>\n",
       "      <td>59.7195</td>\n",
       "      <td>1.0036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.688100</td>\n",
       "      <td>0.687936</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>0.4923</td>\n",
       "      <td>5.9524</td>\n",
       "      <td>0.0887</td>\n",
       "      <td>89.8161</td>\n",
       "      <td>3.7244</td>\n",
       "      <td>1.4926</td>\n",
       "      <td>68.6854</td>\n",
       "      <td>1.4990</td>\n",
       "      <td>3.8047</td>\n",
       "      <td>59.8582</td>\n",
       "      <td>1.0012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.687918</td>\n",
       "      <td>0.0711</td>\n",
       "      <td>0.4969</td>\n",
       "      <td>5.9328</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>89.5604</td>\n",
       "      <td>3.7788</td>\n",
       "      <td>1.5535</td>\n",
       "      <td>68.2927</td>\n",
       "      <td>1.4877</td>\n",
       "      <td>3.8166</td>\n",
       "      <td>59.6032</td>\n",
       "      <td>1.0056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.688000</td>\n",
       "      <td>0.687951</td>\n",
       "      <td>0.0704</td>\n",
       "      <td>0.4907</td>\n",
       "      <td>5.9511</td>\n",
       "      <td>0.089</td>\n",
       "      <td>89.8449</td>\n",
       "      <td>3.7392</td>\n",
       "      <td>1.5255</td>\n",
       "      <td>68.3801</td>\n",
       "      <td>1.5039</td>\n",
       "      <td>3.8149</td>\n",
       "      <td>59.7612</td>\n",
       "      <td>1.0049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.687800</td>\n",
       "      <td>0.687918</td>\n",
       "      <td>0.0708</td>\n",
       "      <td>0.4924</td>\n",
       "      <td>5.9483</td>\n",
       "      <td>0.0871</td>\n",
       "      <td>90.1368</td>\n",
       "      <td>3.8315</td>\n",
       "      <td>1.5274</td>\n",
       "      <td>68.1370</td>\n",
       "      <td>1.4993</td>\n",
       "      <td>3.8137</td>\n",
       "      <td>59.7717</td>\n",
       "      <td>1.0114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.688100</td>\n",
       "      <td>0.687928</td>\n",
       "      <td>0.0707</td>\n",
       "      <td>0.4920</td>\n",
       "      <td>5.9525</td>\n",
       "      <td>0.0876</td>\n",
       "      <td>90.1217</td>\n",
       "      <td>3.8297</td>\n",
       "      <td>1.5345</td>\n",
       "      <td>68.1248</td>\n",
       "      <td>1.5007</td>\n",
       "      <td>3.8161</td>\n",
       "      <td>59.7327</td>\n",
       "      <td>1.0094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>0.688100</td>\n",
       "      <td>0.687942</td>\n",
       "      <td>0.0706</td>\n",
       "      <td>0.4912</td>\n",
       "      <td>5.95</td>\n",
       "      <td>0.0878</td>\n",
       "      <td>90.1358</td>\n",
       "      <td>3.8268</td>\n",
       "      <td>1.5399</td>\n",
       "      <td>68.1685</td>\n",
       "      <td>1.4988</td>\n",
       "      <td>3.8134</td>\n",
       "      <td>59.7190</td>\n",
       "      <td>1.0094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=43898, training_loss=0.6902236239807693, metrics={'train_runtime': 10496.4932, 'train_samples_per_second': 8.364, 'train_steps_per_second': 4.182, 'total_flos': 0.0, 'train_loss': 0.6902236239807693, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OANDA finnhub (with volume)\n",
    "\n",
    "# sru lr of 1e-4, batch size 1 hidden size 448, 60 min, \n",
    "# fp16, no slippage, classification loss ONLY, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "Could not estimate the number of tokens of the input, floating-point operations will not be computed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='43908' max='43908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [43908/43908 4:27:42, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Day profit</th>\n",
       "      <th>Day sharpe</th>\n",
       "      <th>Trade %</th>\n",
       "      <th>Full trade %</th>\n",
       "      <th>Full trade accuracy</th>\n",
       "      <th>Full trade g/l</th>\n",
       "      <th>Medium trade %</th>\n",
       "      <th>Medium trade accuracy</th>\n",
       "      <th>Medium trade g/l</th>\n",
       "      <th>Small trade %</th>\n",
       "      <th>Small trade accuracy</th>\n",
       "      <th>Small trade g/l</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.717100</td>\n",
       "      <td>0.693747</td>\n",
       "      <td>0.1514</td>\n",
       "      <td>0.1636</td>\n",
       "      <td>7.6228</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0051</td>\n",
       "      <td>21.2821</td>\n",
       "      <td>0.7697</td>\n",
       "      <td>1.6179</td>\n",
       "      <td>52.3595</td>\n",
       "      <td>1.0044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.697700</td>\n",
       "      <td>0.692957</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>4.5296</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0248</td>\n",
       "      <td>7.2072</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.2235</td>\n",
       "      <td>42.5318</td>\n",
       "      <td>0.1798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.694900</td>\n",
       "      <td>0.699272</td>\n",
       "      <td>0.0312</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>9.4922</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>80.6527</td>\n",
       "      <td>1.3304</td>\n",
       "      <td>10.5715</td>\n",
       "      <td>52.4933</td>\n",
       "      <td>1.0329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.693500</td>\n",
       "      <td>0.692022</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>4.8924</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3661</td>\n",
       "      <td>68.0546</td>\n",
       "      <td>0.5981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.693000</td>\n",
       "      <td>0.690215</td>\n",
       "      <td>0.1971</td>\n",
       "      <td>0.264</td>\n",
       "      <td>6.0723</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.7774</td>\n",
       "      <td>69.5721</td>\n",
       "      <td>0.5458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.692400</td>\n",
       "      <td>0.690883</td>\n",
       "      <td>0.2042</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>6.6588</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>75.</td>\n",
       "      <td>1.8482</td>\n",
       "      <td>0.8015</td>\n",
       "      <td>68.1698</td>\n",
       "      <td>0.9901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.692400</td>\n",
       "      <td>0.691494</td>\n",
       "      <td>0.1089</td>\n",
       "      <td>0.3278</td>\n",
       "      <td>4.3362</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.6246</td>\n",
       "      <td>73.0368</td>\n",
       "      <td>0.7382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.689541</td>\n",
       "      <td>0.2179</td>\n",
       "      <td>0.3769</td>\n",
       "      <td>5.2645</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>80.3071</td>\n",
       "      <td>1.0581</td>\n",
       "      <td>1.6695</td>\n",
       "      <td>70.289</td>\n",
       "      <td>0.8497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.690450</td>\n",
       "      <td>0.1894</td>\n",
       "      <td>0.454</td>\n",
       "      <td>4.9846</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0080</td>\n",
       "      <td>86.9281</td>\n",
       "      <td>2.0731</td>\n",
       "      <td>1.1076</td>\n",
       "      <td>72.5458</td>\n",
       "      <td>1.0780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.692000</td>\n",
       "      <td>0.692612</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.145</td>\n",
       "      <td>7.9661</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1947</td>\n",
       "      <td>78.2858</td>\n",
       "      <td>1.1479</td>\n",
       "      <td>4.1721</td>\n",
       "      <td>61.6112</td>\n",
       "      <td>0.8959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.691600</td>\n",
       "      <td>0.689665</td>\n",
       "      <td>0.2207</td>\n",
       "      <td>0.3447</td>\n",
       "      <td>5.8265</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>82.1782</td>\n",
       "      <td>1.7923</td>\n",
       "      <td>1.5849</td>\n",
       "      <td>70.1571</td>\n",
       "      <td>0.7853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.690660</td>\n",
       "      <td>0.1526</td>\n",
       "      <td>0.2956</td>\n",
       "      <td>3.8703</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>72.7273</td>\n",
       "      <td>0.4241</td>\n",
       "      <td>1.0487</td>\n",
       "      <td>70.7619</td>\n",
       "      <td>0.7166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.690484</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2844</td>\n",
       "      <td>4.8233</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0286</td>\n",
       "      <td>83.0032</td>\n",
       "      <td>1.8768</td>\n",
       "      <td>1.2609</td>\n",
       "      <td>72.531</td>\n",
       "      <td>0.8787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.688801</td>\n",
       "      <td>0.2834</td>\n",
       "      <td>0.3744</td>\n",
       "      <td>6.1748</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>83.0189</td>\n",
       "      <td>1.8608</td>\n",
       "      <td>0.2303</td>\n",
       "      <td>77.8552</td>\n",
       "      <td>1.0259</td>\n",
       "      <td>2.3274</td>\n",
       "      <td>68.9806</td>\n",
       "      <td>0.8356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7500</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.689988</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>4.6416</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>87.5</td>\n",
       "      <td>9.4044</td>\n",
       "      <td>0.3170</td>\n",
       "      <td>78.0027</td>\n",
       "      <td>0.8485</td>\n",
       "      <td>2.5470</td>\n",
       "      <td>67.2299</td>\n",
       "      <td>0.8465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8000</td>\n",
       "      <td>0.691500</td>\n",
       "      <td>0.690354</td>\n",
       "      <td>0.2422</td>\n",
       "      <td>0.2688</td>\n",
       "      <td>6.3509</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1206</td>\n",
       "      <td>81.2452</td>\n",
       "      <td>0.7070</td>\n",
       "      <td>3.2249</td>\n",
       "      <td>65.2709</td>\n",
       "      <td>0.9031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8500</td>\n",
       "      <td>0.691300</td>\n",
       "      <td>0.693063</td>\n",
       "      <td>0.0951</td>\n",
       "      <td>0.0943</td>\n",
       "      <td>6.4097</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2924</td>\n",
       "      <td>74.3983</td>\n",
       "      <td>0.6761</td>\n",
       "      <td>2.9783</td>\n",
       "      <td>64.2237</td>\n",
       "      <td>0.8599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9000</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.690585</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.3199</td>\n",
       "      <td>3.5998</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1066</td>\n",
       "      <td>79.6817</td>\n",
       "      <td>1.5325</td>\n",
       "      <td>1.4989</td>\n",
       "      <td>72.8655</td>\n",
       "      <td>0.9194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9500</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.690194</td>\n",
       "      <td>0.2545</td>\n",
       "      <td>0.3327</td>\n",
       "      <td>5.9201</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>88.3333</td>\n",
       "      <td>2.8002</td>\n",
       "      <td>0.637</td>\n",
       "      <td>75.5389</td>\n",
       "      <td>1.2497</td>\n",
       "      <td>2.9784</td>\n",
       "      <td>63.8694</td>\n",
       "      <td>1.0395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10000</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.689610</td>\n",
       "      <td>0.2149</td>\n",
       "      <td>0.368</td>\n",
       "      <td>4.7690</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0851</td>\n",
       "      <td>83.0294</td>\n",
       "      <td>1.9879</td>\n",
       "      <td>1.2856</td>\n",
       "      <td>70.5903</td>\n",
       "      <td>0.668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10500</td>\n",
       "      <td>0.690700</td>\n",
       "      <td>0.690720</td>\n",
       "      <td>0.2037</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>6.0138</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>88.3562</td>\n",
       "      <td>6.0289</td>\n",
       "      <td>0.945</td>\n",
       "      <td>72.2201</td>\n",
       "      <td>0.6246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11000</td>\n",
       "      <td>0.691200</td>\n",
       "      <td>0.689615</td>\n",
       "      <td>0.2643</td>\n",
       "      <td>0.3021</td>\n",
       "      <td>6.3960</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3362</td>\n",
       "      <td>80.5867</td>\n",
       "      <td>1.1378</td>\n",
       "      <td>3.0554</td>\n",
       "      <td>65.6911</td>\n",
       "      <td>0.9567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11500</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.690134</td>\n",
       "      <td>0.2455</td>\n",
       "      <td>0.2706</td>\n",
       "      <td>6.1395</td>\n",
       "      <td>0.0014</td>\n",
       "      <td>91.2621</td>\n",
       "      <td>1.4783</td>\n",
       "      <td>0.4421</td>\n",
       "      <td>79.4175</td>\n",
       "      <td>0.8572</td>\n",
       "      <td>2.7146</td>\n",
       "      <td>66.037</td>\n",
       "      <td>0.9473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12000</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.689372</td>\n",
       "      <td>0.2498</td>\n",
       "      <td>0.3562</td>\n",
       "      <td>4.9647</td>\n",
       "      <td>0.001</td>\n",
       "      <td>93.1507</td>\n",
       "      <td>10.8433</td>\n",
       "      <td>0.414</td>\n",
       "      <td>78.3797</td>\n",
       "      <td>0.961</td>\n",
       "      <td>1.533</td>\n",
       "      <td>70.1815</td>\n",
       "      <td>0.8426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12500</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.689791</td>\n",
       "      <td>0.2183</td>\n",
       "      <td>0.3579</td>\n",
       "      <td>4.5865</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>84.7054</td>\n",
       "      <td>1.6078</td>\n",
       "      <td>2.2757</td>\n",
       "      <td>70.2962</td>\n",
       "      <td>0.9267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13000</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.688745</td>\n",
       "      <td>0.2927</td>\n",
       "      <td>0.4113</td>\n",
       "      <td>5.7692</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2624</td>\n",
       "      <td>82.5538</td>\n",
       "      <td>1.3198</td>\n",
       "      <td>2.6434</td>\n",
       "      <td>68.4623</td>\n",
       "      <td>0.9646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13500</td>\n",
       "      <td>0.691400</td>\n",
       "      <td>0.688847</td>\n",
       "      <td>0.2487</td>\n",
       "      <td>0.4465</td>\n",
       "      <td>4.3225</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>87.9121</td>\n",
       "      <td>2.8484</td>\n",
       "      <td>0.4152</td>\n",
       "      <td>81.1855</td>\n",
       "      <td>1.3163</td>\n",
       "      <td>1.6279</td>\n",
       "      <td>70.2027</td>\n",
       "      <td>0.8909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14000</td>\n",
       "      <td>0.691000</td>\n",
       "      <td>0.689809</td>\n",
       "      <td>0.2634</td>\n",
       "      <td>0.3824</td>\n",
       "      <td>6.0133</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>88.3803</td>\n",
       "      <td>2.1112</td>\n",
       "      <td>1.0748</td>\n",
       "      <td>76.9152</td>\n",
       "      <td>1.2788</td>\n",
       "      <td>2.9753</td>\n",
       "      <td>60.9929</td>\n",
       "      <td>0.9026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14500</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.689808</td>\n",
       "      <td>0.2033</td>\n",
       "      <td>0.2821</td>\n",
       "      <td>4.1932</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>78.5018</td>\n",
       "      <td>0.3959</td>\n",
       "      <td>2.0941</td>\n",
       "      <td>71.9737</td>\n",
       "      <td>0.8781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15000</td>\n",
       "      <td>0.691100</td>\n",
       "      <td>0.692113</td>\n",
       "      <td>0.1532</td>\n",
       "      <td>0.1555</td>\n",
       "      <td>6.0071</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>50.</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.6025</td>\n",
       "      <td>73.5665</td>\n",
       "      <td>0.6709</td>\n",
       "      <td>3.1456</td>\n",
       "      <td>62.4453</td>\n",
       "      <td>0.8245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15500</td>\n",
       "      <td>0.690900</td>\n",
       "      <td>0.689697</td>\n",
       "      <td>0.2204</td>\n",
       "      <td>0.3212</td>\n",
       "      <td>4.3251</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>94.5946</td>\n",
       "      <td>1.9009</td>\n",
       "      <td>0.5826</td>\n",
       "      <td>79.5196</td>\n",
       "      <td>1.0261</td>\n",
       "      <td>1.8170</td>\n",
       "      <td>69.1294</td>\n",
       "      <td>0.9209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16000</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.690179</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.2505</td>\n",
       "      <td>5.3648</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.3346</td>\n",
       "      <td>78.2699</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>1.4635</td>\n",
       "      <td>70.4226</td>\n",
       "      <td>0.7247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16500</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.689463</td>\n",
       "      <td>0.2192</td>\n",
       "      <td>0.3791</td>\n",
       "      <td>4.5679</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>84.2105</td>\n",
       "      <td>4.5105</td>\n",
       "      <td>0.4328</td>\n",
       "      <td>81.0551</td>\n",
       "      <td>1.4734</td>\n",
       "      <td>1.9593</td>\n",
       "      <td>69.3242</td>\n",
       "      <td>0.9062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17000</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.689750</td>\n",
       "      <td>0.1811</td>\n",
       "      <td>0.3642</td>\n",
       "      <td>3.4954</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.156</td>\n",
       "      <td>82.9567</td>\n",
       "      <td>1.4911</td>\n",
       "      <td>1.4211</td>\n",
       "      <td>73.2661</td>\n",
       "      <td>0.9378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17500</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>0.690480</td>\n",
       "      <td>0.1440</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>4.3174</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2858</td>\n",
       "      <td>81.3559</td>\n",
       "      <td>1.5914</td>\n",
       "      <td>1.3099</td>\n",
       "      <td>71.0784</td>\n",
       "      <td>0.9866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18000</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>0.689871</td>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.2796</td>\n",
       "      <td>6.2573</td>\n",
       "      <td>0.0024</td>\n",
       "      <td>92.4324</td>\n",
       "      <td>0.5687</td>\n",
       "      <td>0.6916</td>\n",
       "      <td>75.3542</td>\n",
       "      <td>0.6397</td>\n",
       "      <td>2.9812</td>\n",
       "      <td>63.3713</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18500</td>\n",
       "      <td>0.690600</td>\n",
       "      <td>0.690066</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.3405</td>\n",
       "      <td>6.3679</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>83.5688</td>\n",
       "      <td>1.5581</td>\n",
       "      <td>1.5952</td>\n",
       "      <td>75.0163</td>\n",
       "      <td>1.1214</td>\n",
       "      <td>3.6933</td>\n",
       "      <td>56.4005</td>\n",
       "      <td>1.0395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19000</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>0.689057</td>\n",
       "      <td>0.2798</td>\n",
       "      <td>0.3272</td>\n",
       "      <td>4.3806</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>85.8156</td>\n",
       "      <td>1.8045</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>77.6389</td>\n",
       "      <td>1.3278</td>\n",
       "      <td>1.5357</td>\n",
       "      <td>68.9483</td>\n",
       "      <td>1.1753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19500</td>\n",
       "      <td>0.690800</td>\n",
       "      <td>0.690773</td>\n",
       "      <td>0.2356</td>\n",
       "      <td>0.2458</td>\n",
       "      <td>5.686</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>90.</td>\n",
       "      <td>3.0672</td>\n",
       "      <td>0.6524</td>\n",
       "      <td>77.4736</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>2.3384</td>\n",
       "      <td>66.8727</td>\n",
       "      <td>1.0517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20000</td>\n",
       "      <td>0.690400</td>\n",
       "      <td>0.689742</td>\n",
       "      <td>0.2355</td>\n",
       "      <td>0.2881</td>\n",
       "      <td>5.1574</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.1929</td>\n",
       "      <td>75.1023</td>\n",
       "      <td>0.7681</td>\n",
       "      <td>1.9477</td>\n",
       "      <td>67.8856</td>\n",
       "      <td>0.8062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20500</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>0.688995</td>\n",
       "      <td>0.3082</td>\n",
       "      <td>0.3694</td>\n",
       "      <td>5.9658</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>79.2387</td>\n",
       "      <td>1.0212</td>\n",
       "      <td>3.1122</td>\n",
       "      <td>65.3584</td>\n",
       "      <td>0.9515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21000</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.689773</td>\n",
       "      <td>0.3167</td>\n",
       "      <td>0.3687</td>\n",
       "      <td>6.4697</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>78.6806</td>\n",
       "      <td>1.3095</td>\n",
       "      <td>1.6514</td>\n",
       "      <td>73.3448</td>\n",
       "      <td>1.02</td>\n",
       "      <td>2.6748</td>\n",
       "      <td>58.6127</td>\n",
       "      <td>0.9012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21500</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.688606</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.4209</td>\n",
       "      <td>5.062</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.606</td>\n",
       "      <td>78.2883</td>\n",
       "      <td>1.0334</td>\n",
       "      <td>2.2662</td>\n",
       "      <td>68.4602</td>\n",
       "      <td>0.9097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22000</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.689495</td>\n",
       "      <td>0.2165</td>\n",
       "      <td>0.3034</td>\n",
       "      <td>4.6013</td>\n",
       "      <td>0.</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>80.0481</td>\n",
       "      <td>0.3960</td>\n",
       "      <td>1.8223</td>\n",
       "      <td>71.1371</td>\n",
       "      <td>0.7471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22500</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.689875</td>\n",
       "      <td>0.2521</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>5.3633</td>\n",
       "      <td>0.0016</td>\n",
       "      <td>97.479</td>\n",
       "      <td>3.8762</td>\n",
       "      <td>0.7544</td>\n",
       "      <td>76.3781</td>\n",
       "      <td>0.7473</td>\n",
       "      <td>2.2733</td>\n",
       "      <td>68.2249</td>\n",
       "      <td>0.9537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23000</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.688728</td>\n",
       "      <td>0.3008</td>\n",
       "      <td>0.3476</td>\n",
       "      <td>5.2293</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>89.5035</td>\n",
       "      <td>1.0931</td>\n",
       "      <td>1.0843</td>\n",
       "      <td>75.6714</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>2.1498</td>\n",
       "      <td>66.2313</td>\n",
       "      <td>0.9922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23500</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.690546</td>\n",
       "      <td>0.3003</td>\n",
       "      <td>0.2852</td>\n",
       "      <td>6.0172</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>83.0948</td>\n",
       "      <td>1.7192</td>\n",
       "      <td>1.0790</td>\n",
       "      <td>73.0525</td>\n",
       "      <td>0.7829</td>\n",
       "      <td>3.1863</td>\n",
       "      <td>60.9303</td>\n",
       "      <td>1.0788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24000</td>\n",
       "      <td>0.690500</td>\n",
       "      <td>0.689065</td>\n",
       "      <td>0.2639</td>\n",
       "      <td>0.353</td>\n",
       "      <td>4.9769</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>81.4298</td>\n",
       "      <td>1.4443</td>\n",
       "      <td>2.304</td>\n",
       "      <td>70.5563</td>\n",
       "      <td>0.9892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24500</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.689286</td>\n",
       "      <td>0.2536</td>\n",
       "      <td>0.3665</td>\n",
       "      <td>4.9124</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>95.9016</td>\n",
       "      <td>1.4479</td>\n",
       "      <td>0.5914</td>\n",
       "      <td>78.4783</td>\n",
       "      <td>1.1807</td>\n",
       "      <td>1.6935</td>\n",
       "      <td>70.2825</td>\n",
       "      <td>1.0661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25000</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.688176</td>\n",
       "      <td>0.3128</td>\n",
       "      <td>0.4485</td>\n",
       "      <td>5.0697</td>\n",
       "      <td>0.0079</td>\n",
       "      <td>92.9883</td>\n",
       "      <td>1.6835</td>\n",
       "      <td>0.7363</td>\n",
       "      <td>78.8725</td>\n",
       "      <td>1.226</td>\n",
       "      <td>2.1340</td>\n",
       "      <td>67.4056</td>\n",
       "      <td>0.9557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25500</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.688752</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.4039</td>\n",
       "      <td>4.4462</td>\n",
       "      <td>0.002</td>\n",
       "      <td>97.3684</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.712</td>\n",
       "      <td>78.4157</td>\n",
       "      <td>1.2235</td>\n",
       "      <td>2.0818</td>\n",
       "      <td>68.2385</td>\n",
       "      <td>0.9982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.689180</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.3498</td>\n",
       "      <td>5.2509</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.7112</td>\n",
       "      <td>78.4710</td>\n",
       "      <td>1.1857</td>\n",
       "      <td>2.6845</td>\n",
       "      <td>66.1609</td>\n",
       "      <td>0.9899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26500</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.689201</td>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.3633</td>\n",
       "      <td>5.6363</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.5702</td>\n",
       "      <td>79.184</td>\n",
       "      <td>1.1551</td>\n",
       "      <td>2.604</td>\n",
       "      <td>66.7323</td>\n",
       "      <td>0.9559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27000</td>\n",
       "      <td>0.690300</td>\n",
       "      <td>0.689552</td>\n",
       "      <td>0.2477</td>\n",
       "      <td>0.3192</td>\n",
       "      <td>4.9177</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.5764</td>\n",
       "      <td>78.0506</td>\n",
       "      <td>1.1684</td>\n",
       "      <td>2.4422</td>\n",
       "      <td>68.6749</td>\n",
       "      <td>0.927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27500</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.689120</td>\n",
       "      <td>0.2726</td>\n",
       "      <td>0.3387</td>\n",
       "      <td>4.8362</td>\n",
       "      <td>0.0173</td>\n",
       "      <td>92.4127</td>\n",
       "      <td>1.3206</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>76.9914</td>\n",
       "      <td>1.1926</td>\n",
       "      <td>1.9629</td>\n",
       "      <td>66.4384</td>\n",
       "      <td>0.7419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28000</td>\n",
       "      <td>0.690400</td>\n",
       "      <td>0.688792</td>\n",
       "      <td>0.2772</td>\n",
       "      <td>0.365</td>\n",
       "      <td>4.5864</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>96.4706</td>\n",
       "      <td>2.3987</td>\n",
       "      <td>0.5768</td>\n",
       "      <td>77.0067</td>\n",
       "      <td>1.1182</td>\n",
       "      <td>2.0039</td>\n",
       "      <td>70.4338</td>\n",
       "      <td>0.885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28500</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.688463</td>\n",
       "      <td>0.3235</td>\n",
       "      <td>0.3477</td>\n",
       "      <td>5.9892</td>\n",
       "      <td>0.0034</td>\n",
       "      <td>91.4729</td>\n",
       "      <td>2.1169</td>\n",
       "      <td>0.9912</td>\n",
       "      <td>77.2371</td>\n",
       "      <td>1.1694</td>\n",
       "      <td>2.2649</td>\n",
       "      <td>65.5639</td>\n",
       "      <td>0.8794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29000</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.689025</td>\n",
       "      <td>0.2670</td>\n",
       "      <td>0.3322</td>\n",
       "      <td>4.8444</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>100.</td>\n",
       "      <td>nan</td>\n",
       "      <td>0.447</td>\n",
       "      <td>76.6727</td>\n",
       "      <td>1.0726</td>\n",
       "      <td>2.0757</td>\n",
       "      <td>70.5438</td>\n",
       "      <td>0.8735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29500</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.688721</td>\n",
       "      <td>0.2866</td>\n",
       "      <td>0.3658</td>\n",
       "      <td>4.9215</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>90.2985</td>\n",
       "      <td>1.5134</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>76.6635</td>\n",
       "      <td>1.127</td>\n",
       "      <td>2.1031</td>\n",
       "      <td>68.0033</td>\n",
       "      <td>0.9495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30000</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.688921</td>\n",
       "      <td>0.2804</td>\n",
       "      <td>0.3357</td>\n",
       "      <td>4.4543</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>94.3396</td>\n",
       "      <td>1.1755</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>76.7443</td>\n",
       "      <td>1.1262</td>\n",
       "      <td>2.2446</td>\n",
       "      <td>68.397</td>\n",
       "      <td>1.0052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30500</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.688907</td>\n",
       "      <td>0.3006</td>\n",
       "      <td>0.3671</td>\n",
       "      <td>4.9610</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>92.0556</td>\n",
       "      <td>1.7576</td>\n",
       "      <td>0.8956</td>\n",
       "      <td>76.3735</td>\n",
       "      <td>1.1920</td>\n",
       "      <td>1.9978</td>\n",
       "      <td>68.3628</td>\n",
       "      <td>0.9802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31000</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.688517</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.3785</td>\n",
       "      <td>4.7515</td>\n",
       "      <td>0.0012</td>\n",
       "      <td>97.8947</td>\n",
       "      <td>5.4728</td>\n",
       "      <td>0.6155</td>\n",
       "      <td>77.7068</td>\n",
       "      <td>1.0984</td>\n",
       "      <td>2.0387</td>\n",
       "      <td>69.5373</td>\n",
       "      <td>0.9088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31500</td>\n",
       "      <td>0.689900</td>\n",
       "      <td>0.688830</td>\n",
       "      <td>0.3511</td>\n",
       "      <td>0.3828</td>\n",
       "      <td>5.6181</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>89.9794</td>\n",
       "      <td>1.6062</td>\n",
       "      <td>1.1863</td>\n",
       "      <td>76.1777</td>\n",
       "      <td>1.0948</td>\n",
       "      <td>2.3692</td>\n",
       "      <td>64.6474</td>\n",
       "      <td>0.9569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32000</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.688614</td>\n",
       "      <td>0.3368</td>\n",
       "      <td>0.364</td>\n",
       "      <td>5.1365</td>\n",
       "      <td>0.0449</td>\n",
       "      <td>88.6057</td>\n",
       "      <td>1.6023</td>\n",
       "      <td>1.3181</td>\n",
       "      <td>76.4636</td>\n",
       "      <td>1.1088</td>\n",
       "      <td>2.2673</td>\n",
       "      <td>63.6481</td>\n",
       "      <td>0.9241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32500</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.689130</td>\n",
       "      <td>0.3073</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>5.6637</td>\n",
       "      <td>0.005</td>\n",
       "      <td>90.2375</td>\n",
       "      <td>2.1073</td>\n",
       "      <td>0.9061</td>\n",
       "      <td>77.2735</td>\n",
       "      <td>0.9534</td>\n",
       "      <td>2.8163</td>\n",
       "      <td>65.7793</td>\n",
       "      <td>0.9655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33000</td>\n",
       "      <td>0.690100</td>\n",
       "      <td>0.688457</td>\n",
       "      <td>0.3171</td>\n",
       "      <td>0.3594</td>\n",
       "      <td>4.9118</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>90.1961</td>\n",
       "      <td>2.1523</td>\n",
       "      <td>0.8266</td>\n",
       "      <td>76.6314</td>\n",
       "      <td>0.9962</td>\n",
       "      <td>2.2613</td>\n",
       "      <td>68.7873</td>\n",
       "      <td>1.2080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33500</td>\n",
       "      <td>0.690200</td>\n",
       "      <td>0.688998</td>\n",
       "      <td>0.2821</td>\n",
       "      <td>0.3305</td>\n",
       "      <td>4.8249</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>91.2568</td>\n",
       "      <td>2.0806</td>\n",
       "      <td>0.8564</td>\n",
       "      <td>76.5949</td>\n",
       "      <td>0.9187</td>\n",
       "      <td>2.2447</td>\n",
       "      <td>67.9164</td>\n",
       "      <td>0.9853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34000</td>\n",
       "      <td>0.689300</td>\n",
       "      <td>0.689280</td>\n",
       "      <td>0.3355</td>\n",
       "      <td>0.3298</td>\n",
       "      <td>5.6942</td>\n",
       "      <td>0.0377</td>\n",
       "      <td>84.5375</td>\n",
       "      <td>2.0185</td>\n",
       "      <td>1.2456</td>\n",
       "      <td>74.8704</td>\n",
       "      <td>0.9233</td>\n",
       "      <td>2.6333</td>\n",
       "      <td>64.6185</td>\n",
       "      <td>0.9844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34500</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.688782</td>\n",
       "      <td>0.3471</td>\n",
       "      <td>0.3555</td>\n",
       "      <td>5.4949</td>\n",
       "      <td>0.0794</td>\n",
       "      <td>83.3527</td>\n",
       "      <td>1.6106</td>\n",
       "      <td>1.3036</td>\n",
       "      <td>75.5385</td>\n",
       "      <td>1.0009</td>\n",
       "      <td>2.1671</td>\n",
       "      <td>64.1909</td>\n",
       "      <td>0.9696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35000</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.689042</td>\n",
       "      <td>0.3135</td>\n",
       "      <td>0.3049</td>\n",
       "      <td>5.3961</td>\n",
       "      <td>0.023</td>\n",
       "      <td>88.9016</td>\n",
       "      <td>2.0351</td>\n",
       "      <td>1.0877</td>\n",
       "      <td>75.1315</td>\n",
       "      <td>0.8490</td>\n",
       "      <td>2.1612</td>\n",
       "      <td>66.2145</td>\n",
       "      <td>1.1021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35500</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>0.688740</td>\n",
       "      <td>0.3340</td>\n",
       "      <td>0.347</td>\n",
       "      <td>5.2348</td>\n",
       "      <td>0.046</td>\n",
       "      <td>85.3505</td>\n",
       "      <td>1.679</td>\n",
       "      <td>1.2620</td>\n",
       "      <td>75.7905</td>\n",
       "      <td>0.9399</td>\n",
       "      <td>2.0925</td>\n",
       "      <td>64.8634</td>\n",
       "      <td>0.9488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36000</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>0.688648</td>\n",
       "      <td>0.317</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>5.1432</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>92.2190</td>\n",
       "      <td>1.8967</td>\n",
       "      <td>0.9181</td>\n",
       "      <td>76.1442</td>\n",
       "      <td>0.9336</td>\n",
       "      <td>2.1259</td>\n",
       "      <td>68.6002</td>\n",
       "      <td>0.9659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36500</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>0.688779</td>\n",
       "      <td>0.3152</td>\n",
       "      <td>0.3443</td>\n",
       "      <td>5.2968</td>\n",
       "      <td>0.0209</td>\n",
       "      <td>89.6096</td>\n",
       "      <td>1.9345</td>\n",
       "      <td>1.1215</td>\n",
       "      <td>76.7366</td>\n",
       "      <td>0.9696</td>\n",
       "      <td>2.2252</td>\n",
       "      <td>66.2137</td>\n",
       "      <td>0.8980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37000</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.688543</td>\n",
       "      <td>0.3438</td>\n",
       "      <td>0.3681</td>\n",
       "      <td>5.5820</td>\n",
       "      <td>0.0278</td>\n",
       "      <td>88.4889</td>\n",
       "      <td>1.5909</td>\n",
       "      <td>1.2404</td>\n",
       "      <td>76.5547</td>\n",
       "      <td>0.9973</td>\n",
       "      <td>2.3324</td>\n",
       "      <td>64.5292</td>\n",
       "      <td>0.8844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37500</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.689168</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.3212</td>\n",
       "      <td>5.3490</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>91.7943</td>\n",
       "      <td>2.6255</td>\n",
       "      <td>1.0571</td>\n",
       "      <td>76.2420</td>\n",
       "      <td>0.9801</td>\n",
       "      <td>2.3923</td>\n",
       "      <td>65.2132</td>\n",
       "      <td>0.9006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38000</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.688790</td>\n",
       "      <td>0.3212</td>\n",
       "      <td>0.3490</td>\n",
       "      <td>5.2649</td>\n",
       "      <td>0.0161</td>\n",
       "      <td>90.6634</td>\n",
       "      <td>1.9929</td>\n",
       "      <td>1.063</td>\n",
       "      <td>76.3357</td>\n",
       "      <td>0.985</td>\n",
       "      <td>2.3440</td>\n",
       "      <td>65.0283</td>\n",
       "      <td>0.908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38500</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>0.688975</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>5.3881</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>88.2463</td>\n",
       "      <td>1.7094</td>\n",
       "      <td>1.1923</td>\n",
       "      <td>76.3612</td>\n",
       "      <td>1.0162</td>\n",
       "      <td>2.3825</td>\n",
       "      <td>64.5564</td>\n",
       "      <td>0.8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39000</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.688866</td>\n",
       "      <td>0.3236</td>\n",
       "      <td>0.3449</td>\n",
       "      <td>5.2922</td>\n",
       "      <td>0.0205</td>\n",
       "      <td>89.2031</td>\n",
       "      <td>2.0312</td>\n",
       "      <td>1.1125</td>\n",
       "      <td>76.4508</td>\n",
       "      <td>1.0064</td>\n",
       "      <td>2.3827</td>\n",
       "      <td>65.0594</td>\n",
       "      <td>0.904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39500</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.689123</td>\n",
       "      <td>0.3119</td>\n",
       "      <td>0.3258</td>\n",
       "      <td>5.2962</td>\n",
       "      <td>0.0182</td>\n",
       "      <td>89.8771</td>\n",
       "      <td>1.9907</td>\n",
       "      <td>1.1033</td>\n",
       "      <td>76.3289</td>\n",
       "      <td>1.0029</td>\n",
       "      <td>2.4000</td>\n",
       "      <td>64.7978</td>\n",
       "      <td>0.9005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40000</td>\n",
       "      <td>0.689600</td>\n",
       "      <td>0.688983</td>\n",
       "      <td>0.3112</td>\n",
       "      <td>0.335</td>\n",
       "      <td>5.2472</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>91.3232</td>\n",
       "      <td>2.1377</td>\n",
       "      <td>0.9996</td>\n",
       "      <td>76.4319</td>\n",
       "      <td>0.9757</td>\n",
       "      <td>2.4047</td>\n",
       "      <td>65.6441</td>\n",
       "      <td>0.9053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40500</td>\n",
       "      <td>0.689700</td>\n",
       "      <td>0.688831</td>\n",
       "      <td>0.3154</td>\n",
       "      <td>0.3410</td>\n",
       "      <td>5.1539</td>\n",
       "      <td>0.01</td>\n",
       "      <td>91.1609</td>\n",
       "      <td>2.3055</td>\n",
       "      <td>1.0087</td>\n",
       "      <td>76.3873</td>\n",
       "      <td>0.9794</td>\n",
       "      <td>2.4088</td>\n",
       "      <td>65.5111</td>\n",
       "      <td>0.9099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41000</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.688890</td>\n",
       "      <td>0.3199</td>\n",
       "      <td>0.3408</td>\n",
       "      <td>5.2599</td>\n",
       "      <td>0.0142</td>\n",
       "      <td>91.0781</td>\n",
       "      <td>2.0462</td>\n",
       "      <td>1.0813</td>\n",
       "      <td>76.4301</td>\n",
       "      <td>0.9911</td>\n",
       "      <td>2.4456</td>\n",
       "      <td>64.9704</td>\n",
       "      <td>0.902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41500</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.688790</td>\n",
       "      <td>0.3250</td>\n",
       "      <td>0.3484</td>\n",
       "      <td>5.2322</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>90.0943</td>\n",
       "      <td>2.0188</td>\n",
       "      <td>1.1015</td>\n",
       "      <td>76.4077</td>\n",
       "      <td>0.9944</td>\n",
       "      <td>2.4038</td>\n",
       "      <td>64.8534</td>\n",
       "      <td>0.9029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42000</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.688801</td>\n",
       "      <td>0.3259</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>5.2796</td>\n",
       "      <td>0.0171</td>\n",
       "      <td>89.8383</td>\n",
       "      <td>2.0567</td>\n",
       "      <td>1.0972</td>\n",
       "      <td>76.3869</td>\n",
       "      <td>0.9941</td>\n",
       "      <td>2.4009</td>\n",
       "      <td>64.9635</td>\n",
       "      <td>0.9044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42500</td>\n",
       "      <td>0.689800</td>\n",
       "      <td>0.688779</td>\n",
       "      <td>0.3246</td>\n",
       "      <td>0.3480</td>\n",
       "      <td>5.2253</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>90.0474</td>\n",
       "      <td>2.1339</td>\n",
       "      <td>1.0894</td>\n",
       "      <td>76.3715</td>\n",
       "      <td>0.9924</td>\n",
       "      <td>2.3724</td>\n",
       "      <td>64.991</td>\n",
       "      <td>0.9072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43000</td>\n",
       "      <td>0.690000</td>\n",
       "      <td>0.688762</td>\n",
       "      <td>0.3248</td>\n",
       "      <td>0.3494</td>\n",
       "      <td>5.2063</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>90.5785</td>\n",
       "      <td>2.1127</td>\n",
       "      <td>1.0817</td>\n",
       "      <td>76.3634</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>2.3712</td>\n",
       "      <td>65.0546</td>\n",
       "      <td>0.9078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43500</td>\n",
       "      <td>0.689500</td>\n",
       "      <td>0.688764</td>\n",
       "      <td>0.3249</td>\n",
       "      <td>0.3494</td>\n",
       "      <td>5.2126</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>90.5941</td>\n",
       "      <td>2.1106</td>\n",
       "      <td>1.0823</td>\n",
       "      <td>76.3586</td>\n",
       "      <td>0.9926</td>\n",
       "      <td>2.3724</td>\n",
       "      <td>65.0523</td>\n",
       "      <td>0.909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .8) & (abs_trade >= .5)] > 0).mean() * 100,\n",
      "<ipython-input-2-3fb8edfb8ee8>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .8) & (abs_trade >= .5) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-3fb8edfb8ee8>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .8) & (abs_trade >= .5) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .8) & (abs_trade >= .5) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:20: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade accuracy': (soft_profit[(abs_trade < .8) & (abs_trade >= .5)] > 0).mean() * 100,\n",
      "<ipython-input-2-3fb8edfb8ee8>:21: RuntimeWarning: Mean of empty slice.\n",
      "  'medium trade g/l': soft_profit[(abs_trade < .8) & (abs_trade >= .5) & (soft_profit > 0)].mean()\n",
      "<ipython-input-2-3fb8edfb8ee8>:22: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade < .8) & (abs_trade >= .5) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:15: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade accuracy': (soft_profit[abs_trade >= .8] > 0).mean() * 100,\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:16: RuntimeWarning: Mean of empty slice.\n",
      "  'full trade g/l': soft_profit[(abs_trade >= .8) & (soft_profit > 0)].mean()\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "<ipython-input-2-3fb8edfb8ee8>:17: RuntimeWarning: Mean of empty slice.\n",
      "  / -soft_profit[(abs_trade >= .8) & (soft_profit < 0)].mean(),\n",
      "C:\\Users\\micha\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:190: RuntimeWarning: invalid value encountered in divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=43908, training_loss=0.6909465659475938, metrics={'train_runtime': 16064.3508, 'train_samples_per_second': 5.466, 'train_steps_per_second': 2.733, 'total_flos': 0.0, 'train_loss': 0.6909465659475938, 'epoch': 1.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OANDA finnhub\n",
    "\n",
    "# sru lr of 1e-4, batch size 1 hidden size 448, 60 min, \n",
    "# fp16, no slippage, .5 classification loss + .5 rr nll, rotary embeddings, .1 dropout\n",
    "# weight decay, head size of 64, NO diagonal attention allowed\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gpt2 experiements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class GPT2Trader(PreTrainedModel):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "        # use levine 2020 layer numbers\n",
    "        n_layer = round((math.log(config.n_embd) - 5.039) / 5.55e-2)\n",
    "        n_layer = max(1, n_layer)\n",
    "        print(f'Using {n_layer} layers')\n",
    "        config.n_layer = n_layer\n",
    "        \n",
    "        config.initializer_range = 1 / math.sqrt(config.n_embd)\n",
    "        \n",
    "        self.embed = nn.Linear(5, config.n_embd, bias = False)\n",
    "        self.norm = nn.LayerNorm(config.n_embd)\n",
    "        self.gpt = GPT2Model(config)\n",
    "        self.trade = nn.Linear(config.n_embd, 60, bias = False)\n",
    "\n",
    "\n",
    "    def forward(self, ohlcv, future):\n",
    "        embed = self.norm(self.embed(ohlcv))\n",
    "        hidden = self.gpt(inputs_embeds = embed).last_hidden_state\n",
    "        \n",
    "        soft_trade = self.trade(hidden)\n",
    "        \n",
    "        # sharpe information\n",
    "        soft_trade = torch.tanh(soft_trade)\n",
    "        soft_profit = soft_trade * future\n",
    "        \n",
    "        # the exp is so that loss is purely positive and minimizes toward 0 (also losses have more loss than profit)\n",
    "        loss_ppl = torch.square(-soft_profit + future.abs()).mean()\n",
    "        \n",
    "        # penalty for big trades (to stop trading from happening with no profit)\n",
    "        trade_penalty = soft_trade.abs().mean()\n",
    "        \n",
    "        loss = loss_ppl# + .1 * trade_penalty # .1 means that a 100% position must make at least .1 of a std to offset loss\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'profits': soft_profit,\n",
    "            'trades': soft_trade,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir = \"./results\",\n",
    "    logging_strategy = \"steps\",\n",
    "    evaluation_strategy = \"steps\",\n",
    "    logging_steps = 100,\n",
    "    eval_steps = 100,\n",
    "    report_to = \"none\",\n",
    "    learning_rate = 5e-4,\n",
    "    lr_scheduler_type = \"cosine\",\n",
    "    warmup_ratio = .05,\n",
    "    num_train_epochs = 1,\n",
    "    per_device_train_batch_size = 1,\n",
    "    per_device_eval_batch_size = 1,\n",
    "    max_grad_norm = 1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 16 layers\n"
     ]
    }
   ],
   "source": [
    "config = GPT2Config(\n",
    "    n_embd = 384, n_head = 6, vocab_size = 0, n_positions = 2000,\n",
    "    resid_pdrop = .01, embd_pdrop = .01, attn_pdrop = .01, # low dropout since only using 1 epoch training and to make model more robust to data issues (.1 has worse loss, accuracy & t-score)\n",
    "    summary_first_dropout = 0, summary_proj_to_labels = False,\n",
    "    scale_attn_by_inverse_layer_idx = True, use_cache = False\n",
    ")\n",
    "model = GPT2Trader(config)\n",
    "trainer = Trainer(\n",
    "    model = model,\n",
    "    args = training_args,\n",
    "    train_dataset = fx['train'],\n",
    "    eval_dataset = fx['validation'],\n",
    "    compute_metrics = compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## failed idea: have the model go through a timewise curriculum of the data\n",
    "The idea was that if the training didn't respect the timeseries nature of the data, then the model could \"memorize\" parts of the data and use that to predict past data better (which wouldn't be good at test time). Seemingly this isn't an issue as the model performs better on a validation set that does come from the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraderTrainer(Trainer):\n",
    "\n",
    "    def get_train_dataloader(self) -> DataLoader:\n",
    "        \"\"\"\n",
    "        Returns the training :class:`~torch.utils.data.DataLoader`.\n",
    "\n",
    "        Will use no sampler if :obj:`self.train_dataset` does not implement :obj:`__len__`, a random sampler (adapted\n",
    "        to distributed training if necessary) otherwise.\n",
    "\n",
    "        Subclass and override this method if you want to inject some custom behavior.\n",
    "        \"\"\"\n",
    "        if self.train_dataset is None:\n",
    "            raise ValueError(\"Trainer: training requires a train_dataset.\")\n",
    "        train_sampler = self._get_train_sampler()\n",
    "\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.args.train_batch_size,\n",
    "#             shuffle=False, # TO STOP OVERFITTING\n",
    "            sampler=train_sampler,\n",
    "            collate_fn=self.data_collator,\n",
    "            drop_last=self.args.dataloader_drop_last,\n",
    "            num_workers=self.args.dataloader_num_workers,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## make sure unshuffled split maintains order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = Dataset.from_dict({\"input\": list(range(100))})\n",
    "split = foo.train_test_split(.1, shuffle = False)\n",
    "valid_test = split['test'].train_test_split(.5, shuffle = False)\n",
    "foo = DatasetDict({\n",
    "    'train': split['train'],\n",
    "    'validation': valid_test['train'],\n",
    "    'test': valid_test['test']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([90, 91, 92, 93, 94], [95, 96, 97, 98, 99])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foo['validation']['input'], foo['test']['input']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## quick timing check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2Trader(config).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.2 ms  2.7 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fake_data = torch.randn(4, 391, 256)\n",
    "fake_data = fake_data.cuda()\n",
    "model(fake_data)\n",
    "cpu = fake_data.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 9 layers\n"
     ]
    }
   ],
   "source": [
    "model = GPT2Trader(config).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "748 ms  82.3 ms per loop (mean  std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "fake_data = torch.randn(4, 391, 256)\n",
    "model(fake_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
